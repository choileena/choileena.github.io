---
title: "Build-PK-IV - Comprehensive"
description: |
  This tutorial describes a comprehensive PK data building procedure for medications that are intravenously administered. There are two phases: data processing which standardizes and combines the input data (*Pro-Demographic*, *Pro-Med-Str*, *Pro-Drug Level*, *Pro-Laboratory*) and data building which creates the final PK data (*Build-PK-IV*).
author:
  - name: Nathan T. James
output:
  distill::distill_article:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = TRUE)
knitr::opts_chunk$set(R.options = list(width = 140))
library(EHR)
library(pkdata)
library(lubridate)
```

* See also "Example 2: Complete Data Processing and Building from Raw Extracted Data to PK Data" in "[2. EHR Vignette for Structured Data](https://cran.r-project.org/web/packages/EHR/vignettes/ehr_vignette_02_str.html)" of `EHR` package.

# Introduction

This tutorial describes four modules for processing data (*Pro-Demographic*, *Pro-Med-Str*, *Pro-Drug Level*, *Pro-Laboratory*) and one module for PK data building (*Build-PK-IV*) using data extracted from a structured database.

To begin we load the `EHR` package, the `pkdata` package, and the `lubridate` package. 

```{r load-lib-dir, eval=FALSE}
# load EHR package and dependencies
library(EHR)
library(pkdata)
library(lubridate)
```

* We first define three directories: 

    + one for raw structured data
    + one containing files used for interactive checking
    + one for processed data. 
    
* There are 4 types of raw data expected to exist in the raw data directory (i.e., rawDataDir below):

    + a demographic file for use with the *Pro-Demographic* module (Demographics_DATA.csv)
    + two files for the *Pro-Drug Level* module (SampleTimes_DATA.csv and SampleConcentration_DATA.csv)
    + two dosing files for the *Pro-Med-Str* module (FLOW_DATA.csv and MAR_DATA.csv)
    + two lab files for use with the *Pro-Laboratory* module (Creatinine_DATA.csv and Albumin_DATA.csv).

```{r ex2-dirs}
# define 3 directories
rawDataDir <- system.file("examples", "str_ex2", package="EHR") # directory for raw data

td <- tempdir()
checkDir <- file.path(td, 'checks') # directory for interactive checking
dir.create(checkDir)

dataDir <- file.path(td, 'data') # directory for processed data
dir.create(dataDir)

# examine raw data files in rawDataDir
dir(rawDataDir)
```

# Pre-Processing for Raw Extracted Data

The raw datasets must go through a pre-processing stage which creates new ID variables and datasets that can be used by the data processing modules. There are three pre-processing steps:

(1)  read and clean raw data
(2)  merge raw data to create new ID variables
(3)  make new data for use with modules.

Each raw dataset should contain a subject unique ID, a subject visit ID, or both ids. In this example the subject unique ID is called `subject_uid` and the subject visit ID is called `subject_id`. The subject visit ID is a combination of subject and visit/course -- e.g., `subject_id` 14.0 is the first course for subject 14, `subject_id` 14.1 is the second course for subject 14, and so on. `subject_uid` is a unique ID that is the same for all subject records. The integer part of `subject_id` has a 1-to-1 correspondence with `subject_uid` -- for this example, `subject_uid` 62734832 is associated with both `subject_id` 14.0 and `subject_id` 14.1. If there is only a single visit/course per subject only the subject unique ID is needed.

## (1) Read and clean raw data

* **`readTransform()`**:  This function reads in a CSV file and makes optional modifications to the resulting dataframe.

* **Demographics raw data**
    + The example demographics data file contains ID variables `subject_id` and `subject_uid`, in addition to demographic variables such as gender, date of birth, height, weight, etc. As `subject_id` and `subject_uid` already exist, no further cleaning is needed.
    + The Demographics_DATA.csv file is read in using the `readTransform()` function. 

```{r demo-in}
# demographics data
demo.in <- readTransform(file.path(rawDataDir, "Demographics_DATA.csv"))
head(demo.in)
```

* **Concentration raw data**
    + The example concentration data consists of two files:
        + 1) SampleTimes_DATA.csv: contains the concentration sampling times
        + 2) SampleConcentration_DATA.csv: contains the concentration measurements
    + If all concentration data is in one file, the user should transform the file so it contains a subject unique ID, a subject visit ID, or both ids.
    + Use the function `readTransform()`
      + to read SampleTimes_DATA.csv, and rename the variable `Study.ID` to `subject_id` and create a new variable called `samp`, which indexes the sample number, using the `modify=` argument.
      + to read SampleConcentration_DATA.csv, and transform the concentration values - we use the helper function sampId() to process the subject_id field.

```{r samp-in2}
# read SampleTimes_DATA.csv
samp.in <- readTransform(file.path(rawDataDir, "SampleTimes_DATA.csv"),
    rename = c('Study.ID' = 'subject_id'),
    modify = list(samp = expression(as.numeric(sub('Sample ', '', Event.Name)))))
head(samp.in)
```

```{r conc-in2}
# helper function used to make subject_id
sampId <- function(x) {
  # remove leading zeroes or trailing periods
  subid <- gsub('(^0*|\\.$)', '', x)
  # change _ to .
  gsub('_([0-9]+[_].*)$', '.\\1', subid)
}

# read SampleConcentration_DATA.csv
conc.in <- readTransform(file.path(rawDataDir, "SampleConcentration_DATA.csv"),
  modify = list(
    subid = expression(sampId(name)),
    subject_id = expression(as.numeric(sub('[_].*', '', subid))),
    samp = expression(sub('[^_]*[_]', '', subid)),
    name = NULL,
    data_file = NULL,
    subid = NULL
    )
  )
head(conc.in)
```

* **Dosing raw data**
    + The example drug dosing data consists of two files containing two sources of IV dose information:
        + 1) FLOW_DATA.csv: contains aliases for both ID variables, and it is read in with the `readTransform()` function which renames the variables `Subject.Id` to `subject_id` and `Subject.Uniq.Id` to `subject_uid`. 
        + 2) MAR_DATA.csv: contains several variables with a colon (:) character. To preserve the colon in these variable names, the data can be read in without checking for syntactically valid `R` variable names. The data is read in using `read.csv()` with the argument `check.names = FALSE` and then passed to the **`dataTransformation()`** function which renames `Uniq.Id` to `subject_uid`.
    + If all dosing data is in one file, the user should transform the file so it contains a subject unique ID, a subject visit ID, or both ids.

```{r flow-in}
# FLOW dosing data
flow.in <- readTransform(file.path(rawDataDir, "FLOW_DATA.csv"),
                         rename = c('Subject.Id' = 'subject_id',
                                    'Subject.Uniq.Id' = 'subject_uid')) 
# pre-process the flow data 
# date.time variable should be in an appropriate form
flow.in[,'date.time'] <- pkdata::parse_dates(EHR:::fixDates(flow.in[,'Perform.Date']))
# unit and rate are required: separate unit and rate from 'Final.Rate..NFR.units.' if needed
flow.in[,'unit'] <- sub('.*[ ]', '', flow.in[,'Final.Rate..NFR.units.'])
flow.in[,'rate'] <- as.numeric(sub('([0-9.]+).*', '\\1', flow.in[,'Final.Rate..NFR.units.']))
head(flow.in)
```

```{r mar-in}
# MAR dosing data
mar.in0 <- read.csv(file.path(rawDataDir, "MAR_DATA.csv"), check.names = FALSE)
mar.in <- dataTransformation(mar.in0, rename = c('Uniq.Id' = 'subject_uid'))
head(mar.in)
```

* **Laboratory raw data**
    + The example laboratory data consists of files two files, Creatinine_DATA.csv and Albumin_DATA.csv. Both files are read in using the `readTransform()` function and `Subject.uniq` is renamed to `subject_uid`.
    + Each laboratory file should be transformed so it contains a subject unique ID, a subject visit ID, or both ids.

```{r labs-in}
# Serum creatinine lab data
creat.in <- readTransform(file.path(rawDataDir, "Creatinine_DATA.csv"),
    rename = c('Subject.uniq' = 'subject_uid'))
head(creat.in)

# Albumin lab data
alb.in <- readTransform(file.path(rawDataDir, "Albumin_DATA.csv"),
    rename = c('Subject.uniq' = 'subject_uid'))
head(creat.in)
```

## (2) Merge data to create new ID variables

* **`idCrosswalk()`**: This function merges all of the cleaned input datasets and creates new IDs.
    + Input:
        + the `data=` argument of this function accepts a list of input datasets
        + the `idcols=` argument accepts a list of vectors or character strings that identify the ID variables in the corresponding input dataset.
    + Output:
        + a crosswalk dataset between the original ID variables (`subject_id`, `subject_uid`) and the new ID variables (`mod_id`, `mod_visit`, and `mod_id_visit`). 
        + the new variable `mod_id_visit` has a 1-to-1 correspondence to variable `subject_id` and uniquely identifies each subjects' visit/course; the new variable `mod_id` has a 1-to-1 correspondence to variable `subject_uid` and uniquely identifies each subject.

```{r merge-ids}
# define list of input datasets
data <-  list(demo.in,
              samp.in,
              conc.in,
              flow.in,
              mar.in,
              creat.in,
              alb.in)

# define list of vectors or character strings that identify the ID variables
idcols <-  list(c('subject_id', 'subject_uid'), # id vars in demo.in
                'subject_id', # id var in samp.in
                'subject_id', # id var in conc.in
                c('subject_id', 'subject_uid'), # id vars in flow.in
                'subject_uid', # id var in mar.in
                'subject_uid', # id var in creat.in
                'subject_uid') # id var in creat.in

# merge all IDs from cleaned datasets and create new ID variables
id.xwalk <- idCrosswalk(data, idcols, visit.id="subject_id", uniq.id="subject_uid")
saveRDS(id.xwalk, file=file.path(dataDir,"module_id_xwalk.rds"))
head(id.xwalk)
```

## (3) Make new data for use with modules

```{r, eval = FALSE}
pullFakeId(dat, xwalk, firstCols = NULL, orderBy = NULL)
```

* **`pullFakeId()`**: This function replaces the original IDs -- `subject_id` and `subject_uid` -- with new IDs -- `mod_id`, `mod_visit`, and `mod_id_visit` -- to create datasets which can be used by the data processing modules.
    + The `dat=` argument should contain the cleaned input data.frame from pre-processing step (1).
    + The `xwalk=` argument should contain the crosswalk data.frame produced in step (2).
    + Additional arguments `firstCols=` and `orderBy=` control which variables are in the first columns of the output and the sort order, respectively. 
    + The cleaned, structured data are saved as `R` objects for use with the modules.

```{r mod-id-data}
## demographics data
demo.cln <- pullFakeId(demo.in, id.xwalk,
    firstCols = c('mod_id', 'mod_visit', 'mod_id_visit'),
    uniq.id = 'subject_uid')
head(demo.cln)
saveRDS(demo.cln, file=file.path(dataDir,"demo_mod_id.rds"))

## drug level data
# sampling times
samp.cln <- pullFakeId(samp.in, id.xwalk,
    firstCols = c('mod_id', 'mod_visit', 'mod_id_visit', 'samp'), 
    orderBy = c('mod_id_visit','samp'),
    uniq.id = 'subject_uid')
head(samp.cln)
saveRDS(samp.cln, file=file.path(dataDir,"samp_mod_id.rds"))

# drug concentration measurements
conc.cln <- pullFakeId(conc.in, id.xwalk,
    firstCols = c('record_id', 'mod_id', 'mod_visit', 'mod_id_visit', 'samp'),
    orderBy = 'record_id',
    uniq.id = 'subject_uid')
head(conc.cln)
saveRDS(conc.cln, file=file.path(dataDir,"conc_mod_id.rds"))

## dosing data
# flow
flow.cln <- pullFakeId(flow.in, id.xwalk,
    firstCols = c('mod_id', 'mod_visit', 'mod_id_visit'),
    uniq.id = 'subject_uid')
head(flow.cln)
saveRDS(flow.cln, file=file.path(dataDir,"flow_mod_id.rds"))

# mar
mar.cln <- pullFakeId(mar.in, id.xwalk, firstCols = 'mod_id', uniq.id = 'subject_uid')
head(mar.cln)
saveRDS(mar.cln, file=file.path(dataDir,"mar_mod_id.rds"))

## laboratory data
# creatinine
creat.cln <- pullFakeId(creat.in, id.xwalk, 'mod_id',uniq.id = 'subject_uid')
head(creat.cln)
saveRDS(creat.cln, file=file.path(dataDir,"creat_mod_id.rds"))

# albumin
alb.cln <- pullFakeId(alb.in, id.xwalk, 'mod_id', uniq.id = 'subject_uid')
head(alb.cln)
saveRDS(alb.cln, file=file.path(dataDir,"alb_mod_id.rds"))
```


* **Options and parameters**: Before running the processing modules, it is necessary to define several options and parameters. 

    + Using `options(pkxwalk =)` allows the modules to access the crosswalk file. 
    + Create a `drugname` stub.
    + Define the lower limit of quantification (LLOQ) for the drug concentration if applicable.

```{r mod-setup}
# set crosswalk option 
xwalk <- readRDS(file.path(dataDir, "module_id_xwalk.rds"))
options(pkxwalk = 'xwalk')

# define parameters
drugname <- 'fent'
LLOQ <- 0.05
```

# Pro-Demographic

* This module accepts the cleaned structured demographic dataset and a user-defined set of exclusion criteria and returns a formatted list with the demographic data and records meeting the exclusion criteria suitable for integration with the other modules.
* For this example, we exclude subjects with a value of 1 for `in_hospital_mortality` or `add_ecmo` and create a new variable called `length_of_icu_stay`.
* **`run_Demo()`** is the function to run this module.

```{r Pro-Demographic}
# helper function
exclude_val <- function(x, val=1) { !is.na(x) & x == val }

demo.out <- run_Demo(demo.path = file.path(dataDir, "demo_mod_id.rds"),
    demo.columns = list(id = 'mod_id_visit'),
    toexclude = expression(exclude_val(in_hospital_mortality) | exclude_val(add_ecmo)),
    demo.mod.list = list(length_of_icu_stay = 
                        expression(daysDiff(surgery_date, date_icu_dc))))

head(demo.out$demo)
demo.out$exclude
```

# Pro-Med-Str Part I: IV dose data

* This module processes structured medication data. Only Part I which handles IV dose data is described here. For processing structure e-prescription medication data, see [*Pro-Med-Str* - Part II](Pro-Med-Str-Part2.html).
* The IV dose data comes from two sources:
    + Flow data: patient flow sheets which at this institution record infusion rates and changes to all infusions for all inpatients outside of the operating room.
    + Medication Administration Records (MAR) data: This data record all bolus doses of medications and infusions administered in the operating room.
* The module is semi-interactive -- it generates several files to check potential data errors and get feedback from an investigator. If corrected information ('fix' files) are provided, the module should be re-run to incorporate the corrections. 
* **run_MedStrI()** is the function to process IV dose data.

```{r Pro-Med-Str1, collapse = TRUE}
ivdose.out <- run_MedStrI(
    mar.path=file.path(dataDir,"mar_mod_id.rds"),
    mar.columns = list(id='mod_id', datetime=c('Date','Time'), dose='med:dosage', drug='med:mDrug', given='med:given'),
    medGivenReq = TRUE,
    flow.path=file.path(dataDir,"flow_mod_id.rds"),
    flow.columns = list(id = 'mod_id', datetime = 'date.time', finalunits = 'Final.Units', 
                        unit = 'unit', rate = 'rate', weight = 'Final.Wt..kg.'),
    medchk.path=file.path(system.file("examples", "str_ex2", package="EHR"), sprintf('medChecked-%s.csv', drugname)),
    demo.list = NULL,
    demo.columns = list(),
    missing.wgt.path = NULL,
    wgt.columns = list(),
    check.path = checkDir,
    failflow_fn = 'FailFlow',
    failunit_fn = 'Unit',
    failnowgt_fn = 'NoWgt',
    infusion.unit = 'mcg/kg/hr',
    bolus.unit = 'mcg',
    bol.rate.thresh = Inf,
    rateunit = 'mcg/hr',
    ratewgtunit = 'mcg/kg/hr',
    weightunit = 'kg',
    drugname = drugname)

head(ivdose.out)
```

# Pro-Drug Level

* This module processes drug concentration data that can be merged with medication dose data and other types of data. 
* This module is semi-interactive -- it generates several files while processing in order to check missing data and potential data errors, and get feedback from an investigator. If corrected information ('fix' files) are provided, the module should be re-run to incorporate the corrections.
* **run_DrugLevel** is the function to process the drug concentration data.

```{r Pro-Drug-Level, collapse = TRUE}
conc.out <- run_DrugLevel(conc.path=file.path(dataDir,"conc_mod_id.rds"),
    conc.columns = list(id = 'mod_id', conc = 'conc.level', idvisit = 'mod_id_visit', samplinkid = 'mod_id_event'),
    conc.select=c('mod_id','mod_id_visit','samp','fentanyl_calc_conc'),
    conc.rename=c(fentanyl_calc_conc = 'conc.level', samp= 'event'),
    conc.mod.list=list(mod_id_event = expression(paste(mod_id_visit, event, sep = '_'))),
    samp.path=file.path(dataDir,"samp_mod_id.rds"),
    samp.columns = list(conclinkid = 'mod_id_event', datetime = 'Sample.Collection.Date.and.Time'),
    samp.mod.list=list(mod_id_event = expression(paste(mod_id_visit, samp, sep = '_'))),
    check.path=checkDir,
    failmiss_fn = 'MissingConcDate-',
    multsets_fn = 'multipleSetsConc-',
    faildup_fn = 'DuplicateConc-', 
    drugname=drugname,
    LLOQ=LLOQ,
    demo.list=demo.out,
    demo.columns = list(id = 'mod_id', idvisit = 'mod_id_visit'))
head(conc.out)
```

* The output provides a message that 3 rows are missing concentration date. The file 'failMissingConcDate-fent.csv' contains the 3 records with missing values for the `date.time` variable.

```{r faildate}
( fail.miss.conc.date <- read.csv(file.path(checkDir,"failMissingConcDate-fent.csv")) )
```

* We can correct the missing dates by providing an updated file called 'fixMissingConcDate-fent.csv' that contains the missing data.

```{r fixdate}
fail.miss.conc.date[,"datetime"] <- c("9/30/2016 09:32","10/1/2016 19:20","10/2/2016 02:04")
fail.miss.conc.date

write.csv(fail.miss.conc.date, file.path(checkDir,"fixMissingConcDate-fent.csv"))
```

* After providing the updated file, the same `run_DrugLevel()` function should be re-run. The output now contains an additional message below the first message saying "fixMissingConcDate-fent.csv read with failures replaced". The conc.out data.frame also contains 3 additional rows with the corrected data.

```{r Pro-Drug-Level-rerun, collapse = TRUE}
conc.out <- run_DrugLevel(conc.path=file.path(dataDir,"conc_mod_id.rds"),
    conc.columns = list(id = 'mod_id', conc = 'conc.level', idvisit = 'mod_id_visit', samplinkid = 'mod_id_event'),
    conc.select=c('mod_id','mod_id_visit','samp','fentanyl_calc_conc'),
    conc.rename=c(fentanyl_calc_conc = 'conc.level', samp= 'event'),
    conc.mod.list=list(mod_id_event = expression(paste(mod_id_visit, event, sep = '_'))),
    samp.path=file.path(dataDir,"samp_mod_id.rds"),
    samp.columns = list(conclinkid = 'mod_id_event', datetime = 'Sample.Collection.Date.and.Time'),
    samp.mod.list=list(mod_id_event = expression(paste(mod_id_visit, samp, sep = '_'))),
    check.path=checkDir,
    failmiss_fn = 'MissingConcDate-',
    multsets_fn = 'multipleSetsConc-',
    faildup_fn = 'DuplicateConc-',
    drugname=drugname,
    LLOQ=LLOQ,
    demo.list=demo.out,
    demo.columns = list(id = 'mod_id', idvisit = 'mod_id_visit'))
```

```{r remove-fix, include=FALSE}
# remove fix file, so running vignette produces warning with first run of run_DrugLevel()
fx <- file.path(checkDir,"fixMissingConcDate-fent.csv")
if (file.exists(fx)) file.remove(fx)

# remove multiplesetsconc file
ms <- file.path(checkDir,paste0("multipleSetsConc-", drugname, Sys.Date(),".csv"))
if (file.exists(ms)) file.remove(ms)
```

# Pro-Laboratory

* This module processes laboratory data that can be merged with data from other modules.
* **run_Labs()** is the function to process the laboratory data.

```{r Pro-Laboratory}
creat.out <- run_Labs(lab.path=file.path(dataDir,"creat_mod_id.rds"),
    lab.select = c('mod_id','date.time','creat'),
    lab.mod.list = list(date.time = expression(parse_dates(fixDates(paste(date, time))))))

alb.out <- run_Labs(lab.path=file.path(dataDir,"alb_mod_id.rds"),
    lab.select = c('mod_id','date.time','alb'),
    lab.mod.list = list(date.time = expression(parse_dates(fixDates(paste(date, time))))))

lab.out <- list(creat.out, alb.out)

str(lab.out)
```

# Build-PK-IV

* This module creates PK data for IV medications. 
* Both dose data in the format output from the *Pro-Med-Str1* module and concentration data in the format output from the *Pro-DrugLevel* module are required.
* Demographic data from the *Pro-Demographic* module and laboratory data from the *Pro-Laboratory* module are optional. 
* The module is semi-interactive -- it generates several files to check potential data errors, and get feedback from an investigator. If corrected information (‘fix’ files) are provided, the module should be re-run to incorporate the corrections.
* If `pk.vars` includes ‘date’, the output generates its original date-time to which the ‘time’ is mapped. Users can use `pk.vars` to include variables for demographics or labs that are already merged with the concentration dataset when they prefer to provide a single concentration data file (required). But a separate dose data file is still required.
* **run_Build_PK_IV()** is the function to build PK data with IV dosing data.

```{r Build-PK-IV, collapse = TRUE}
pk_dat <- run_Build_PK_IV(
    conc=conc.out,
    conc.columns = list(id = 'mod_id', datetime = 'date.time', druglevel = 'conc.level', 
                        idvisit = 'mod_id_visit'),
    dose=ivdose.out,
    dose.columns = list(id = 'mod_id', date = 'date.dose', infuseDatetime = 'infuse.time', 
                        infuseDose = 'infuse.dose', infuseTimeExact= 'infuse.time.real',
                        bolusDatetime = 'bolus.time', bolusDose = 'bolus.dose', 
                        gap = 'maxint', weight = 'weight'),
    demo.list = demo.out,
    demo.columns = list(id = 'mod_id', idvisit = 'mod_id_visit'),
    lab.list = lab.out,
    lab.columns = list(id = 'mod_id', datetime = 'date.time'),
    pk.vars=c('date'),
    drugname=drugname,
    check.path=checkDir,
    missdemo_fn='-missing-demo',
    faildupbol_fn='DuplicateBolus-',
    date.format="%m/%d/%y %H:%M:%S",
    date.tz="America/Chicago")
```

* **Retrieving the original IDs**: 
    + The function `pullRealId()` appends the original IDs -- `subject_id` and `subject_uid` to the data. 
    + The parameter `remove.mod.id=TRUE` can be used to also remove any module IDs -- `mod_id`, `mod_visit`, and `mod_id_visit`. 

```{r Build-PK-IV-out}
# convert id back to original IDs
pk_dat <- pullRealId(pk_dat, remove.mod.id=TRUE)

head(pk_dat)
```

# References  
1. Choi L, Beck C, McNeer E, Weeks HL, Williams ML, James NT, Niu X, Abou-Khalil BW, Birdwell KA, Roden DM, Stein CM. Development of a System for Post-marketing Population Pharmacokinetic and Pharmacodynamic Studies using Real-World Data from Electronic Health Records. Clinical Pharmacology & Therapeutics. 2020 Apr;107(4):934-43. doi: 10.1002/cpt.1787.
