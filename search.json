{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\nhttps://github.com/choileena\nhttps://github.com/choileena/EHR\nhttps://github.com/choileena/pkdata\nhttps://github.com/choileena/medExtractR\n\n\n\n",
      "last_modified": "2021-08-18T16:56:57-05:00"
    },
    {
      "path": "Build-PK-IV-comprehensive.html",
      "title": "Build-PK-IV - Comprehensive",
      "description": "This tutorial describes a comprehensive PK data building procedure for medications that are intravenously administered. There are two phases: data processing which standardizes and combines the input data (*Pro-Demographic*, *Pro-Med-Str*, *Pro-Drug Level*, *Pro-Laboratory*) and data building which creates the final PK data (*Build-PK-IV*).\n",
      "author": [
        {
          "name": "Nathan T. James",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nIntroduction\nPre-Processing for Raw Extracted Data\nPro-Demographic\nPro-Med-Str Part I: IV dose data\nPro-Drug Level\nPro-Laboratory\nBuild-PK-IV\n\nIntroduction\nThis tutorial describes four modules for processing data (Pro-Demographic, Pro-Med-Str, Pro-Drug Level, Pro-Laboratory) and one module for PK data building (Build-PK-IV) using data extracted from a structured database.\nTo begin we load the EHR package, the pkdata package, and the lubridate package.\n\n\n# load EHR package and dependencies\nlibrary(EHR)\nlibrary(pkdata)\nlibrary(lubridate)\n\n\n\nWe also define three directories: one for raw structured data, one containing files used for interactive checking, and one for processed data. The raw data includes a demographic file for use with the Pro-Demographic module (Demographics_DATA.csv); two files for the Pro-Drug Level module (SampleTimes_DATA.csv and SampleConcentration_DATA.csv); two dosing files for the Pro-Med-Str module (FLOW_DATA.csv and MAR_DATA.csv); and two lab files for use with the Pro-Laboratory module (Creatinine_DATA.csv and Albumin_DATA.csv).\n\n\n# define 3 directories\nrawDataDir <- system.file(\"examples\", \"str_ex2\", package=\"EHR\")\n\ntd <- tempdir()\ndir.create(file.path(td, 'checks'))\ncheckDir <- file.path(td, 'checks')\n\ndir.create(file.path(td, 'data'))\ndataDir <- file.path(td, 'data')\n\n# examine files in rawDataDir\ndir(rawDataDir)\n\n\n[1] \"Albumin_DATA.csv\"             \"Creatinine_DATA.csv\"         \n[3] \"Demographics_DATA.csv\"        \"e-rx_DATA.csv\"               \n[5] \"FLOW_DATA.csv\"                \"MAR_DATA.csv\"                \n[7] \"medChecked-fent.csv\"          \"SampleConcentration_DATA.csv\"\n[9] \"SampleTimes_DATA.csv\"        \n\nPre-Processing for Raw Extracted Data\nThe structured datasets must go through a pre-processing stage which creates new ID variables and datasets that can be used by the data processing modules. There are three main pre-processing steps: (1) read and clean raw data; (2) merge raw data to create new ID variables; (3) make new data for use with modules.\nEach raw dataset should contain a subject unique ID, a subject visit ID, or both ids. In this example the subject unique ID is called subject_uid and the subject visit ID is called subject_id. The subject visit ID is a combination of subject and visit/course – e.g., subject_id 14.0 is the first course for subject 14, subject_id 14.1 is the second course for subject 14, and so on. subject_uid is a unique ID that is the same for all subject records. The integer part of subject_id has a 1-to-1 correspondence with subject_uid – for this example, subject_uid 62734832 is associated with both subject_id 14.0 and subject_id 14.1. If there is only a single visit/course per subject only the subject unique ID is needed.\n(1) Read and clean raw data\nThe demographics data file contains ID variables subject_id and subject_uid, in addition to demographic variables such as gender, date of birth, height, weight, etc. The Demographics_DATA.csv file is read in using the readTransform() function.\n\n\n# demographics data\ndemo.in <- readTransform(file.path(rawDataDir, \"Demographics_DATA.csv\"))\nhead(demo.in)\n\n\n  subject_id subject_uid gender weight height surgery_date\n1       1106    34364670      0   5.14  59.18    6/28/2014\n2       1444    36792472      1   5.67  62.90    1/10/2016\n3       1465    36292449      0  23.67 118.02    3/19/2016\n4       1520    34161967      0  14.07  97.04    7/18/2016\n5       1524    37857374      1  23.40 102.80    7/23/2016\n6       1550    37826262      1   6.21  62.03     9/4/2016\n  ageatsurgery stat_sts cpb_sts in_hospital_mortality add_ecmo\n1          141        3     133                     0        0\n2          292        1      65                     0        0\n3         2591        2     357                     0        0\n4         1320        5      93                     0        0\n5         1561        3      87                     1        0\n6          208        1     203                     0        0\n  date_icu_dc time_fromor\n1    7/2/2014        1657\n2   1/12/2016        1325\n3   3/20/2016          NA\n4   7/19/2016        1745\n5   7/30/2016        1847\n6   9/11/2016        1210\n\nThe example concentration data consists of two files, SampleTimes_DATA.csv and SampleConcentration_DATA.csv containing the concentration sampling times and values, respectively. The function readTransform() can be used to read in the data, rename the variable Study.ID to subject_id and create a new variable called samp, which indexes the sample number, using the modify= argument.\n\n\nsamp.in <- readTransform(file.path(rawDataDir, \"SampleTimes_DATA.csv\"),\n    rename = c('Study.ID' = 'subject_id'),\n    modify = list(samp = expression(as.numeric(sub('Sample ', '', Event.Name)))))\nhead(samp.in)\n\n\n  subject_id Event.Name Sample.Collection.Date.and.Time samp\n1      466.1   Sample 1                  2/3/2017 10:46    1\n2      466.1   Sample 2                  2/4/2017 20:30    2\n3     1106.0   Sample 1                 6/28/2014 13:40    1\n4     1106.0   Sample 2                 6/29/2014 03:10    2\n5     1106.0   Sample 3                 6/30/2014 03:35    3\n6     1106.0   Sample 4                  7/1/2014 03:45    4\n\nThe function readTransform() is also used to read and transform the concentration values. We use the helper function sampId() to process the subject_id field.\n\n\n# helper function used to make subject_id\nsampId <- function(x) {\n  # remove leading zeroes or trailing periods\n  subid <- gsub('(^0*|\\\\.$)', '', x)\n  # change _ to .\n  gsub('_([0-9]+[_].*)$', '.\\\\1', subid)\n}\n\nconc.in <- readTransform(file.path(rawDataDir, \"SampleConcentration_DATA.csv\"),\n  modify = list(\n    subid = expression(sampId(name)),\n    subject_id = expression(as.numeric(sub('[_].*', '', subid))),\n    samp = expression(sub('[^_]*[_]', '', subid)),\n    name = NULL,\n    data_file = NULL,\n    subid = NULL\n    )\n  )\nhead(conc.in)\n\n\n  record_id fentanyl_calc_conc subject_id samp\n1         1         0.01413622      466.1    1\n2         2         0.27982075      466.1    2\n3         3         6.11873679     1106.0    1\n4         4         0.59161716     1106.0    2\n5         5         0.11280471     1106.0    3\n6         6         0.02112153     1106.0    4\n\nThe example drug dosing data consists of files FLOW_DATA.csv and MAR_DATA.csv containing two sources of IV dose information. The FLOW data csv file contains aliases for both ID variables; it is read in with the readTransform() function which renames the variables Subject.Id to subject_id and Subject.Uniq.Id to subject_uid.\n\n\n# FLOW dosing data\nflow.in <- readTransform(file.path(rawDataDir, \"FLOW_DATA.csv\"),\n                         rename = c('Subject.Id' = 'subject_id',\n                                    'Subject.Uniq.Id' = 'subject_uid')) \nhead(flow.in)\n\n\n  subject_id subject_uid     Perform.Date FOCUS_MEDNAME Final.Wt..kg.\n1       1596    38340814   12/4/2016 5:30      Fentanyl          6.75\n2       1596    38340814   12/4/2016 6:00      Fentanyl          6.75\n3       1596    38340814   12/4/2016 7:00      Fentanyl          6.75\n4       1596    38340814   12/4/2016 7:40      Fentanyl          6.75\n5       1607    38551767 12/24/2016 19:30      Fentanyl          2.60\n6       1607    38551767 12/24/2016 20:00      Fentanyl          2.60\n  Final.Rate..NFR.units. Final.Units Flow\n1            1 mcg/kg/hr       3.375   NA\n2            1 mcg/kg/hr       6.750  0.1\n3            1 mcg/kg/hr       4.500  0.1\n4            0 mcg/kg/hr       0.000   NA\n5            2 mcg/kg/hr       2.600   NA\n6            2 mcg/kg/hr       5.200  0.2\n\nThe MAR data csv file contains several variables with a colon (:) character. To preserve the colon in these variable names, the data can be read in without checking for syntactically valid R variable names. The data is read in using read.csv() with the argument check.names = FALSE and then passed to the dataTransformation() function which renames Uniq.Id to subject_uid.\n\n\n# MAR dosing data\nmar.in0 <- read.csv(file.path(rawDataDir, \"MAR_DATA.csv\"), check.names = FALSE)\nmar.in <- dataTransformation(mar.in0, rename = c('Uniq.Id' = 'subject_uid'))\nhead(mar.in)\n\n\n  subject_uid       Date  Time                 med:mDrug   med:dosage\n1    28579217 2017-02-04 19:15               Nicardipine 3 mcg/kg/min\n2    28579217 2011-10-02 22:11                Famotidine       4.5 mg\n3    28579217 2011-10-02 20:17          Morphine sulfate         1 mg\n4    28579217 2011-10-03 02:28 Diphenhydramine injection        12 mg\n5    28579217 2011-10-02 22:11                 Cefazolin       225 mg\n6    28579217 2011-10-02 23:30          Morphine sulfate         1 mg\n  med:route med:freq med:given\n1        IV     <NA>     Given\n2        IV   q12hrs     Given\n3        IV  q2h prn     Given\n4        IV      now     Given\n5        IV    q8hrs     Given\n6        IV  q2h prn     Given\n\nThe example laboratory data consists of files Creatinine_DATA.csv and Albumin_DATA.csv. Both files are read in using the readTransform() function and Subject.uniq is renamed to subject_uid.\n\n\n# Serum creatinine lab data\ncreat.in <- readTransform(file.path(rawDataDir, \"Creatinine_DATA.csv\"),\n    rename = c('Subject.uniq' = 'subject_uid'))\nhead(creat.in)\n\n\n  subject_uid     date time creat\n1    28579217 02/05/17 4:00  0.52\n2    28579217 02/06/17 5:00  0.53\n3    28579217 10/03/11 4:28  0.42\n4    28579217 10/04/11 4:15  0.35\n5    28579217 10/06/11 4:25  0.29\n6    28579217 10/09/11 4:45  0.28\n\n# Albumin lab data\nalb.in <- readTransform(file.path(rawDataDir, \"Albumin_DATA.csv\"),\n    rename = c('Subject.uniq' = 'subject_uid'))\nhead(creat.in)\n\n\n  subject_uid     date time creat\n1    28579217 02/05/17 4:00  0.52\n2    28579217 02/06/17 5:00  0.53\n3    28579217 10/03/11 4:28  0.42\n4    28579217 10/04/11 4:15  0.35\n5    28579217 10/06/11 4:25  0.29\n6    28579217 10/09/11 4:45  0.28\n\n(2) Merge data to create new ID variables\nThe function idCrosswalk() merges all of the cleaned input datasets and creates new IDs. The data= argument of this function accepts a list of input datasets and the idcols= argument accepts a list of vectors or character strings that identify the ID variables in the corresponding input dataset.\nThe output of idCrosswalk() is a crosswalk dataset between the original ID variables (subject_id, subject_uid) and the new ID variables (mod_id, mod_visit, and mod_id_visit). The new variable mod_id_visit has a 1-to-1 correspondence to variable subject_id and uniquely identifies each subjects’ visit/course; the new variable mod_id has a 1-to-1 correspondence to variable subject_uid and uniquely identifies each subject.\n\n\n# merge all ID datasets\ndata <-  list(demo.in,\n              samp.in,\n              conc.in,\n              flow.in,\n              mar.in,\n              creat.in,\n              alb.in)\n\nidcols <-  list(c('subject_id', 'subject_uid'), # id vars in demo.in\n                'subject_id', # id var in samp.in\n                'subject_id', # id var in conc.in\n                c('subject_id', 'subject_uid'), # id vars in flow.in\n                'subject_uid', # id var in mar.in\n                'subject_uid', # id var in creat.in\n                'subject_uid') # id var in creat.in\n\nid.xwalk <- idCrosswalk(data, idcols, visit.id=\"subject_id\", uniq.id=\"subject_uid\")\nsaveRDS(id.xwalk, file=file.path(dataDir,\"module_id_xwalk.rds\"))\n\nid.xwalk\n\n\n   subject_id subject_uid mod_visit mod_id mod_id_visit\n1       466.0    28579217         1      1          1.1\n2       466.1    28579217         2      1          1.2\n3      1106.0    34364670         1      2          2.1\n4      1444.0    36792472         1      3          3.1\n5      1465.0    36292449         1      4          4.1\n6      1520.0    34161967         1      5          5.1\n7      1524.0    37857374         1      6          6.1\n8      1550.0    37826262         1      7          7.1\n9      1566.0    35885929         1      8          8.1\n10     1566.1    35885929         2      8          8.2\n11     1596.0    38340814         1      9          9.1\n12     1607.0    38551767         1     10         10.1\n13     1607.1    38551767         2     10         10.2\n14     1724.0    39087607         1     11         11.1\n15     1770.0    39418554         1     12         12.1\n16     1770.1    39418554         2     12         12.2\n17     2157.0    42023523         1     13         13.1\n18     2162.0    42044808         1     14         14.1\n19     2164.0    41221120         1     15         15.1\n\n(3) Make new data for use with modules\nThe function pullFakeId() replaces the original IDs – subject_id and subject_uid – with new IDs – mod_id, mod_visit, and mod_id_visit – to create datasets which can be used by the data processing modules. Generally, the function call to pullFakeId() is\n\n\npullFakeId(dat, xwalk, firstCols = NULL, orderBy = NULL)\n\n\n\nThe dat= argument should contain the cleaned input data.frame from pre-processing step (1) and the xwalk= argument should contain the crosswalk data.frame produced in step (2). Additional arguments firstCols= and orderBy= control which variables are in the first columns of the output and the sort order, respectively. The cleaned structured data are saved as R objects for use with the modules.\n\n\n## demographics data\ndemo.cln <- pullFakeId(demo.in, id.xwalk,\n    firstCols = c('mod_id', 'mod_visit', 'mod_id_visit'),\n    uniq.id = 'subject_uid')\nhead(demo.cln)\n\n\n  mod_id mod_visit mod_id_visit gender weight height surgery_date\n1      2         1          2.1      0   5.14  59.18    6/28/2014\n2      3         1          3.1      1   5.67  62.90    1/10/2016\n3      4         1          4.1      0  23.67 118.02    3/19/2016\n4      5         1          5.1      0  14.07  97.04    7/18/2016\n5      6         1          6.1      1  23.40 102.80    7/23/2016\n6      7         1          7.1      1   6.21  62.03     9/4/2016\n  ageatsurgery stat_sts cpb_sts in_hospital_mortality add_ecmo\n1          141        3     133                     0        0\n2          292        1      65                     0        0\n3         2591        2     357                     0        0\n4         1320        5      93                     0        0\n5         1561        3      87                     1        0\n6          208        1     203                     0        0\n  date_icu_dc time_fromor\n1    7/2/2014        1657\n2   1/12/2016        1325\n3   3/20/2016          NA\n4   7/19/2016        1745\n5   7/30/2016        1847\n6   9/11/2016        1210\n\nsaveRDS(demo.cln, file=file.path(dataDir,\"demo_mod_id.rds\"))\n\n## drug level data\n# sampling times\nsamp.cln <- pullFakeId(samp.in, id.xwalk,\n    firstCols = c('mod_id', 'mod_visit', 'mod_id_visit', 'samp'), \n    orderBy = c('mod_id_visit','samp'),\n    uniq.id = 'subject_uid')\nhead(samp.cln)\n\n\n  mod_id mod_visit mod_id_visit samp Event.Name\n1      1         2          1.2    1   Sample 1\n2      1         2          1.2    2   Sample 2\n3     10         1         10.1    1   Sample 1\n4     10         1         10.1    2   Sample 2\n5     10         1         10.1    3   Sample 3\n6     10         1         10.1    4   Sample 4\n  Sample.Collection.Date.and.Time\n1                  2/3/2017 10:46\n2                  2/4/2017 20:30\n3                12/23/2016 05:15\n4                12/24/2016 18:00\n5                12/25/2016 03:00\n6                12/26/2016 04:00\n\nsaveRDS(samp.cln, file=file.path(dataDir,\"samp_mod_id.rds\"))\n\n# sampling concentrations\nconc.cln <- pullFakeId(conc.in, id.xwalk,\n    firstCols = c('record_id', 'mod_id', 'mod_visit', 'mod_id_visit', 'samp'),\n    orderBy = 'record_id',\n    uniq.id = 'subject_uid')\nhead(conc.cln)\n\n\n  record_id mod_id mod_visit mod_id_visit samp fentanyl_calc_conc\n1         1      1         2          1.2    1         0.01413622\n2         2      1         2          1.2    2         0.27982075\n3         3      2         1          2.1    1         6.11873679\n4         4      2         1          2.1    2         0.59161716\n5         5      2         1          2.1    3         0.11280471\n6         6      2         1          2.1    4         0.02112153\n\nsaveRDS(conc.cln, file=file.path(dataDir,\"conc_mod_id.rds\"))\n\n## dosing data\n# flow\nflow.cln <- pullFakeId(flow.in, id.xwalk,\n    firstCols = c('mod_id', 'mod_visit', 'mod_id_visit'),\n    uniq.id = 'subject_uid')\nhead(flow.cln)\n\n\n  mod_id mod_visit mod_id_visit     Perform.Date FOCUS_MEDNAME\n1      9         1          9.1   12/4/2016 5:30      Fentanyl\n2      9         1          9.1   12/4/2016 6:00      Fentanyl\n3      9         1          9.1   12/4/2016 7:00      Fentanyl\n4      9         1          9.1   12/4/2016 7:40      Fentanyl\n5     10         1         10.1 12/24/2016 19:30      Fentanyl\n6     10         1         10.1 12/24/2016 20:00      Fentanyl\n  Final.Wt..kg. Final.Rate..NFR.units. Final.Units Flow\n1          6.75            1 mcg/kg/hr       3.375   NA\n2          6.75            1 mcg/kg/hr       6.750  0.1\n3          6.75            1 mcg/kg/hr       4.500  0.1\n4          6.75            0 mcg/kg/hr       0.000   NA\n5          2.60            2 mcg/kg/hr       2.600   NA\n6          2.60            2 mcg/kg/hr       5.200  0.2\n\nsaveRDS(flow.cln, file=file.path(dataDir,\"flow_mod_id.rds\"))\n\n# mar\nmar.cln <- pullFakeId(mar.in, id.xwalk, firstCols = 'mod_id', uniq.id = 'subject_uid')\nhead(mar.cln)\n\n\n  mod_id       Date  Time                 med:mDrug   med:dosage\n1      1 2017-02-04 19:15               Nicardipine 3 mcg/kg/min\n2      1 2011-10-02 22:11                Famotidine       4.5 mg\n3      1 2011-10-02 20:17          Morphine sulfate         1 mg\n4      1 2011-10-03 02:28 Diphenhydramine injection        12 mg\n5      1 2011-10-02 22:11                 Cefazolin       225 mg\n6      1 2011-10-02 23:30          Morphine sulfate         1 mg\n  med:route med:freq med:given\n1        IV     <NA>     Given\n2        IV   q12hrs     Given\n3        IV  q2h prn     Given\n4        IV      now     Given\n5        IV    q8hrs     Given\n6        IV  q2h prn     Given\n\nsaveRDS(mar.cln, file=file.path(dataDir,\"mar_mod_id.rds\"))\n\n## laboratory data\ncreat.cln <- pullFakeId(creat.in, id.xwalk, 'mod_id',uniq.id = 'subject_uid')\nhead(creat.cln)\n\n\n  mod_id     date time creat\n1      1 02/05/17 4:00  0.52\n2      1 02/06/17 5:00  0.53\n3      1 10/03/11 4:28  0.42\n4      1 10/04/11 4:15  0.35\n5      1 10/06/11 4:25  0.29\n6      1 10/09/11 4:45  0.28\n\nalb.cln <- pullFakeId(alb.in, id.xwalk, 'mod_id', uniq.id = 'subject_uid')\nhead(alb.cln)\n\n\n  mod_id     date  time alb\n1      8 07/30/20  5:23 2.9\n2      8 07/28/20  3:12 2.0\n3      8 07/29/20  1:39 2.7\n4      8 08/21/20 10:35 4.1\n5      4 06/13/15 17:20 4.1\n6      6 07/25/16  8:35 2.3\n\nsaveRDS(creat.cln, file=file.path(dataDir,\"creat_mod_id.rds\"))\nsaveRDS(alb.cln, file=file.path(dataDir,\"alb_mod_id.rds\"))\n\n\n\nBefore running the processing modules, it is necessary to define several options and parameters. Using options(pkxwalk =) allows the modules to access the crosswalk file. We also create a drugname stub and define the lower limit of quantification (LLOQ) for the drug of interest.\n\n\n# set crosswalk option \nxwalk <- readRDS(file.path(dataDir, \"module_id_xwalk.rds\"))\noptions(pkxwalk = 'xwalk')\n\n# define parameters\ndrugname <- 'fent'\nLLOQ <- 0.05\n\n\n\nPro-Demographic\nThe Pro-Demographic module accepts the cleaned structured demographic dataset and a user-defined set of exclusion criteria and returns a formatted list with the demographic data and records meeting the exclusion criteria suitable for integration with the other modules. For this example, we exclude subjects with a value of 1 for in_hospital_mortality or add_ecmo and create a new variable called length_of_icu_stay.\nThe demographic data can be processed by the run_Demo() function using:\n\n\n# helper function\nexclude_val <- function(x, val=1) { !is.na(x) & x == val }\n\ndemo.out <- run_Demo(demo.path = file.path(dataDir, \"demo_mod_id.rds\"),\n    toexclude = expression(exclude_val(in_hospital_mortality) | exclude_val(add_ecmo)),\n    demo.mod.list = list(length_of_icu_stay = \n                        expression(daysDiff(surgery_date, date_icu_dc))))\n\n\nThe number of subjects in the demographic data, who meet the exclusion criteria: 2\n\nhead(demo.out$demo)\n\n\n  mod_id mod_visit mod_id_visit gender weight height surgery_date\n1      2         1          2.1      0   5.14  59.18    6/28/2014\n2      3         1          3.1      1   5.67  62.90    1/10/2016\n3      4         1          4.1      0  23.67 118.02    3/19/2016\n4      5         1          5.1      0  14.07  97.04    7/18/2016\n5      6         1          6.1      1  23.40 102.80    7/23/2016\n6      7         1          7.1      1   6.21  62.03     9/4/2016\n  ageatsurgery stat_sts cpb_sts in_hospital_mortality add_ecmo\n1          141        3     133                     0        0\n2          292        1      65                     0        0\n3         2591        2     357                     0        0\n4         1320        5      93                     0        0\n5         1561        3      87                     1        0\n6          208        1     203                     0        0\n  date_icu_dc time_fromor length_of_icu_stay\n1    7/2/2014        1657                  4\n2   1/12/2016        1325                  2\n3   3/20/2016          NA                  1\n4   7/19/2016        1745                  1\n5   7/30/2016        1847                  7\n6   9/11/2016        1210                  7\n\ndemo.out$exclude\n\n\n[1] \"6.1\"  \"13.1\"\n\nPro-Med-Str Part I: IV dose data\nThe Pro-Med-Str module processes structured medication data. Only Part I which handles IV dose data is described here.\nThe IV dose data comes from two sources, Flow data and Medication Administration Records (MAR) data. The Flow data are patient flow sheets which at this institution record infusion rates and changes to all infusions for all inpatients outside of the operating room. The MAR data record all bolus doses of medications and infusions administered in the operating room. The module is semi-interactive; it generates several files to check potential data errors and get feedback from an investigator. If corrected information (‘fix’ files) are provided, the module should be re-run to incorporate the corrections. The IV dose data can be processed by the run_MedStrI() function using:\n\n\nivdose.out <- run_MedStrI(flow.path=file.path(dataDir,\"flow_mod_id.rds\"), \n    flow.select = c('mod_id','mod_id_visit','Perform.Date','Final.Wt..kg.',\n                    'Final.Rate..NFR.units.','Final.Units'),\n    flow.rename = c('mod_id','mod_id_visit', 'Perform.Date', 'weight',\n                    'rate', 'final.units'),\n    flow.mod.list = list(\n      date.time = expression(parse_dates(fixDates(Perform.Date))),\n      unit = expression(sub('.*[ ]', '', rate)),\n      rate = expression(as.numeric(sub('([0-9.]+).*', '\\\\1', rate)))),\n    medchk.path=file.path(rawDataDir, sprintf('medChecked-%s.csv', drugname)), \n    mar.path=file.path(dataDir,\"mar_mod_id.rds\"),\n    demo.list=NULL,\n    check.path=checkDir, \n    failflow_fn = 'FailFlow',\n    failunit_fn = 'Unit',\n    failnowgt_fn = 'NoWgt',\n    infusion.unit = 'mcg/kg/hr',\n    bolus.unit = 'mcg',\n    bol.rate.thresh = Inf,\n    drugname = drugname)\n\n\nThe number of rows in the original data                124\nThe number of rows after removing the duplicates       124\nno units other than mcg/kg/hr or mcg, file /tmp/Rtmpabzp3x/checks/failUnit-fent.csv not created\n#########################\n33 rows from 1 subjects with \"kg\" in infusion unit but missing weight, see file /tmp/Rtmpabzp3x/checks/failNoWgt-fent.csv AND create /tmp/Rtmpabzp3x/checks/fixNoWgt-fent.csv\n#########################\n\nhead(ivdose.out)\n\n\n  mod_id  date.dose infuse.time.real infuse.time infuse.dose\n1      1 2011-10-02             <NA>        <NA>          NA\n2      1 2011-10-02             <NA>        <NA>          NA\n3      1 2017-02-04             <NA>        <NA>          NA\n4      1 2017-02-04             <NA>        <NA>          NA\n5      1 2017-02-04             <NA>        <NA>          NA\n6      2 2014-06-28             <NA>        <NA>          NA\n           bolus.time bolus.dose given.dose maxint weight\n1 2011-10-02 15:35:00         25         NA      0     NA\n2 2011-10-02 17:26:00         25         NA      0     NA\n3 2017-02-04 16:15:00         50         NA      0     NA\n4 2017-02-04 16:30:00         20         NA      0     NA\n5 2017-02-04 20:57:00         20         NA      0     NA\n6 2014-06-28 08:15:00         20         NA      0     NA\n\nPro-Drug Level\nPro-Drug Level module processes drug concentration data that can be merged with medication dose data and other types of data. This module is semi-interactive; it generates several files while processing in order to check missing data and potential data errors, and get feedback from an investigator. If corrected information (‘fix’ files) are provided, the module should be re-run to incorporate the corrections. The drug concentration data can be processed by the run_DrugLevel function using:\n\n\nconc.out <- run_DrugLevel(conc.path=file.path(dataDir,\"conc_mod_id.rds\"),\n    conc.select=c('mod_id','mod_id_visit','samp','fentanyl_calc_conc'),\n    conc.rename=c(fentanyl_calc_conc = 'conc.level', samp= 'event'),\n    conc.mod.list=list(mod_id_event = expression(paste(mod_id_visit, event, sep = '_'))),\n    samp.path=file.path(dataDir,\"samp_mod_id.rds\"),\n    samp.mod.list=list(mod_id_event = expression(paste(mod_id_visit, samp, sep = '_'))),\n    check.path=checkDir,\n    failmiss_fn = 'MissingConcDate-',\n    multsets_fn = 'multipleSetsConc-',\n    faildup_fn = 'DuplicateConc-',\n    drugname=drugname,\n    LLOQ=LLOQ,\n    demo.list=demo.out)\n\n\n#########################\n3 rows need review, see file /tmp/Rtmpabzp3x/checks/failMissingConcDate-fent.csv AND create /tmp/Rtmpabzp3x/checks/fixMissingConcDate-fent.csv\n#########################\nsubjects with concentration missing from sample file\n mod_id mod_id_event\n      8        8.1_1\n      8        8.1_2\n      8        8.1_3\n1 subjects have multiple sets of concentration data\n16 total unique subjects ids (including multiple visits) currently in the concentration data\n15 total unique subjects in the concentration data\n#########################\n15 rows need review, see file /tmp/Rtmpabzp3x/checks/multipleSetsConc-fent2021-08-18.csv\n#########################\n15 total unique subjects ids (after excluding multiple visits) in the concentration data\n15 total unique subjects in the concentration data\n\nhead(conc.out)\n\n\n   mod_id mod_id_visit event  conc.level mod_id_event\n1       1          1.2     1 0.014136220        1.2_1\n2       1          1.2     2 0.279820752        1.2_2\n55     10         10.1     2 3.136047304       10.1_2\n56     10         10.1     9 0.004720171       10.1_9\n57     10         10.1    10 0.017136367      10.1_10\n58     10         10.1    12 0.006335571      10.1_12\n             date.time eid\n1  2017-02-03 10:46:00   1\n2  2017-02-04 20:30:00   1\n55 2016-12-24 18:00:00   1\n56 2017-01-01 04:20:00   1\n57 2017-01-02 04:42:00   1\n58 2017-01-04 03:40:00   1\n\nThe output provides a message that 3 rows are missing concentration date. The file ‘failMissingConcDate-fent.csv’ contains the 3 records with missing values for the date.time variable.\n\n\n( fail.miss.conc.date <- read.csv(file.path(checkDir,\"failMissingConcDate-fent.csv\")) )\n\n\n  subject_id subject_uid mod_id_event date.time\n1       1566    35885929        8.1_1        NA\n2       1566    35885929        8.1_2        NA\n3       1566    35885929        8.1_3        NA\n\nWe can correct the missing dates by providing an updated file called ‘fixMissingConcDate-fent.csv’ that contains the missing data.\n\n\nfail.miss.conc.date[,\"date.time\"] <- c(\"9/30/2016 09:32\",\"10/1/2016 19:20\",\"10/2/2016 02:04\")\nfail.miss.conc.date\n\n\n  subject_id subject_uid mod_id_event       date.time\n1       1566    35885929        8.1_1 9/30/2016 09:32\n2       1566    35885929        8.1_2 10/1/2016 19:20\n3       1566    35885929        8.1_3 10/2/2016 02:04\n\nwrite.csv(fail.miss.conc.date, file.path(checkDir,\"fixMissingConcDate-fent.csv\"))\n\n\n\nAfter providing the updated file, the same run_DrugLevel() function should be re-run. The output now contains an additional message below the first message saying “fixMissingConcDate-fent.csv read with failures replaced”. The conc.out data.frame also contains 3 additional rows with the corrected data.\n\n\nconc.out <- run_DrugLevel(conc.path=file.path(dataDir,\"conc_mod_id.rds\"),\n    conc.select=c('mod_id','mod_id_visit','samp','fentanyl_calc_conc'),\n    conc.rename=c(fentanyl_calc_conc = 'conc.level', samp= 'event'),\n    conc.mod.list=list(mod_id_event = expression(paste(mod_id_visit, event, sep = '_'))),\n    samp.path=file.path(dataDir,\"samp_mod_id.rds\"),\n    samp.mod.list=list(mod_id_event = expression(paste(mod_id_visit, samp, sep = '_'))),\n    check.path=checkDir,\n    failmiss_fn = 'MissingConcDate-',\n    multsets_fn = 'multipleSetsConc-',\n    faildup_fn = 'DuplicateConc-', \n    drugname=drugname,\n    LLOQ=LLOQ,\n    demo.list=demo.out)\n\n\n#########################\n3 rows need review, see file /tmp/Rtmpabzp3x/checks/failMissingConcDate-fent.csv AND create /tmp/Rtmpabzp3x/checks/fixMissingConcDate-fent.csv\n#########################\nfile /tmp/Rtmpabzp3x/checks/fixMissingConcDate-fent.csv read with failures replaced\nsubjects with concentration missing from sample file\n[1] mod_id       mod_id_event\n<0 rows> (or 0-length row.names)\n1 subjects have multiple sets of concentration data\n16 total unique subjects ids (including multiple visits) currently in the concentration data\n15 total unique subjects in the concentration data\n#########################\n15 rows need review, see file /tmp/Rtmpabzp3x/checks/multipleSetsConc-fent2021-08-18.csv\n#########################\n15 total unique subjects ids (after excluding multiple visits) in the concentration data\n15 total unique subjects in the concentration data\n\nPro-Laboratory\nThe Pro-Laboratory module processes laboratory data that can be merged with data from other modules. The laboratory data can be processed using:\n\n\ncreat.out <- run_Labs(lab.path=file.path(dataDir,\"creat_mod_id.rds\"),\n    lab.select = c('mod_id','date.time','creat'),\n    lab.mod.list = list(date.time = expression(parse_dates(fixDates(paste(date, time))))))\n\nalb.out <- run_Labs(lab.path=file.path(dataDir,\"alb_mod_id.rds\"),\n    lab.select = c('mod_id','date.time','alb'),\n    lab.mod.list = list(date.time = expression(parse_dates(fixDates(paste(date, time))))))\n\nlab.out <- list(creat.out, alb.out)\n\nstr(lab.out)\n\n\nList of 2\n $ :'data.frame':   266 obs. of  3 variables:\n  ..$ mod_id   : int [1:266] 1 1 1 1 1 1 1 1 1 1 ...\n  ..$ date.time: POSIXct[1:266], format: \"2017-02-05 04:00:00\" ...\n  ..$ creat    : num [1:266] 0.52 0.53 0.42 0.35 0.29 0.28 0.34 0.59 0.54 0.26 ...\n $ :'data.frame':   44 obs. of  3 variables:\n  ..$ mod_id   : int [1:44] 8 8 8 8 4 6 6 9 10 10 ...\n  ..$ date.time: POSIXct[1:44], format: \"2020-07-30 05:23:00\" ...\n  ..$ alb      : num [1:44] 2.9 2 2.7 4.1 4.1 2.3 2.6 3 3.1 4.2 ...\n\nBuild-PK-IV\nThe Build-PK-IV module creates PK data for IV medications. Both dose data from the Pro-Med-Str1 module and concentration data from the Pro-DrugLevel module are required. Demographic data from the Pro-Demographic module and laboratory data from the Pro-Laboratory module are optional. The module is semi-interactive; it generates several files to check potential data errors, and get feedback from an investigator. If corrected information (‘fix’ files) are provided, the module should be re-run to incorporate the corrections. PK data with IV dosing can be built by the run_Build_PK_IV function using:\n\n\npk_dat <- run_Build_PK_IV(conc=conc.out,\n    dose=ivdose.out,\n    demo.list=demo.out,\n    demo.vars=c('weight', 'weight_demo', 'height', 'gender',\n                'ageatsurgery', 'stat_sts', 'cpb_sts',\n                'length_of_icu_stay'),\n    demo.abbr=c('wgt', 'wgt_demo', 'height', 'gender',\n                'age', 'stat', 'cpb', 'loi'),\n    lab.dat = lab.out,\n    lab.vars = c('creat','alb'),\n    pk.vars=c('mod_id_visit', 'time', 'conc', 'dose', 'rate', 'event',\n              'other', 'multiple.record', 'date', 'mod_id'),\n    drugname=drugname,\n    check.path=checkDir,\n    missdemo_fn='-missing-demo',\n    faildupbol_fn='DuplicateBolus-',\n    date.format=\"%m/%d/%y %H:%M:%S\",\n    date.tz=\"America/Chicago\")\n\n\n0 duplicated rows\nThe dimension of the PK data before merging with demographics: 234 x 9\nThe number of subjects in the PK data before merging with demographics: 15\nThe number of subjects in the demographic file, who meet the exclusion criteria: 2\ncheck NA frequency in demographics, see file /tmp/Rtmpabzp3x/checks/fent-missing-demo.csv\nList of IDs missing at least 1 cpb_sts: 12.1\nThe list of final demographic variables: weight\nweight_demo\nheight\ngender\nageatsurgery\nstat_sts\ncpb_sts\nlength_of_icu_stay\nChecked: there are no missing creat\nList of IDs missing at least 1 alb: 1.2\n11.1\n15.1\n2.1\n3.1\n4.1\n5.1\n7.1\n8.1\nThe dimension of the final PK data exported with the key demographics: 197 x 17 with 13 distinct subjects (mod_id_visit)\n\nThe function pullRealId() appends the original IDs – subject_id and subject_uid to the data. The parameter remove.mod.id=TRUE can be used to also remove any module IDs – mod_id, mod_visit, and mod_id_visit.\n\n\n# convert id back to original IDs\npk_dat <- pullRealId(pk_dat, remove.mod.id=TRUE)\n\nhead(pk_dat)\n\n\n     subject_id subject_uid time      conc   amt rate mdv evid   wgt\n2         466.1    28579217 0.00        NA  50.0  0.0   1    1 21.99\n2.1       466.1    28579217 0.25        NA  20.0  0.0   1    1 21.99\n2.2       466.1    28579217 4.25 0.2798208    NA   NA   0    0 21.99\n12       1607.0    38551767 0.00        NA 109.2 10.4   1    1  2.60\n12.1     1607.0    38551767 0.00        NA  10.0  0.0   1    1  2.60\n12.2     1607.0    38551767 1.25        NA  15.0  0.0   1    1  2.60\n     wgt_demo height gender  age stat cpb loi creat alb\n2       21.99 116.90      0 2451    1 107   1  0.54  NA\n2.1     21.99 116.90      0 2451    1 107   1  0.54  NA\n2.2     21.99 116.90      0 2451    1 107   1  0.54  NA\n12       2.76  45.94      0   23    3 110  12  0.66 1.6\n12.1     2.76  45.94      0   23    3 110  12  0.66 1.6\n12.2     2.76  45.94      0   23    3 110  12  0.66 1.6\n\nReferences\nChoi L, Beck C, McNeer E, Weeks HL, Williams ML, James NT, Niu X, Abou-Khalil BW, Birdwell KA, Roden DM, Stein CM. Development of a System for Post-marketing Population Pharmacokinetic and Pharmacodynamic Studies using Real-World Data from Electronic Health Records. Clinical Pharmacology & Therapeutics. 2020 Apr; 107(4): 934-943.\n\n\n\n",
      "last_modified": "2021-08-18T16:56:59-05:00"
    },
    {
      "path": "Build-PK-IV-simple.html",
      "title": "Build-PK-IV - Simple",
      "description": "This lecture describes a simple pharmacokinetic data building procedure without using additional data processing modules for medications that are intravenously administered.\n",
      "author": [
        {
          "name": "Nathan T. James, Leena Choi",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nIntroduction\nQuick Data Building with Processed Datasets\n\nIntroduction\nThis lecture describes a simple pharmacokinetic (PK) data building procedure in EHRtoPKPD for medications that are intravenously (IV) administered. It demonstrates how to quickly build PK data using Build-PK-IV when cleaned data for concentration, drug dose, demographic and laboratory datasets are available in the appropriate data format. A comprehensive PK data building procedure with Build-PK-IV for IV medications that requires several data processing modules is described in Build-PK-IV - Comprehensive (see Choi et al.\\(^{1}\\) for details).\nTo begin we load the EHR package, the pkdata package, and the lubridate package.\n\n\n# load EHR package and dependencies\nlibrary(EHR)\nlibrary(pkdata)\nlibrary(lubridate)\n\n\n\nQuick Data Building with Processed Datasets\nWe first define a directory for the raw data and a directory for interactive checking output files. The data includes a demographic file, a drug concentration file, an IV dosing file, and a laboratory file, which are all cleaned and formatted appropriately.\n\n\n# define directories\nrawDataDir <- system.file(\"examples\", \"str_ex1\", package=\"EHR\")\ntd <- tempdir()\ndir.create(file.path(td, 'check1'))\ncheckDir <- file.path(td, 'check1')\n\n# read in data\ndemo <- read.csv(file.path(rawDataDir,\"Demographics_DATA_simple.csv\"),stringsAsFactors = FALSE)\nhead(demo)\n\n\n  patient_id patient_visit_id gender weight height surgery_date\n1          2              2.1      1  62.99 179.72    6/20/2015\n2          3              3.1      0   7.71  72.99   12/15/2018\n3          4              4.1      1  12.00  92.02    1/12/2018\n4          5              5.1      0   5.89  56.13    5/13/2018\n5          6              6.2      1   7.90  63.31    9/24/2018\n6          6              6.1      1   6.16  60.89    5/26/2018\n  ageatsurgery stat_sts cpb_sts date_icu_dc time_fromor\n1         6245        2      80   6/22/2015          NA\n2          574        3      67  12/16/2018          NA\n3         1214        1      70   1/13/2018          NA\n4          102        1     151   5/14/2018        1427\n5          343        2      50   10/6/2018          NA\n6          222        4      99   8/13/2018        1958\n  length_of_icu_stay\n1                  2\n2                  1\n3                  1\n4                  1\n5                 12\n6                 79\n\nconc.data <- read.csv(file.path(rawDataDir,\"Concentration_DATA_simple.csv\"),stringsAsFactors = FALSE)\nhead(conc.data)\n\n\n  patient_id patient_visit_id event conc.level           date.time\n1         10             10.1     4       0.17 2019-02-02 05:30:00\n2         10             10.1     2       4.05 2019-02-24 14:00:00\n3         10             10.1     3       0.64 2019-02-25 03:30:00\n4         10             10.1     5       0.33 2019-02-27 02:45:00\n5         10             10.1     6       0.07 2019-02-28 03:30:00\n6         10             10.1     7       0.05 2019-03-01 02:35:00\n\nivdose.data <- read.csv(file.path(rawDataDir,\"IVDose_DATA_simple.csv\"),stringsAsFactors = FALSE)\nhead(ivdose.data)\n\n\n  patient_id  date.dose    infuse.time.real         infuse.time\n1          1 2009-10-18 2009-10-18 11:35:00 2009-10-18 12:00:00\n2          1 2009-10-18 2009-10-18 12:00:00 2009-10-18 12:00:00\n3          1 2009-10-18 2009-10-18 13:00:00 2009-10-18 13:00:00\n4          1 2009-10-18 2009-10-18 14:00:00 2009-10-18 14:00:00\n5          1 2009-10-18 2009-10-18 15:00:00 2009-10-18 15:00:00\n6          1 2009-10-18 2009-10-18 16:00:00 2009-10-18 16:00:00\n  infuse.dose bolus.time bolus.dose given.dose maxint weight\n1         8.8       <NA>         NA          0     60    4.4\n2         8.8       <NA>         NA          0     60    4.4\n3         8.8       <NA>         NA          0     60    4.4\n4         8.8       <NA>         NA          0     60    4.4\n5         8.8       <NA>         NA          0     60    4.4\n6         8.8       <NA>         NA          0     60    4.4\n\ncreat.data <- read.csv(file.path(rawDataDir,\"Creatinine_DATA_simple.csv\"),stringsAsFactors = FALSE)\nhead(creat.data)\n\n\n  patient_id           date.time creat\n1          2 2015-06-23 04:35:00  0.75\n2          2 2015-06-22 04:00:00  0.69\n3          2 2015-06-21 01:55:00  0.78\n4          2 2015-06-24 03:45:00  0.64\n5          2 2015-06-14 15:11:00  0.71\n6          2 2015-06-20 20:14:00  0.58\n\nThe EHR package modules use a standardized naming convention for patient identification (ID) variables. We rename the unique patient-level ID from patient_id to mod_id and the visit-level ID from patient_visit_id to mod_id_visit. If there is only a single visit/course per subject the unique patient-level ID and visit-level ID can be the same, however both mod_id and mod_id_visit should be defined.\n\n\nnames(conc.data)[1:2] <- names(demo)[1:2] <- c(\"mod_id\", \"mod_id_visit\")\nnames(creat.data)[1] <- names(ivdose.data)[1] <- \"mod_id\"\n\n\n\n\nUsing the four datasets, we can build a final PK dataset with the function run_Build_PK_IV().\n\n\nsimple_pk_dat <- run_Build_PK_IV(\n    conc=conc.data,\n    dose=ivdose.data,\n    lab.dat = list(creat.data),\n    lab.vars = c('creat'),\n    demo.list = demo,\n    demo.vars=c('weight', 'weight_demo', 'height', 'gender', 'ageatsurgery',\n                'stat_sts', 'cpb_sts', 'length_of_icu_stay'),\n    demo.abbr=c('wgt', 'wgt_demo', 'height', 'gender',\n                'age', 'stat', 'cpb', 'loi'),\n    pk.vars=c('mod_id_visit', 'time', 'conc', 'dose', 'rate', 'event',\n              'other', 'multiple.record', 'date', 'mod_id'),\n    drugname='fent',\n    check.path=checkDir)\n\n\n0 duplicated rows\nThe dimension of the PK data before merging with demographics: 149 x 9\nThe number of subjects in the PK data before merging with demographics: 10\nThe number of subjects in the demographic file, who meet the exclusion criteria: 0\ncheck NA frequency in demographics, see file /tmp/Rtmpabzp3x/check1/fent-missing-demo.csv\nList of IDs missing at least 1 cpb_sts: \nChecked: all missing cpb_sts are 0\nThe list of final demographic variables: weight\nweight_demo\nheight\ngender\nageatsurgery\nstat_sts\ncpb_sts\nlength_of_icu_stay\nChecked: there are no missing creat\nThe dimension of the final PK data exported with the key demographics: 149 x 16 with 10 distinct subjects (mod_id_visit)\n\n\n\nhead(simple_pk_dat,15)\n\n\n   mod_id_visit  time conc amt rate mdv evid   wgt wgt_demo height\n1           1.2  0.00   NA  50    0   1    1 25.04    25.04 114.39\n2           1.2  0.75   NA 100    0   1    1 25.04    25.04 114.39\n3           1.2  1.65   NA 100    0   1    1 25.04    25.04 114.39\n4           1.2  1.77   NA 250    0   1    1 25.04    25.04 114.39\n5           1.2  2.05   NA 250    0   1    1 25.04    25.04 114.39\n6           1.2  3.72   NA 250    0   1    1 25.04    25.04 114.39\n7           1.2  5.23   NA 100    0   1    1 25.04    25.04 114.39\n8           1.2  6.25 2.83  NA   NA   0    0 25.04    25.04 114.39\n9           1.2 20.68 0.41  NA   NA   0    0 25.04    25.04 114.39\n10          1.2 70.90 0.04  NA   NA   0    0 25.04    25.04 114.39\n11          1.2 95.25 0.01  NA   NA   0    0 25.04    25.04 114.39\n12         10.1  0.00   NA  25    0   1    1  6.06     6.06  63.20\n13         10.1  0.52   NA 100    0   1    1  6.06     6.06  63.20\n14         10.1  1.42   NA  25    0   1    1  6.06     6.06  63.20\n15         10.1  2.77   NA  50    0   1    1  6.06     6.06  63.20\n   gender  age stat cpb loi creat\n1       1 2295    2  79   1  0.60\n2       1 2295    2  79   1  0.60\n3       1 2295    2  79   1  0.60\n4       1 2295    2  79   1  0.60\n5       1 2295    2  79   1  0.60\n6       1 2295    2  79   1  0.60\n7       1 2295    2  79   1  0.60\n8       1 2295    2  79   1  0.60\n9       1 2295    2  79   1  0.50\n10      1 2295    2  79   1  0.54\n11      1 2295    2  79   1  0.57\n12      0  209    1 195   5  0.64\n13      0  209    1 195   5  0.64\n14      0  209    1 195   5  0.64\n15      0  209    1 195   5  0.64\n\nReferences\nChoi L, Beck C, McNeer E, Weeks HL, Williams ML, James NT, Niu X, Abou-Khalil BW, Birdwell KA, Roden DM, Stein CM. Development of a System for Post-marketing Population Pharmacokinetic and Pharmacodynamic Studies using Real-World Data from Electronic Health Records. Clinical Pharmacology & Therapeutics. 2020 Apr; 107(4): 934-943.\n\n\n\n",
      "last_modified": "2021-08-18T16:57:00-05:00"
    },
    {
      "path": "Build-PK-Oral.html",
      "title": "Build-PK-Oral",
      "description": "This lecture describes the PK data building module in the system for medications that are typically orally administrated. It demonstrates how to quickly build PK data using *Build-PK-Oral* when drug dose data that can be provided by users or generated from unstructured clinical notes using extracted dosing information with the *Extract-Med* module and processed with the *Pro-Med-NLP* module in the system.\n",
      "author": [
        {
          "name": "Michael L. Williams",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nIntroduction\nBuild-PK-Oral\n\nHere add links to vignettes\nIntroduction\nPopulation PKPD Data Format\nSoftware which performs population PKPD model fitting typically require data to be in roughly the same format. Here is an example of data which is in a suitable format for analysis in NONMEM, the oldest and most popular choice for implementation of nonlinear mixed effects models suitable for PKPD analysis (among other applications).\n\n\n\n\n\nexampledata\n\n\n   CID   time conc dose addl II mdv age\n1    1    0.0   NA 10.0   27 12   1  46\n2    1  336.0 16.1   NA   NA NA   0  46\n3    1  336.5   NA 10.0  139 12   1  46\n4    1 2015.0  6.4   NA   NA NA   0  46\n5    1 2015.5   NA  5.0  105 12   1  46\n6    1 3287.0  5.6   NA   NA NA   0  46\n7    1 3287.5   NA  5.0  285 12   1  46\n8    1 6720.0  6.6   NA   NA NA   0  46\n9    1 6720.5   NA  5.0  265 12   1  46\n10   1 9911.0  5.0   NA   NA NA   0  46\n11   2    0.0   NA 10.0   27 12   1  72\n12   2  336.0 15.1   NA   NA NA   0  72\n13   2  336.5   NA 10.0   65 12   1  72\n14   2 1128.0 11.7   NA   NA NA   0  72\n15   2 1128.5   NA  7.5   25 12   1  72\n16   2 1440.0  2.9   NA   NA NA   0  72\n17   2 1440.5   NA  2.5   29 12   1  72\n18   2 1800.0  2.2   NA   NA NA   0  72\n19   2 1800.5   NA  2.5   29 12   1  72\n20   2 2160.0  4.3   NA   NA NA   0  72\n21   3    0.0   NA  2.5   27 12   1  56\n22   3  336.0  3.4   NA   NA NA   0  56\n23   3  336.5   NA  2.5  159 12   1  56\n24   3 2256.0 10.2   NA   NA NA   0  56\n25   3 2256.5   NA  7.5   17 12   1  56\n26   3 2472.0  7.5   NA   NA NA   0  56\n\nThis simple example has two types of rows, dose events (information concerning dosing) and concentration events (information concerning blood concentration levels for the drug of interest). The rows indicate the following information:\nCID: Unique identifier for each individual in the dataset.\ntime: Time of either the dose or concentration of interest.\nconc: Drug blood concentration, NA for a dose event.\ndose: Dose amount, we are concerned solely with oral dosing in this module, NA for concentration events.\naddl: Additional doses, the number of times for an oral dose to be repeated.\nII: Interdose interval, the amount of time between each additional dose.\nmdv: Missing dependent variable, indicates that there is no dependent variable (in this case, blood concentration) in the row, denotes dose events.\nage: Each column can store model covariates, these can be time varying or fixed by individual.\nTaking as an example the first row, which is a dose event, we can interpret that a dose of 10 mg is taken at time 0 then 27 additional doses are taken every 12 hours (time can take any unit). If we calculate each of these 27 doses then we see that the final dose is given at time=324, 12 hours before the measured concentration of 16.1 in row 2. Of course this same dosing information could be expressed in 28 rows, (10 mg at time 0, 10 mg at time 12, 10 mg at time 24, etc.) but this more compact form is preferable in the presence of a regular dosing interval.\nEHR Sourced Oral Dosing Data\nNow that we know the form that our data ultimately needs to take, we can consider how the data looks in it’s raw form. The module Extract-Med takes raw EHR notes to produce extracted medication data. See the relevant workshop to understand that process. Other modules (Pro-Phenotype, Pro-Med-NLP, Pro-Med-Str, Pro-Drug-Level, Pro-Laboratory, Pro-Demographic) take this extracted information and process it further, our interest is in the intermediate dataset generated by these modules but not yet in the form presented above. Here is an example of such data.\n\n\nex\n\n\n   id                  dt dose_morn conc age weight  hgb\n1   1 2019-02-27 10:00:00      10.0 16.1  46    154 12.0\n2   1 2019-05-08 10:00:00       5.0  6.4  46    154 12.0\n3   1 2019-06-30 10:00:00       5.0  5.6  46    154 12.0\n4   1 2019-11-20 10:00:00       5.0  6.6  46    154 12.0\n5   1 2020-04-01 10:00:00       2.5  5.0  46    154 12.0\n6   2 2020-04-10 10:00:00      10.0 15.1  72    193  8.6\n7   2 2020-05-13 10:00:00       7.5 11.7  72    193  8.6\n8   2 2020-05-26 10:00:00       2.5  2.9  72    193  8.6\n9   2 2020-06-10 10:00:00       2.5  2.2  72    193  8.6\n10  2 2020-06-25 10:00:00       2.5  4.3  72    193  8.6\n11  3 2020-07-07 10:00:00       2.5  3.4  56    167 12.2\n12  3 2020-09-25 10:00:00       7.5 10.2  56    167 12.2\n13  3 2020-10-04 10:00:00       5.0  7.5  56    167 12.2\n                    ld\n1  2019-02-26 22:00:00\n2  2019-05-07 18:00:00\n3                 <NA>\n4  2019-11-19 18:00:00\n5                 <NA>\n6                 <NA>\n7  2020-05-12 21:00:00\n8                 <NA>\n9                 <NA>\n10                <NA>\n11                <NA>\n12 2020-09-24 22:00:00\n13                <NA>\n\nThe ID, time, and covariate data in this dataframe is self explanatory. The difficult data to deal with can be found in dose_morn, conc, and ld. conc is a measured blood concentration which is recorded at the time indicated in time. dose_morn is the dose which was taken in the morning of that measured concentration, as extracted by Extract-Med. ld is the last-dose time, the extracted time of the dose which precedes the measured concentration, if present in the EHR. This information can be used to construct a course of drug dosing but some assumptions need to be made. Consider the two following assumptions:\nDosing only occurs on the morning of the recorded dose.\nDosing occurs twice daily at 8am and 8pm.\nObviously, the correct assumption will depend on the drug of interest, some drugs are taken on a regular schedule, others are as needed. Drugs which undergo routine therapeutic drug monitoring tend to be the latter so assumption 2 will likely be the better assumption.\nIf a twice-daily dosing assumption is appropriate, then we can begin to think about how to best choose the timing of each dose, can we exploit some information in our dataset to determine dose timings which are more realistic than, say every day 8am and 8pm. In doing so we need to remember that the timing of the dose before the measured concentration is most important for estimating the PK profile. Some other things to consider:\nThe timing of the concentration measurement itself may impact dosing.\nThere may or may not be an extracted last-dose time to work with.\nFor this reason, we will break up our algorithm into with and without last-dose times and discuss how we arrive at a final dose-building algorithm.\nWithout Last-Dose Times\nWhen we do not have an extracted last-dose time, we must work off of only our measured concentration timing and assumptions about how routine therapeutic monitoring is typically performed. The majority of these labs are conducted in the morning, and patients will typically hold off on taking their medications until after the blood draw. For that reason, we assume that a dose is taken 30 minutes after a measured blood concentration, then proceeds with a dose every 12 hours. The final dose in the seq uence will occur 6-18 hours before the next measured concentration, the timing of which will determine the next sequence of doses, and so on until the final measured concentration. The First measured dose requires special attention. Typical drug monitoring procedure suggests it is reasonable to assume that the drug has been taken regularly before this first concentration. The safest assumptiom, assuming no further information is available, is that the drug has been taken every 12 hours for long enough to reach a steady state of trough concentrations. In our system this defaults to 336 hours, ending 12 hours before the first measured concentration.\nWith Last-Dose times\nIn the case where extracted last-dose times are available, we can begin by building the same dataset as without last-dose times. We then add a row for the extracted last dose and eliminate an appropriate number of doses from the preceding dose sequence to avoid incorrect double-dosing, this is done by removing doses until the last dose in the sequence is 6-18 hours before the extracted last-dose time. This allows for last-dose times which are more than 12 hours before the extracted concentration to be appropriately accounted for.\nBuild-PK-Oral\nIn order to run the Build-PK-Oral we first need to load the EHR package into our R environment.\n\n\nlibrary(EHR)\n\n\n\nLet’s have another look at the example data we want to process:\n\n\nex\n\n\n   id                  dt dose_morn conc age weight  hgb\n1   1 2019-02-27 10:00:00      10.0 16.1  46    154 12.0\n2   1 2019-05-08 10:00:00       5.0  6.4  46    154 12.0\n3   1 2019-06-30 10:00:00       5.0  5.6  46    154 12.0\n4   1 2019-11-20 10:00:00       5.0  6.6  46    154 12.0\n5   1 2020-04-01 10:00:00       2.5  5.0  46    154 12.0\n6   2 2020-04-10 10:00:00      10.0 15.1  72    193  8.6\n7   2 2020-05-13 10:00:00       7.5 11.7  72    193  8.6\n8   2 2020-05-26 10:00:00       2.5  2.9  72    193  8.6\n9   2 2020-06-10 10:00:00       2.5  2.2  72    193  8.6\n10  2 2020-06-25 10:00:00       2.5  4.3  72    193  8.6\n11  3 2020-07-07 10:00:00       2.5  3.4  56    167 12.2\n12  3 2020-09-25 10:00:00       7.5 10.2  56    167 12.2\n13  3 2020-10-04 10:00:00       5.0  7.5  56    167 12.2\n                    ld\n1  2019-02-26 22:00:00\n2  2019-05-07 18:00:00\n3                 <NA>\n4  2019-11-19 18:00:00\n5                 <NA>\n6                 <NA>\n7  2020-05-12 21:00:00\n8                 <NA>\n9                 <NA>\n10                <NA>\n11                <NA>\n12 2020-09-24 22:00:00\n13                <NA>\n\nThere are 3 individuals in the dataset, each has a set of EHR-extracted dose and blood concentrations data along with demographic data and information commonly found with laboratory data:\nAll concentrations are being taken in the morning. Given that this is a drug which should be taken orally every 12 hours, we can construct a reasonable dosing schedule which details the amount and timing of each dose.\nrun_Build_PK_Oral() will build an appropriate dataset for population PK analysis, given specification of appropriate columns:\nidCol: subject identification number\ndtCol: time of concentration measurement\ndoseCol: dose\nconcCol: drug concentration\nldCol: last-dose time; the default is NULL to ignore\nfirst_interval_hours: Hours of regular dosing leading up to the first concentration; the default is 336 hours = 14 days\nimputeClosest: Vector of columns for imputation of missing data using last observation carried forward or, if unavailable, next observation propagated backward\n\n\n# Build PK data without last-dose times\nrun_Build_PK_Oral(x = dat[,-8],\n                  idCol = \"id\",\n                  dtCol = \"dt\",\n                  doseCol = \"dose_morn\",\n                  concCol = \"conc\",\n                  ldCol = NULL,\n                  first_interval_hours = 336,\n                  imputeClosest = NULL)\n\n\n   CID   time                date conc dose addl II mdv age weight\n1    1    0.0 2019-02-13 10:00:00   NA 10.0   27 12   1  46    154\n2    1  336.0 2019-02-27 10:00:00 16.1   NA   NA NA   0  46    154\n3    1  336.5 2019-02-27 10:30:00   NA 10.0  139 12   1  46    154\n4    1 2015.0 2019-05-08 10:00:00  6.4   NA   NA NA   0  46    154\n5    1 2015.5 2019-05-08 10:30:00   NA  5.0  105 12   1  46    154\n6    1 3287.0 2019-06-30 10:00:00  5.6   NA   NA NA   0  46    154\n7    1 3287.5 2019-06-30 10:30:00   NA  5.0  285 12   1  46    154\n8    1 6720.0 2019-11-20 10:00:00  6.6   NA   NA NA   0  46    154\n9    1 6720.5 2019-11-20 10:30:00   NA  5.0  265 12   1  46    154\n10   1 9911.0 2020-04-01 10:00:00  5.0   NA   NA NA   0  46    154\n11   2    0.0 2020-03-27 10:00:00   NA 10.0   27 12   1  72    193\n12   2  336.0 2020-04-10 10:00:00 15.1   NA   NA NA   0  72    193\n13   2  336.5 2020-04-10 10:30:00   NA 10.0   65 12   1  72    193\n14   2 1128.0 2020-05-13 10:00:00 11.7   NA   NA NA   0  72    193\n15   2 1128.5 2020-05-13 10:30:00   NA  7.5   25 12   1  72    193\n16   2 1440.0 2020-05-26 10:00:00  2.9   NA   NA NA   0  72    193\n17   2 1440.5 2020-05-26 10:30:00   NA  2.5   29 12   1  72    193\n18   2 1800.0 2020-06-10 10:00:00  2.2   NA   NA NA   0  72    193\n19   2 1800.5 2020-06-10 10:30:00   NA  2.5   29 12   1  72    193\n20   2 2160.0 2020-06-25 10:00:00  4.3   NA   NA NA   0  72    193\n21   3    0.0 2020-06-23 10:00:00   NA  2.5   27 12   1  56    167\n22   3  336.0 2020-07-07 10:00:00  3.4   NA   NA NA   0  56    167\n23   3  336.5 2020-07-07 10:30:00   NA  2.5  159 12   1  56    167\n24   3 2256.0 2020-09-25 10:00:00 10.2   NA   NA NA   0  56    167\n25   3 2256.5 2020-09-25 10:30:00   NA  7.5   17 12   1  56    167\n26   3 2472.0 2020-10-04 10:00:00  7.5   NA   NA NA   0  56    167\n    hgb\n1  12.0\n2  12.0\n3  12.0\n4  12.0\n5  12.0\n6  12.0\n7  12.0\n8  12.0\n9  12.0\n10 12.0\n11  8.6\n12  8.6\n13  8.6\n14  8.6\n15  8.6\n16  8.6\n17  8.6\n18  8.6\n19  8.6\n20  8.6\n21 12.2\n22 12.2\n23 12.2\n24 12.2\n25 12.2\n26 12.2\n\nNote that addl and II dictate an every-twelve-hour dosing schedule which leads up to the proceeding concentration. Covariates are preserved and a time variable which represents hours since first dose is generated. This data is now in an appropriate format for PK analysis but makes no use of the last-dose times although they are extracted along with some (but not all) concentrations. When last-dose times are present in the input data and they are specified in the argument ldCol, the sequence of doses leading up to the extracted dose is reduced and a new row is inserted which accurately describes the timing of the dose which precedes the relevant concentration.\n\n\n# Build PK data with last-dose times\nrun_Build_PK_Oral(x = dat,\n                  idCol = \"id\",\n                  dtCol = \"dt\",\n                  doseCol = \"dose_morn\",\n                  concCol = \"conc\",\n                  ldCol = \"ld\",\n                  first_interval_hours = 336,\n                  imputeClosest = NULL)\n\n\n   CID   time                date conc dose addl II mdv age weight\n1    1    0.0 2019-02-13 10:00:00   NA 10.0   26 12   1  46    154\n2    1  324.0 2019-02-26 22:00:00   NA 10.0    0 NA   1  46    154\n3    1  336.0 2019-02-27 10:00:00 16.1   NA   NA NA   0  46    154\n4    1  336.5 2019-02-27 10:30:00   NA 10.0  138 12   1  46    154\n5    1 1999.0 2019-05-07 18:00:00   NA 10.0    0 NA   1  46    154\n6    1 2015.0 2019-05-08 10:00:00  6.4   NA   NA NA   0  46    154\n7    1 2015.5 2019-05-08 10:30:00   NA  5.0  105 12   1  46    154\n8    1 3287.0 2019-06-30 10:00:00  5.6   NA   NA NA   0  46    154\n9    1 3287.5 2019-06-30 10:30:00   NA  5.0  284 12   1  46    154\n10   1 6704.0 2019-11-19 18:00:00   NA  5.0    0 NA   1  46    154\n11   1 6720.0 2019-11-20 10:00:00  6.6   NA   NA NA   0  46    154\n12   1 6720.5 2019-11-20 10:30:00   NA  5.0  265 12   1  46    154\n13   1 9911.0 2020-04-01 10:00:00  5.0   NA   NA NA   0  46    154\n14   2    0.0 2020-03-27 10:00:00   NA 10.0   27 12   1  72    193\n15   2  336.0 2020-04-10 10:00:00 15.1   NA   NA NA   0  72    193\n16   2  336.5 2020-04-10 10:30:00   NA 10.0   64 12   1  72    193\n17   2 1115.0 2020-05-12 21:00:00   NA 10.0    0 NA   1  72    193\n18   2 1128.0 2020-05-13 10:00:00 11.7   NA   NA NA   0  72    193\n19   2 1128.5 2020-05-13 10:30:00   NA  7.5   25 12   1  72    193\n20   2 1440.0 2020-05-26 10:00:00  2.9   NA   NA NA   0  72    193\n21   2 1440.5 2020-05-26 10:30:00   NA  2.5   29 12   1  72    193\n22   2 1800.0 2020-06-10 10:00:00  2.2   NA   NA NA   0  72    193\n23   2 1800.5 2020-06-10 10:30:00   NA  2.5   29 12   1  72    193\n24   2 2160.0 2020-06-25 10:00:00  4.3   NA   NA NA   0  72    193\n25   3    0.0 2020-06-23 10:00:00   NA  2.5   27 12   1  56    167\n26   3  336.0 2020-07-07 10:00:00  3.4   NA   NA NA   0  56    167\n27   3  336.5 2020-07-07 10:30:00   NA  2.5  158 12   1  56    167\n28   3 2244.0 2020-09-24 22:00:00   NA  2.5    0 NA   1  56    167\n29   3 2256.0 2020-09-25 10:00:00 10.2   NA   NA NA   0  56    167\n30   3 2256.5 2020-09-25 10:30:00   NA  7.5   17 12   1  56    167\n31   3 2472.0 2020-10-04 10:00:00  7.5   NA   NA NA   0  56    167\n    hgb\n1  12.0\n2  12.0\n3  12.0\n4  12.0\n5  12.0\n6  12.0\n7  12.0\n8  12.0\n9  12.0\n10 12.0\n11 12.0\n12 12.0\n13 12.0\n14  8.6\n15  8.6\n16  8.6\n17  8.6\n18  8.6\n19  8.6\n20  8.6\n21  8.6\n22  8.6\n23  8.6\n24  8.6\n25 12.2\n26 12.2\n27 12.2\n28 12.2\n29 12.2\n30 12.2\n31 12.2\n\nIndividual 1 has no extracted last-dose times so their data is unchanged from before. Compare, however, rows 7-9 to rows 7-8 of the previous dataset constructed without last-dose times. The measured concentration of 14.1 on date 2019-11-01 is associated with a last-dose time. addl drops from 69 to 68 and the extracted last-dose is added in row 8 with additional date 2019-10-31 20:58:36, the last-dose time extracted from clinical notes. Notice that the number of doses leading up to the concentration is unchanged and the timing of the final dose has been adjusted to reflect information in the EHR (i.e., the calculated time of 1162.70 for time). This dataset still relies on assumptions about dosing, but should reflect the actual dosing schedule better by incorporating last-dose times from the EHR.\nReferences\nChoi L, Beck C, McNeer E, Weeks HL, Williams ML, James NT, Niu X, Abou-Khalil BW, Birdwell KA, Roden DM, Stein CM. Development of a System for Post-marketing Population Pharmacokinetic and Pharmacodynamic Studies using Real-World Data from Electronic Health Records. Clinical Pharmacology & Therapeutics. 2020 Apr; 107(4): 934-943.\n\n\n\n",
      "last_modified": "2021-08-18T16:57:00-05:00"
    },
    {
      "path": "Extract-Med.html",
      "title": "Extract-Med",
      "description": "This lecture describes how to obtain drug dosing information from unstructured clinical notes using *Extract-Med* module in the system.\n",
      "author": [
        {
          "name": "Hannah L. Weeks, Elizabeth McNeer",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nIntroduction\n\nHere add links to vignettes\nIntroduction\n\n\n\n",
      "last_modified": "2021-08-18T16:57:01-05:00"
    },
    {
      "path": "index.html",
      "title": "Choi Lab",
      "author": [],
      "contents": "\n\n\n\nLeena Choi, PhD\nVice Chair of Diversity and Inclusion, Department of Biostatistics\nProfessor of Biostatistics\n\n\n\nhttps://www.vumc.org/biostatistics/person/leena-choi-phd\n\nThe major research focus of our lab is to construct a system for drug-related studies such as pharmacokinetics (PK), pharmacodynamics (PD), and pharmacogenomics (PGx) studies using electronic health records (EHRs), which is called “EHRtoPKPD”. This system would allow to perform the studies more efficiently by standardizing data extraction, data processing, and data building procedures. This system would provide the foundation for PK/PD-model guided clinical decision support systems embedded in EHRs to provide an optimal pharmacotherapy, the overarching goal of precision medicine.\n\nThe EHRtoPKPD, a System for PK/PD Studies using EHRs.\nModified from Clin Pharm Ther 2020.\nEHRtoPKPD is a modular system, divided into the three major procedures: data extraction (“Extract-”), data processing (“Pro-”), and data building (“Build-”). Modules were created or under development (gray color box) depending on the data element, task to perform, and type of PK/PD models. For drugs with simple prescription pattern, dose data can be relatively easily extracted from e-prescription databases and processed using Pro-Med-Str module. However, we found that dosing data obtained from e-prescription databases often are not accurate enough for PK/PD studies. Thus, we developed more flexible and targeted NLP system that performed better than existing state-of-art NLP systems for drug dose extraction. Our NLP system was incorporated into our system (Extract-Med module), which can directly extract drug dose information from clinical notes, which is also available as an R package, medExtractR. As building drug dose data from extracted dose information can be very challenging, we developed a dose data building algorithm which was also implemented in our system (Pro-Med-NLP). Other data elements such as drug levels (Pro-Drug Level), demographics (Pro-Demographic), and laboratory data (Pro-Laboratory) can be processed using our system, and then combined with processed dose data to build PK/PD data using PK/PD data building modules (i.e., Build-PK-IV, Build-PK-Oral). The functions to run each module is implemented as R packages, medExtractR and EHR. More details can be found in Choi et al.\\(^{1}\\), and additional modules will be added in the future as it evolves.\n\nLab Team\nCole Beck\nElizabeth McNeer\nMichael Williams\nNathan T. James, ScM\n\nLab Alumni\nHannah L. Weeks\nReferences\nChoi L, Beck C, McNeer E, Weeks HL, Williams ML, James NT, Niu X, Abou-Khalil BW, Birdwell KA, Roden DM, Stein CM. Development of a System for Post-marketing Population Pharmacokinetic and Pharmacodynamic Studies using Real-World Data from Electronic Health Records. Clinical Pharmacology & Therapeutics. 2020 Apr; 107(4): 934-943.\n\n\n\n",
      "last_modified": "2021-08-18T16:57:01-05:00"
    },
    {
      "path": "Pro-Med-NLP.html",
      "title": "Pro-Med-NLP",
      "description": "This lecture describes how to build longitudinal medication dose data from the raw output of an NLP system using the *Pro-Med-NLP* module.\n",
      "author": [
        {
          "name": "Hannah L. Weeks, Elizabeth McNeer",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nIntroduction\n\nHere add links to vignettes\nIntroduction\n\n\n\n",
      "last_modified": "2021-08-18T16:57:01-05:00"
    },
    {
      "path": "Pro-Med-Str-Part2.html",
      "title": "Pro-Med-Str - Part II",
      "description": "This lecture describes how to process structured medication data, especially focusing on e-prescription data.\n",
      "author": [
        {
          "name": "Elizabeth McNeer",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nIntroduction\nRaw E-Prescription Data\nProcessing the Data\n\nHere add links to vignettes\nIntroduction\nThis lecture describes how to use the Pro-Med-Str - Part II module to process structured e-prescription data in EHRtoPKPD.\nThe major tasks the module performs are as follows:\nCreating numeric variables for strength, dose, and frequency\nCalculating daily dose\nRemoving duplicate daily doses for a patient\nRaw E-Prescription Data\nTo use this module, all prescriptions must be for only one drug. Different names, such as brand names and generic names, for the same drug are allowed (e.g., Lamictal and lamotrigine). The data used in this module must include columns for ID, date, strength, dose amount, and frequency. If a description column is included, this module will attempt to extract the strength from the description column in cases where the strength is missing.\nBelow is example e-prescription data from the EHR package including columns for ID, drug name, dose, frequency, date, strength, and description.\n\n\nrawDataDir <- system.file(\"examples\", \"str_ex2\", package=\"EHR\")\n(eRX <- read.csv(file.path(rawDataDir,\"e-rx_DATA.csv\"),stringsAsFactors = FALSE))\n\n\n  GRID    MED_NAME   RX_DOSE             FREQUENCY ENTRY_DATE\n1  ID1 lamotrigine         1                   bid 2009-02-24\n2  ID2 lamotrigine         2                   bid 2006-12-30\n3  ID2    Lamictal         1                   bid 2006-12-30\n4  ID3 Lamictal XR         3                   bid 2004-08-24\n5  ID4 lamotrigine         1           twice a day 2010-05-22\n6  ID5 lamotrigine    2 tabs                   qam 2007-06-13\n7  ID6 lamotrigine 1.5+1+1.5 brkfst, lunch, dinner 2015-03-14\n  STRENGTH_AMOUNT                                        DESCRIPTION\n1             100 lamotrigine 100 mg tablet (Also Known As Lamictal)\n2             100 lamotrigine 100 mg tablet (Also Known As Lamictal)\n3             200                             LaMICtal 200 mg tablet\n4                                       Lamictal XR 100 mg 24 hr Tab\n5          200 mg lamotrigine 200 mg tablet (Also Known As Lamictal)\n6             200         LaMICtal XR 200 mg tablet,extended release\n7             100 lamoTRIgine 100 mg tablet (Also Known As Lamictal)\n\nTo get a daily dose for each patient, we multiply strength*dose*frequency. In order to do this, the STRENGTH_AMOUNT, RX_DOSE, and FREQUENCY variables need to be converted to numeric. Strengths that include units will have the units removed (e.g., numeric strength for ID4 will be 200), frequencies will be converted to the equivalent number of times per day that the medication is taken (e.g., bid = 2, twice a day = 2, qam = 1), and doses will have words like “tabs” removed (e.g., numeric dose for ID5 will be 2). For ID6, separate doses are written for breakfast, lunch, and dinner, so the numeric dose will be 4 (1.5+1+1.5), and the daily dose will be calculated as strength*dose. ID3 is missing a value for STRENGTH_AMOUNT, but we can use the strength that is present in the DESCRIPTION column. In the next section, we show how the run_MedStrII function in the EHR package takes care of all of these tasks for us and calculates a daily dose.\nProcessing the Data\nWe begin by loading the EHR package.\n\n\nlibrary(EHR)\n\n\n\nThe e-prescription data can be processed by the run_MedStrII function using:\n\n\neRX.out <- run_MedStrII(file.path(rawDataDir,\"e-rx_DATA.csv\"),\n    select = c('GRID','MED_NAME','RX_DOSE','FREQUENCY','ENTRY_DATE','STRENGTH_AMOUNT','DESCRIPTION'),\n    rename = c('ID','MED_NAME','RX_DOSE','FREQUENCY','ENTRY_DATE','STRENGTH_AMOUNT','DESCRIPTION'))\n\n\n\nThe following arguments are used in the run_MedStrII function:\nfile: file name of prescription data\nselect: the names of the columns to select\nrename: new column names; the default are the names required for the underlying functions, processErx and processErxAddl\n\n\neRX.out\n\n\n   ID    MED_NAME   RX_DOSE             FREQUENCY ENTRY_DATE\n1 ID1 lamotrigine         1                   bid 2009-02-24\n2 ID2 lamotrigine         2                   bid 2006-12-30\n4 ID3 Lamictal XR         3                   bid 2004-08-24\n5 ID4 lamotrigine         1           twice a day 2010-05-22\n6 ID5 lamotrigine    2 tabs                   qam 2007-06-13\n7 ID6 lamotrigine 1.5+1+1.5 brkfst, lunch, dinner 2015-03-14\n  STRENGTH_AMOUNT                                        DESCRIPTION\n1             100 lamotrigine 100 mg tablet (also known as lamictal)\n2             100 lamotrigine 100 mg tablet (also known as lamictal)\n4                                       lamictal xr 100 mg 24 hr tab\n5          200 mg lamotrigine 200 mg tablet (also known as lamictal)\n6             200         lamictal xr 200 mg tablet,extended release\n7             100 lamotrigine 100 mg tablet (also known as lamictal)\n  strength freq.standard freq.num dose daily.dose       date\n1      100           bid        2    1        200 2009-02-24\n2      100           bid        2    2        400 2006-12-30\n4      100           bid        2    3        600 2004-08-24\n5      200           bid        2    1        400 2010-05-22\n6      200            am        1    2        400 2007-06-13\n7      100           tid        3    4        400 2015-03-14\n  num_doses num_freqs\n1        NA        NA\n2        NA        NA\n4        NA        NA\n5        NA        NA\n6        NA        NA\n7         3         3\n\nIn the above example, daily dose was calculated for the first 5 patients by multiplying strength*dose*freq.num, and a redundant daily dose was removed for the patient with ID2. In order to calculate a daily dose for the patient with ID3, the strength of 100 from the description was used because STRENGTH_AMOUNT was missing. For the patient with ID6, the dose amounts of 1.5, 1, and 1.5 are added together to get a dose of 4, and the daily dose is calculated as strength*dose.\n\n\n\n",
      "last_modified": "2021-08-18T16:57:02-05:00"
    },
    {
      "path": "workshops.html",
      "title": "*EHRtoPKPD* Workshops",
      "description": "Lecture series demonstrating how to use *EHRtoPKPD* with some examples in EHR package\n",
      "author": [],
      "contents": "\n\nContents\nExtract-Med\nPro-Med-NLP\nBuild-PK-Oral\nBuild-PK-IV - Simple\nBuild-PK-IV - Comprehensive\nPro-Med-Str - Part II\nPro-Med-Str - Part I\n\nHere add links to vignettes\nExtract-Med\nThis lecture describes how to obtain drug dosing information from unstructured clinical notes using Extract-Med module in the system.\nPro-Med-NLP\nThis lecture describes how to build longitudinal medication dose data from the raw output of an NLP system using the Pro-Med-NLP module.\nBuild-PK-Oral\nThis lecture describes the PK data building procedure in the EHRtoPKPD for medications that are typically orally administrated. It demonstrates how to quickly build PK data using Build-PK-Oral when drug dose data that can be provided by users or generated from unstructured clinical notes using extracted dosing information with the Extract-Med module and processed with the Pro-Med-NLP module in the system.\nBuild-PK-IV - Simple\nThis lecture describes a simple PK data building procedure in the EHRtoPKPD for medications that are typically intravenously administrated. It demonstrates how to quickly build PK data using Build-PK-IV without using the data processing modules when cleaned data for concentration, drug dose, demographic and laboratory datasets are already available in an appropriate data form.\nBuild-PK-IV - Comprehensive\nThis lecture describes a comprehensive PK data building procedure in the EHRtoPKPD for medications that are typically intravenously administrated. It demonstrates how to utilize several data processing modules (e.g., Pro-Demographic, Pro-Med-Str, Pro-Drug Level, Pro-Laboratory) to standardize and combine more complex datasets when cleaned data are not available, and then finally build PK data using Build-PK-IV.\nPro-Med-Str - Part II\nThis lecture describes how to processes structured medication data, especially focusing on e-prescription data.\nPro-Med-Str - Part I\nThis lecture describes how to processes structured medication data, especially focusing on intravenously given dose data.\n\n\n\n",
      "last_modified": "2021-08-18T16:57:02-05:00"
    }
  ],
  "collections": []
}
