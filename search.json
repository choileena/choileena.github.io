{
  "articles": [
    {
      "path": "about.html",
      "title": "About This Site",
      "description": "Some additional details about the website.",
      "author": [],
      "contents": "\nMore information about the EHRtoPKPD can be found at the following sites.\nhttps://github.com/choileena\nhttps://github.com/choileena/EHR\nhttps://github.com/choileena/pkdata\nhttps://github.com/choileena/medExtractR\n\n",
      "last_modified": "2021-08-19T08:55:06-05:00"
    },
    {
      "path": "Build-PK-IV-comprehensive.html",
      "title": "Build-PK-IV - Comprehensive",
      "description": "This tutorial describes a comprehensive PK data building procedure for medications that are intravenously administered. There are two phases: data processing which standardizes and combines the input data (*Pro-Demographic*, *Pro-Med-Str*, *Pro-Drug Level*, *Pro-Laboratory*) and data building which creates the final PK data (*Build-PK-IV*).\n",
      "author": [
        {
          "name": "Nathan T. James",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nIntroduction\nPre-Processing for Raw Extracted Data\nPro-Demographic\nPro-Med-Str Part I: IV dose data\nPro-Drug Level\nPro-Laboratory\nBuild-PK-IV\n\nHere add links to vignettes\nSee also “Example 2: Complete Data Processing and Building from Raw Extracted Data to PK Data” of “2. EHR Vignette for Structured Data” in EHR package\nIntroduction\nThis tutorial describes four modules for processing data (Pro-Demographic, Pro-Med-Str, Pro-Drug Level, Pro-Laboratory) and one module for PK data building (Build-PK-IV) using data extracted from a structured database.\nTo begin we load the EHR package, the pkdata package, and the lubridate package.\n\n\n# load EHR package and dependencies\nlibrary(EHR)\nlibrary(pkdata)\nlibrary(lubridate)\n\n\n\nWe first define three directories:\none for raw structured data\none containing files used for interactive checking\none for processed data.\n\nThere are 4 types of raw data expected to exist in the raw data directory (i.e., rawDataDir below):\na demographic file for use with the Pro-Demographic module (Demographics_DATA.csv)\ntwo files for the Pro-Drug Level module (SampleTimes_DATA.csv and SampleConcentration_DATA.csv)\ntwo dosing files for the Pro-Med-Str module (FLOW_DATA.csv and MAR_DATA.csv)\ntwo lab files for use with the Pro-Laboratory module (Creatinine_DATA.csv and Albumin_DATA.csv).\n\n\n\n# define 3 directories\nrawDataDir <- system.file(\"examples\", \"str_ex2\", package=\"EHR\") # directory for raw data\n\ntd <- tempdir()\ndir.create(file.path(td, 'checks'))\ncheckDir <- file.path(td, 'checks') # directory for interactive checking\n\ndir.create(file.path(td, 'data'))\ndataDir <- file.path(td, 'data') # directory for processed data\n\n# examine raw data files in rawDataDir\ndir(rawDataDir)\n\n\n[1] \"Albumin_DATA.csv\"             \"Creatinine_DATA.csv\"         \n[3] \"Demographics_DATA.csv\"        \"e-rx_DATA.csv\"               \n[5] \"FLOW_DATA.csv\"                \"MAR_DATA.csv\"                \n[7] \"medChecked-fent.csv\"          \"SampleConcentration_DATA.csv\"\n[9] \"SampleTimes_DATA.csv\"        \n\nPre-Processing for Raw Extracted Data\nThe raw datasets must go through a pre-processing stage which creates new ID variables and datasets that can be used by the data processing modules. There are three pre-processing steps:\nread and clean raw data\nmerge raw data to create new ID variables\nmake new data for use with modules.\nEach raw dataset should contain a subject unique ID, a subject visit ID, or both ids. In this example the subject unique ID is called subject_uid and the subject visit ID is called subject_id. The subject visit ID is a combination of subject and visit/course – e.g., subject_id 14.0 is the first course for subject 14, subject_id 14.1 is the second course for subject 14, and so on. subject_uid is a unique ID that is the same for all subject records. The integer part of subject_id has a 1-to-1 correspondence with subject_uid – for this example, subject_uid 62734832 is associated with both subject_id 14.0 and subject_id 14.1. If there is only a single visit/course per subject only the subject unique ID is needed.\n(1) Read and clean raw data\nreadTransform(): This function reads in a CSV file and makes optional modifications to the resulting dataframe.\nDemographics raw data\nThe example demographics data file contains ID variables subject_id and subject_uid, in addition to demographic variables such as gender, date of birth, height, weight, etc. As subject_id and subject_uid already exist, no further cleaning is needed.\nThe Demographics_DATA.csv file is read in using the readTransform() function.\n\n\n\n# demographics data\ndemo.in <- readTransform(file.path(rawDataDir, \"Demographics_DATA.csv\"))\nhead(demo.in)\n\n\n  subject_id subject_uid gender weight height surgery_date\n1       1106    34364670      0   5.14  59.18    6/28/2014\n2       1444    36792472      1   5.67  62.90    1/10/2016\n3       1465    36292449      0  23.67 118.02    3/19/2016\n4       1520    34161967      0  14.07  97.04    7/18/2016\n5       1524    37857374      1  23.40 102.80    7/23/2016\n6       1550    37826262      1   6.21  62.03     9/4/2016\n  ageatsurgery stat_sts cpb_sts in_hospital_mortality add_ecmo\n1          141        3     133                     0        0\n2          292        1      65                     0        0\n3         2591        2     357                     0        0\n4         1320        5      93                     0        0\n5         1561        3      87                     1        0\n6          208        1     203                     0        0\n  date_icu_dc time_fromor\n1    7/2/2014        1657\n2   1/12/2016        1325\n3   3/20/2016          NA\n4   7/19/2016        1745\n5   7/30/2016        1847\n6   9/11/2016        1210\n\nConcentration raw data\nThe example concentration data consists of two files:\nSampleTimes_DATA.csv: contains the concentration sampling times\n\nSampleConcentration_DATA.csv: contains the concentration measurements\n\n\nIf all concentration data is in one file, the user should transform the file so it contains a subject unique ID, a subject visit ID, or both ids.\nUse the function readTransform()\nto read SampleTimes_DATA.csv, and rename the variable Study.ID to subject_id and create a new variable called samp, which indexes the sample number, using the modify= argument.\nto read SampleConcentration_DATA.csv, and transform the concentration values - we use the helper function sampId() to process the subject_id field.\n\n\n\n\n# read SampleTimes_DATA.csv\nsamp.in <- readTransform(file.path(rawDataDir, \"SampleTimes_DATA.csv\"),\n    rename = c('Study.ID' = 'subject_id'),\n    modify = list(samp = expression(as.numeric(sub('Sample ', '', Event.Name)))))\nhead(samp.in)\n\n\n  subject_id Event.Name Sample.Collection.Date.and.Time samp\n1      466.1   Sample 1                  2/3/2017 10:46    1\n2      466.1   Sample 2                  2/4/2017 20:30    2\n3     1106.0   Sample 1                 6/28/2014 13:40    1\n4     1106.0   Sample 2                 6/29/2014 03:10    2\n5     1106.0   Sample 3                 6/30/2014 03:35    3\n6     1106.0   Sample 4                  7/1/2014 03:45    4\n\n\n\n# helper function used to make subject_id\nsampId <- function(x) {\n  # remove leading zeroes or trailing periods\n  subid <- gsub('(^0*|\\\\.$)', '', x)\n  # change _ to .\n  gsub('_([0-9]+[_].*)$', '.\\\\1', subid)\n}\n\n# read SampleConcentration_DATA.csv\nconc.in <- readTransform(file.path(rawDataDir, \"SampleConcentration_DATA.csv\"),\n  modify = list(\n    subid = expression(sampId(name)),\n    subject_id = expression(as.numeric(sub('[_].*', '', subid))),\n    samp = expression(sub('[^_]*[_]', '', subid)),\n    name = NULL,\n    data_file = NULL,\n    subid = NULL\n    )\n  )\nhead(conc.in)\n\n\n  record_id fentanyl_calc_conc subject_id samp\n1         1         0.01413622      466.1    1\n2         2         0.27982075      466.1    2\n3         3         6.11873679     1106.0    1\n4         4         0.59161716     1106.0    2\n5         5         0.11280471     1106.0    3\n6         6         0.02112153     1106.0    4\n\nDosing raw data\nThe example drug dosing data consists of two files containing two sources of IV dose information:\nFLOW_DATA.csv: contains aliases for both ID variables, and it is read in with the readTransform() function which renames the variables Subject.Id to subject_id and Subject.Uniq.Id to subject_uid.\n\nMAR_DATA.csv: contains several variables with a colon (:) character. To preserve the colon in these variable names, the data can be read in without checking for syntactically valid R variable names. The data is read in using read.csv() with the argument check.names = FALSE and then passed to the dataTransformation() function which renames Uniq.Id to subject_uid.\n\n\nIf all dosing data is in one file, the user should transform the file so it contains a subject unique ID, a subject visit ID, or both ids.\n\n\n\n# FLOW dosing data\nflow.in <- readTransform(file.path(rawDataDir, \"FLOW_DATA.csv\"),\n                         rename = c('Subject.Id' = 'subject_id',\n                                    'Subject.Uniq.Id' = 'subject_uid')) \nhead(flow.in)\n\n\n  subject_id subject_uid     Perform.Date FOCUS_MEDNAME Final.Wt..kg.\n1       1596    38340814   12/4/2016 5:30      Fentanyl          6.75\n2       1596    38340814   12/4/2016 6:00      Fentanyl          6.75\n3       1596    38340814   12/4/2016 7:00      Fentanyl          6.75\n4       1596    38340814   12/4/2016 7:40      Fentanyl          6.75\n5       1607    38551767 12/24/2016 19:30      Fentanyl          2.60\n6       1607    38551767 12/24/2016 20:00      Fentanyl          2.60\n  Final.Rate..NFR.units. Final.Units Flow\n1            1 mcg/kg/hr       3.375   NA\n2            1 mcg/kg/hr       6.750  0.1\n3            1 mcg/kg/hr       4.500  0.1\n4            0 mcg/kg/hr       0.000   NA\n5            2 mcg/kg/hr       2.600   NA\n6            2 mcg/kg/hr       5.200  0.2\n\n\n\n# MAR dosing data\nmar.in0 <- read.csv(file.path(rawDataDir, \"MAR_DATA.csv\"), check.names = FALSE)\nmar.in <- dataTransformation(mar.in0, rename = c('Uniq.Id' = 'subject_uid'))\nhead(mar.in)\n\n\n  subject_uid       Date  Time                 med:mDrug   med:dosage\n1    28579217 2017-02-04 19:15               Nicardipine 3 mcg/kg/min\n2    28579217 2011-10-02 22:11                Famotidine       4.5 mg\n3    28579217 2011-10-02 20:17          Morphine sulfate         1 mg\n4    28579217 2011-10-03 02:28 Diphenhydramine injection        12 mg\n5    28579217 2011-10-02 22:11                 Cefazolin       225 mg\n6    28579217 2011-10-02 23:30          Morphine sulfate         1 mg\n  med:route med:freq med:given\n1        IV     <NA>     Given\n2        IV   q12hrs     Given\n3        IV  q2h prn     Given\n4        IV      now     Given\n5        IV    q8hrs     Given\n6        IV  q2h prn     Given\n\nLaboratory raw data\nThe example laboratory data consists of files two files, Creatinine_DATA.csv and Albumin_DATA.csv. Both files are read in using the readTransform() function and Subject.uniq is renamed to subject_uid.\nEach laboratory file should be transformed so it contains a subject unique ID, a subject visit ID, or both ids.\n\n\n\n# Serum creatinine lab data\ncreat.in <- readTransform(file.path(rawDataDir, \"Creatinine_DATA.csv\"),\n    rename = c('Subject.uniq' = 'subject_uid'))\nhead(creat.in)\n\n\n  subject_uid     date time creat\n1    28579217 02/05/17 4:00  0.52\n2    28579217 02/06/17 5:00  0.53\n3    28579217 10/03/11 4:28  0.42\n4    28579217 10/04/11 4:15  0.35\n5    28579217 10/06/11 4:25  0.29\n6    28579217 10/09/11 4:45  0.28\n\n# Albumin lab data\nalb.in <- readTransform(file.path(rawDataDir, \"Albumin_DATA.csv\"),\n    rename = c('Subject.uniq' = 'subject_uid'))\nhead(creat.in)\n\n\n  subject_uid     date time creat\n1    28579217 02/05/17 4:00  0.52\n2    28579217 02/06/17 5:00  0.53\n3    28579217 10/03/11 4:28  0.42\n4    28579217 10/04/11 4:15  0.35\n5    28579217 10/06/11 4:25  0.29\n6    28579217 10/09/11 4:45  0.28\n\n(2) Merge data to create new ID variables\nidCrosswalk(): This function merges all of the cleaned input datasets and creates new IDs.\nInput:\nthe data= argument of this function accepts a list of input datasets\nthe idcols= argument accepts a list of vectors or character strings that identify the ID variables in the corresponding input dataset.\n\nOutput:\na crosswalk dataset between the original ID variables (subject_id, subject_uid) and the new ID variables (mod_id, mod_visit, and mod_id_visit).\nthe new variable mod_id_visit has a 1-to-1 correspondence to variable subject_id and uniquely identifies each subjects’ visit/course; the new variable mod_id has a 1-to-1 correspondence to variable subject_uid and uniquely identifies each subject.\n\n\n\n\n# define list of input datasets\ndata <-  list(demo.in,\n              samp.in,\n              conc.in,\n              flow.in,\n              mar.in,\n              creat.in,\n              alb.in)\n\n# define list of vectors or character strings that identify the ID variables\nidcols <-  list(c('subject_id', 'subject_uid'), # id vars in demo.in\n                'subject_id', # id var in samp.in\n                'subject_id', # id var in conc.in\n                c('subject_id', 'subject_uid'), # id vars in flow.in\n                'subject_uid', # id var in mar.in\n                'subject_uid', # id var in creat.in\n                'subject_uid') # id var in creat.in\n\n# merge all IDs from cleaned datasets and create new ID variables\nid.xwalk <- idCrosswalk(data, idcols, visit.id=\"subject_id\", uniq.id=\"subject_uid\")\nsaveRDS(id.xwalk, file=file.path(dataDir,\"module_id_xwalk.rds\"))\nhead(id.xwalk)\n\n\n  subject_id subject_uid mod_visit mod_id mod_id_visit\n1      466.0    28579217         1      1          1.1\n2      466.1    28579217         2      1          1.2\n3     1106.0    34364670         1      2          2.1\n4     1444.0    36792472         1      3          3.1\n5     1465.0    36292449         1      4          4.1\n6     1520.0    34161967         1      5          5.1\n\n(3) Make new data for use with modules\n\n\npullFakeId(dat, xwalk, firstCols = NULL, orderBy = NULL)\n\n\n\npullFakeId(): This function replaces the original IDs – subject_id and subject_uid – with new IDs – mod_id, mod_visit, and mod_id_visit – to create datasets which can be used by the data processing modules.\nThe dat= argument should contain the cleaned input data.frame from pre-processing step (1).\nThe xwalk= argument should contain the crosswalk data.frame produced in step (2).\nAdditional arguments firstCols= and orderBy= control which variables are in the first columns of the output and the sort order, respectively.\nThe cleaned, structured data are saved as R objects for use with the modules.\n\n\n\n## demographics data\ndemo.cln <- pullFakeId(demo.in, id.xwalk,\n    firstCols = c('mod_id', 'mod_visit', 'mod_id_visit'),\n    uniq.id = 'subject_uid')\nhead(demo.cln)\n\n\n  mod_id mod_visit mod_id_visit gender weight height surgery_date\n1      2         1          2.1      0   5.14  59.18    6/28/2014\n2      3         1          3.1      1   5.67  62.90    1/10/2016\n3      4         1          4.1      0  23.67 118.02    3/19/2016\n4      5         1          5.1      0  14.07  97.04    7/18/2016\n5      6         1          6.1      1  23.40 102.80    7/23/2016\n6      7         1          7.1      1   6.21  62.03     9/4/2016\n  ageatsurgery stat_sts cpb_sts in_hospital_mortality add_ecmo\n1          141        3     133                     0        0\n2          292        1      65                     0        0\n3         2591        2     357                     0        0\n4         1320        5      93                     0        0\n5         1561        3      87                     1        0\n6          208        1     203                     0        0\n  date_icu_dc time_fromor\n1    7/2/2014        1657\n2   1/12/2016        1325\n3   3/20/2016          NA\n4   7/19/2016        1745\n5   7/30/2016        1847\n6   9/11/2016        1210\n\nsaveRDS(demo.cln, file=file.path(dataDir,\"demo_mod_id.rds\"))\n\n## drug level data\n# sampling times\nsamp.cln <- pullFakeId(samp.in, id.xwalk,\n    firstCols = c('mod_id', 'mod_visit', 'mod_id_visit', 'samp'), \n    orderBy = c('mod_id_visit','samp'),\n    uniq.id = 'subject_uid')\nhead(samp.cln)\n\n\n  mod_id mod_visit mod_id_visit samp Event.Name\n1      1         2          1.2    1   Sample 1\n2      1         2          1.2    2   Sample 2\n3     10         1         10.1    1   Sample 1\n4     10         1         10.1    2   Sample 2\n5     10         1         10.1    3   Sample 3\n6     10         1         10.1    4   Sample 4\n  Sample.Collection.Date.and.Time\n1                  2/3/2017 10:46\n2                  2/4/2017 20:30\n3                12/23/2016 05:15\n4                12/24/2016 18:00\n5                12/25/2016 03:00\n6                12/26/2016 04:00\n\nsaveRDS(samp.cln, file=file.path(dataDir,\"samp_mod_id.rds\"))\n\n# drug concentration measurements\nconc.cln <- pullFakeId(conc.in, id.xwalk,\n    firstCols = c('record_id', 'mod_id', 'mod_visit', 'mod_id_visit', 'samp'),\n    orderBy = 'record_id',\n    uniq.id = 'subject_uid')\nhead(conc.cln)\n\n\n  record_id mod_id mod_visit mod_id_visit samp fentanyl_calc_conc\n1         1      1         2          1.2    1         0.01413622\n2         2      1         2          1.2    2         0.27982075\n3         3      2         1          2.1    1         6.11873679\n4         4      2         1          2.1    2         0.59161716\n5         5      2         1          2.1    3         0.11280471\n6         6      2         1          2.1    4         0.02112153\n\nsaveRDS(conc.cln, file=file.path(dataDir,\"conc_mod_id.rds\"))\n\n## dosing data\n# flow\nflow.cln <- pullFakeId(flow.in, id.xwalk,\n    firstCols = c('mod_id', 'mod_visit', 'mod_id_visit'),\n    uniq.id = 'subject_uid')\nhead(flow.cln)\n\n\n  mod_id mod_visit mod_id_visit     Perform.Date FOCUS_MEDNAME\n1      9         1          9.1   12/4/2016 5:30      Fentanyl\n2      9         1          9.1   12/4/2016 6:00      Fentanyl\n3      9         1          9.1   12/4/2016 7:00      Fentanyl\n4      9         1          9.1   12/4/2016 7:40      Fentanyl\n5     10         1         10.1 12/24/2016 19:30      Fentanyl\n6     10         1         10.1 12/24/2016 20:00      Fentanyl\n  Final.Wt..kg. Final.Rate..NFR.units. Final.Units Flow\n1          6.75            1 mcg/kg/hr       3.375   NA\n2          6.75            1 mcg/kg/hr       6.750  0.1\n3          6.75            1 mcg/kg/hr       4.500  0.1\n4          6.75            0 mcg/kg/hr       0.000   NA\n5          2.60            2 mcg/kg/hr       2.600   NA\n6          2.60            2 mcg/kg/hr       5.200  0.2\n\nsaveRDS(flow.cln, file=file.path(dataDir,\"flow_mod_id.rds\"))\n\n# mar\nmar.cln <- pullFakeId(mar.in, id.xwalk, firstCols = 'mod_id', uniq.id = 'subject_uid')\nhead(mar.cln)\n\n\n  mod_id       Date  Time                 med:mDrug   med:dosage\n1      1 2017-02-04 19:15               Nicardipine 3 mcg/kg/min\n2      1 2011-10-02 22:11                Famotidine       4.5 mg\n3      1 2011-10-02 20:17          Morphine sulfate         1 mg\n4      1 2011-10-03 02:28 Diphenhydramine injection        12 mg\n5      1 2011-10-02 22:11                 Cefazolin       225 mg\n6      1 2011-10-02 23:30          Morphine sulfate         1 mg\n  med:route med:freq med:given\n1        IV     <NA>     Given\n2        IV   q12hrs     Given\n3        IV  q2h prn     Given\n4        IV      now     Given\n5        IV    q8hrs     Given\n6        IV  q2h prn     Given\n\nsaveRDS(mar.cln, file=file.path(dataDir,\"mar_mod_id.rds\"))\n\n## laboratory data\n# creatinine\ncreat.cln <- pullFakeId(creat.in, id.xwalk, 'mod_id',uniq.id = 'subject_uid')\nhead(creat.cln)\n\n\n  mod_id     date time creat\n1      1 02/05/17 4:00  0.52\n2      1 02/06/17 5:00  0.53\n3      1 10/03/11 4:28  0.42\n4      1 10/04/11 4:15  0.35\n5      1 10/06/11 4:25  0.29\n6      1 10/09/11 4:45  0.28\n\nsaveRDS(creat.cln, file=file.path(dataDir,\"creat_mod_id.rds\"))\n\n# albumin\nalb.cln <- pullFakeId(alb.in, id.xwalk, 'mod_id', uniq.id = 'subject_uid')\nhead(alb.cln)\n\n\n  mod_id     date  time alb\n1      8 07/30/20  5:23 2.9\n2      8 07/28/20  3:12 2.0\n3      8 07/29/20  1:39 2.7\n4      8 08/21/20 10:35 4.1\n5      4 06/13/15 17:20 4.1\n6      6 07/25/16  8:35 2.3\n\nsaveRDS(alb.cln, file=file.path(dataDir,\"alb_mod_id.rds\"))\n\n\n\nOptions and parameters: Before running the processing modules, it is necessary to define several options and parameters.\nUsing options(pkxwalk =) allows the modules to access the crosswalk file.\nCreate a drugname stub.\nDefine the lower limit of quantification (LLOQ) for the drug concentration if applicable.\n\n\n\n# set crosswalk option \nxwalk <- readRDS(file.path(dataDir, \"module_id_xwalk.rds\"))\noptions(pkxwalk = 'xwalk')\n\n# define parameters\ndrugname <- 'fent'\nLLOQ <- 0.05\n\n\n\nPro-Demographic\nThis module accepts the cleaned structured demographic dataset and a user-defined set of exclusion criteria and returns a formatted list with the demographic data and records meeting the exclusion criteria suitable for integration with the other modules.\nFor this example, we exclude subjects with a value of 1 for in_hospital_mortality or add_ecmo and create a new variable called length_of_icu_stay.\nrun_Demo() is the function to run this module.\n\n\n# helper function\nexclude_val <- function(x, val=1) { !is.na(x) & x == val }\n\ndemo.out <- run_Demo(demo.path = file.path(dataDir, \"demo_mod_id.rds\"),\n    toexclude = expression(exclude_val(in_hospital_mortality) | exclude_val(add_ecmo)),\n    demo.mod.list = list(length_of_icu_stay = \n                        expression(daysDiff(surgery_date, date_icu_dc))))\n\n\nThe number of subjects in the demographic data, who meet the exclusion criteria: 2\n\nhead(demo.out$demo)\n\n\n  mod_id mod_visit mod_id_visit gender weight height surgery_date\n1      2         1          2.1      0   5.14  59.18    6/28/2014\n2      3         1          3.1      1   5.67  62.90    1/10/2016\n3      4         1          4.1      0  23.67 118.02    3/19/2016\n4      5         1          5.1      0  14.07  97.04    7/18/2016\n5      6         1          6.1      1  23.40 102.80    7/23/2016\n6      7         1          7.1      1   6.21  62.03     9/4/2016\n  ageatsurgery stat_sts cpb_sts in_hospital_mortality add_ecmo\n1          141        3     133                     0        0\n2          292        1      65                     0        0\n3         2591        2     357                     0        0\n4         1320        5      93                     0        0\n5         1561        3      87                     1        0\n6          208        1     203                     0        0\n  date_icu_dc time_fromor length_of_icu_stay\n1    7/2/2014        1657                  4\n2   1/12/2016        1325                  2\n3   3/20/2016          NA                  1\n4   7/19/2016        1745                  1\n5   7/30/2016        1847                  7\n6   9/11/2016        1210                  7\n\ndemo.out$exclude\n\n\n[1] \"6.1\"  \"13.1\"\n\nPro-Med-Str Part I: IV dose data\nThis module processes structured medication data. Only Part I which handles IV dose data is described here. For processing structure e-prescription medication data, see Pro-Med-Str - Part II.\nThe IV dose data comes from two sources:\nFlow data: patient flow sheets which at this institution record infusion rates and changes to all infusions for all inpatients outside of the operating room.\nMedication Administration Records (MAR) data: This data record all bolus doses of medications and infusions administered in the operating room.\n\nThe module is semi-interactive – it generates several files to check potential data errors and get feedback from an investigator. If corrected information (‘fix’ files) are provided, the module should be re-run to incorporate the corrections.\nrun_MedStrI() is the function to process IV dose data.\n\n\nivdose.out <- run_MedStrI(flow.path=file.path(dataDir,\"flow_mod_id.rds\"), \n    flow.select = c('mod_id','mod_id_visit','Perform.Date','Final.Wt..kg.',\n                    'Final.Rate..NFR.units.','Final.Units'),\n    flow.rename = c('mod_id','mod_id_visit', 'Perform.Date', 'weight',\n                    'rate', 'final.units'),\n    flow.mod.list = list(\n      date.time = expression(parse_dates(fixDates(Perform.Date))),\n      unit = expression(sub('.*[ ]', '', rate)),\n      rate = expression(as.numeric(sub('([0-9.]+).*', '\\\\1', rate)))),\n    medchk.path=file.path(rawDataDir, sprintf('medChecked-%s.csv', drugname)), \n    mar.path=file.path(dataDir,\"mar_mod_id.rds\"),\n    demo.list=NULL,\n    check.path=checkDir, \n    failflow_fn = 'FailFlow',\n    failunit_fn = 'Unit',\n    failnowgt_fn = 'NoWgt',\n    infusion.unit = 'mcg/kg/hr',\n    bolus.unit = 'mcg',\n    bol.rate.thresh = Inf,\n    drugname = drugname)\n\n\nThe number of rows in the original data                124\nThe number of rows after removing the duplicates       124\nno units other than mcg/kg/hr or mcg, file /tmp/RtmpsUWI4h/checks/failUnit-fent.csv not created\n#########################\n33 rows from 1 subjects with \"kg\" in infusion unit but missing weight, see file /tmp/RtmpsUWI4h/checks/failNoWgt-fent.csv AND create /tmp/RtmpsUWI4h/checks/fixNoWgt-fent.csv\n#########################\n\nhead(ivdose.out)\n\n\n  mod_id  date.dose infuse.time.real infuse.time infuse.dose\n1      1 2011-10-02             <NA>        <NA>          NA\n2      1 2011-10-02             <NA>        <NA>          NA\n3      1 2017-02-04             <NA>        <NA>          NA\n4      1 2017-02-04             <NA>        <NA>          NA\n5      1 2017-02-04             <NA>        <NA>          NA\n6      2 2014-06-28             <NA>        <NA>          NA\n           bolus.time bolus.dose given.dose maxint weight\n1 2011-10-02 15:35:00         25         NA      0     NA\n2 2011-10-02 17:26:00         25         NA      0     NA\n3 2017-02-04 16:15:00         50         NA      0     NA\n4 2017-02-04 16:30:00         20         NA      0     NA\n5 2017-02-04 20:57:00         20         NA      0     NA\n6 2014-06-28 08:15:00         20         NA      0     NA\n\nPro-Drug Level\nThis module processes drug concentration data that can be merged with medication dose data and other types of data.\nThis module is semi-interactive – it generates several files while processing in order to check missing data and potential data errors, and get feedback from an investigator. If corrected information (‘fix’ files) are provided, the module should be re-run to incorporate the corrections.\nrun_DrugLevel is the function to process the drug concentration data.\n\n\nconc.out <- run_DrugLevel(conc.path=file.path(dataDir,\"conc_mod_id.rds\"),\n    conc.select=c('mod_id','mod_id_visit','samp','fentanyl_calc_conc'),\n    conc.rename=c(fentanyl_calc_conc = 'conc.level', samp= 'event'),\n    conc.mod.list=list(mod_id_event = expression(paste(mod_id_visit, event, sep = '_'))),\n    samp.path=file.path(dataDir,\"samp_mod_id.rds\"),\n    samp.mod.list=list(mod_id_event = expression(paste(mod_id_visit, samp, sep = '_'))),\n    check.path=checkDir,\n    failmiss_fn = 'MissingConcDate-',\n    multsets_fn = 'multipleSetsConc-',\n    faildup_fn = 'DuplicateConc-',\n    drugname=drugname,\n    LLOQ=LLOQ,\n    demo.list=demo.out)\n\n\n#########################\n3 rows need review, see file /tmp/RtmpsUWI4h/checks/failMissingConcDate-fent.csv AND create /tmp/RtmpsUWI4h/checks/fixMissingConcDate-fent.csv\n#########################\nsubjects with concentration missing from sample file\n mod_id mod_id_event\n      8        8.1_1\n      8        8.1_2\n      8        8.1_3\n1 subjects have multiple sets of concentration data\n16 total unique subjects ids (including multiple visits) currently in the concentration data\n15 total unique subjects in the concentration data\n#########################\n15 rows need review, see file /tmp/RtmpsUWI4h/checks/multipleSetsConc-fent2021-08-19.csv\n#########################\n15 total unique subjects ids (after excluding multiple visits) in the concentration data\n15 total unique subjects in the concentration data\n\nhead(conc.out)\n\n\n   mod_id mod_id_visit event  conc.level mod_id_event\n1       1          1.2     1 0.014136220        1.2_1\n2       1          1.2     2 0.279820752        1.2_2\n55     10         10.1     2 3.136047304       10.1_2\n56     10         10.1     9 0.004720171       10.1_9\n57     10         10.1    10 0.017136367      10.1_10\n58     10         10.1    12 0.006335571      10.1_12\n             date.time eid\n1  2017-02-03 10:46:00   1\n2  2017-02-04 20:30:00   1\n55 2016-12-24 18:00:00   1\n56 2017-01-01 04:20:00   1\n57 2017-01-02 04:42:00   1\n58 2017-01-04 03:40:00   1\n\nThe output provides a message that 3 rows are missing concentration date. The file ‘failMissingConcDate-fent.csv’ contains the 3 records with missing values for the date.time variable.\n\n\n( fail.miss.conc.date <- read.csv(file.path(checkDir,\"failMissingConcDate-fent.csv\")) )\n\n\n  subject_id subject_uid mod_id_event date.time\n1       1566    35885929        8.1_1        NA\n2       1566    35885929        8.1_2        NA\n3       1566    35885929        8.1_3        NA\n\nWe can correct the missing dates by providing an updated file called ‘fixMissingConcDate-fent.csv’ that contains the missing data.\n\n\nfail.miss.conc.date[,\"date.time\"] <- c(\"9/30/2016 09:32\",\"10/1/2016 19:20\",\"10/2/2016 02:04\")\nfail.miss.conc.date\n\n\n  subject_id subject_uid mod_id_event       date.time\n1       1566    35885929        8.1_1 9/30/2016 09:32\n2       1566    35885929        8.1_2 10/1/2016 19:20\n3       1566    35885929        8.1_3 10/2/2016 02:04\n\nwrite.csv(fail.miss.conc.date, file.path(checkDir,\"fixMissingConcDate-fent.csv\"))\n\n\n\nAfter providing the updated file, the same run_DrugLevel() function should be re-run. The output now contains an additional message below the first message saying “fixMissingConcDate-fent.csv read with failures replaced”. The conc.out data.frame also contains 3 additional rows with the corrected data.\n\n\nconc.out <- run_DrugLevel(conc.path=file.path(dataDir,\"conc_mod_id.rds\"),\n    conc.select=c('mod_id','mod_id_visit','samp','fentanyl_calc_conc'),\n    conc.rename=c(fentanyl_calc_conc = 'conc.level', samp= 'event'),\n    conc.mod.list=list(mod_id_event = expression(paste(mod_id_visit, event, sep = '_'))),\n    samp.path=file.path(dataDir,\"samp_mod_id.rds\"),\n    samp.mod.list=list(mod_id_event = expression(paste(mod_id_visit, samp, sep = '_'))),\n    check.path=checkDir,\n    failmiss_fn = 'MissingConcDate-',\n    multsets_fn = 'multipleSetsConc-',\n    faildup_fn = 'DuplicateConc-', \n    drugname=drugname,\n    LLOQ=LLOQ,\n    demo.list=demo.out)\n\n\n#########################\n3 rows need review, see file /tmp/RtmpsUWI4h/checks/failMissingConcDate-fent.csv AND create /tmp/RtmpsUWI4h/checks/fixMissingConcDate-fent.csv\n#########################\nfile /tmp/RtmpsUWI4h/checks/fixMissingConcDate-fent.csv read with failures replaced\nsubjects with concentration missing from sample file\n[1] mod_id       mod_id_event\n<0 rows> (or 0-length row.names)\n1 subjects have multiple sets of concentration data\n16 total unique subjects ids (including multiple visits) currently in the concentration data\n15 total unique subjects in the concentration data\n#########################\n15 rows need review, see file /tmp/RtmpsUWI4h/checks/multipleSetsConc-fent2021-08-19.csv\n#########################\n15 total unique subjects ids (after excluding multiple visits) in the concentration data\n15 total unique subjects in the concentration data\n\nPro-Laboratory\nThis module processes laboratory data that can be merged with data from other modules.\nrun_Labs() is the function to process the laboratory data.\n\n\ncreat.out <- run_Labs(lab.path=file.path(dataDir,\"creat_mod_id.rds\"),\n    lab.select = c('mod_id','date.time','creat'),\n    lab.mod.list = list(date.time = expression(parse_dates(fixDates(paste(date, time))))))\n\nalb.out <- run_Labs(lab.path=file.path(dataDir,\"alb_mod_id.rds\"),\n    lab.select = c('mod_id','date.time','alb'),\n    lab.mod.list = list(date.time = expression(parse_dates(fixDates(paste(date, time))))))\n\nlab.out <- list(creat.out, alb.out)\n\nstr(lab.out)\n\n\nList of 2\n $ :'data.frame':   266 obs. of  3 variables:\n  ..$ mod_id   : int [1:266] 1 1 1 1 1 1 1 1 1 1 ...\n  ..$ date.time: POSIXct[1:266], format: \"2017-02-05 04:00:00\" ...\n  ..$ creat    : num [1:266] 0.52 0.53 0.42 0.35 0.29 0.28 0.34 0.59 0.54 0.26 ...\n $ :'data.frame':   44 obs. of  3 variables:\n  ..$ mod_id   : int [1:44] 8 8 8 8 4 6 6 9 10 10 ...\n  ..$ date.time: POSIXct[1:44], format: \"2020-07-30 05:23:00\" ...\n  ..$ alb      : num [1:44] 2.9 2 2.7 4.1 4.1 2.3 2.6 3 3.1 4.2 ...\n\nBuild-PK-IV\nThis module creates PK data for IV medications.\nBoth dose data in the format output from the Pro-Med-Str1 module and concentration data in the format output from the Pro-DrugLevel module are required.\nDemographic data from the Pro-Demographic module and laboratory data from the Pro-Laboratory module are optional.\nThe module is semi-interactive – it generates several files to check potential data errors, and get feedback from an investigator. If corrected information (‘fix’ files) are provided, the module should be re-run to incorporate the corrections.\nrun_Build_PK_IV() is the function to build PK data with IV dosing data.\n\n\npk_dat <- run_Build_PK_IV(\n    conc=conc.out,\n    dose=ivdose.out,\n    demo.list=demo.out,\n    demo.vars=c('weight', 'weight_demo', 'height', 'gender',\n                'ageatsurgery', 'stat_sts', 'cpb_sts',\n                'length_of_icu_stay'),\n    demo.abbr=c('wgt', 'wgt_demo', 'height', 'gender',\n                'age', 'stat', 'cpb', 'loi'),\n    lab.dat = lab.out,\n    lab.vars = c('creat','alb'),\n    pk.vars=c('mod_id_visit', 'time', 'conc', 'dose', 'rate', 'event',\n              'other', 'multiple.record', 'date', 'mod_id'),\n    drugname=drugname,\n    check.path=checkDir,\n    missdemo_fn='-missing-demo',\n    faildupbol_fn='DuplicateBolus-',\n    date.format=\"%m/%d/%y %H:%M:%S\",\n    date.tz=\"America/Chicago\")\n\n\n0 duplicated rows\nThe dimension of the PK data before merging with demographics: 234 x 9\nThe number of subjects in the PK data before merging with demographics: 15\nThe number of subjects in the demographic file, who meet the exclusion criteria: 2\ncheck NA frequency in demographics, see file /tmp/RtmpsUWI4h/checks/fent-missing-demo.csv\nList of IDs missing at least 1 cpb_sts: 12.1\nThe list of final demographic variables: weight\nweight_demo\nheight\ngender\nageatsurgery\nstat_sts\ncpb_sts\nlength_of_icu_stay\nChecked: there are no missing creat\nList of IDs missing at least 1 alb: 1.2\n11.1\n15.1\n2.1\n3.1\n4.1\n5.1\n7.1\n8.1\nThe dimension of the final PK data exported with the key demographics: 197 x 17 with 13 distinct subjects (mod_id_visit)\n\nRetrieving the original IDs:\nThe function pullRealId() appends the original IDs – subject_id and subject_uid to the data.\nThe parameter remove.mod.id=TRUE can be used to also remove any module IDs – mod_id, mod_visit, and mod_id_visit.\n\n\n\n# convert id back to original IDs\npk_dat <- pullRealId(pk_dat, remove.mod.id=TRUE)\n\nhead(pk_dat)\n\n\n     subject_id subject_uid time      conc   amt rate mdv evid   wgt\n2         466.1    28579217 0.00        NA  50.0  0.0   1    1 21.99\n2.1       466.1    28579217 0.25        NA  20.0  0.0   1    1 21.99\n2.2       466.1    28579217 4.25 0.2798208    NA   NA   0    0 21.99\n12       1607.0    38551767 0.00        NA 109.2 10.4   1    1  2.60\n12.1     1607.0    38551767 0.00        NA  10.0  0.0   1    1  2.60\n12.2     1607.0    38551767 1.25        NA  15.0  0.0   1    1  2.60\n     wgt_demo height gender  age stat cpb loi creat alb\n2       21.99 116.90      0 2451    1 107   1  0.54  NA\n2.1     21.99 116.90      0 2451    1 107   1  0.54  NA\n2.2     21.99 116.90      0 2451    1 107   1  0.54  NA\n12       2.76  45.94      0   23    3 110  12  0.66 1.6\n12.1     2.76  45.94      0   23    3 110  12  0.66 1.6\n12.2     2.76  45.94      0   23    3 110  12  0.66 1.6\n\nReferences\nChoi L, Beck C, McNeer E, Weeks HL, Williams ML, James NT, Niu X, Abou-Khalil BW, Birdwell KA, Roden DM, Stein CM. Development of a System for Post-marketing Population Pharmacokinetic and Pharmacodynamic Studies using Real-World Data from Electronic Health Records. Clinical Pharmacology & Therapeutics. 2020 Apr;107(4):934-43. doi: 10.1002/cpt.1787.\n\n\n\n",
      "last_modified": "2021-08-19T09:19:29-05:00"
    },
    {
      "path": "Build-PK-IV-simple.html",
      "title": "Build-PK-IV - Simple",
      "description": "This tutorial describes a simple pharmacokinetic data building procedure without using additional data processing modules for medications that are intravenously administered.\n",
      "author": [
        {
          "name": "Nathan T. James, Leena Choi",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nIntroduction\nQuick Data Building with Processed Datasets\n\nHere add links to vignettes\nSee also “Example 1: Quick Data Building with Processed Datasets” of “2. EHR Vignette for Structured Data” in EHR package\nIntroduction\nThis tutorial describes a simple pharmacokinetic (PK) data building procedure in EHRtoPKPD for medications that are intravenously (IV) administered. It demonstrates how to quickly build PK data using Build-PK-IV when cleaned data for concentration, drug dose, demographic and laboratory datasets are available in the appropriate data format. A comprehensive PK data building procedure with Build-PK-IV for IV medications that requires several data processing modules is described in Build-PK-IV - Comprehensive (see Choi et al.\\(^{1}\\) for details).\nTo begin we load the EHR package, the pkdata package, and the lubridate package.\n\n\n# load EHR package and dependencies\nlibrary(EHR)\nlibrary(pkdata)\nlibrary(lubridate)\n\n\n\nQuick Data Building with Processed Datasets\nThere are four basic steps to build a PK dataset quickly.\n(1) First define directories\na directory for the raw data\na directory for interactive checking output files\n\n\n# define directories\nrawDataDir <- system.file(\"examples\", \"str_ex1\", package=\"EHR\")\ntd <- tempdir()\ndir.create(file.path(td, 'check1'))\ncheckDir <- file.path(td, 'check1')\n\n\n\n(2) Prepare cleaned and appropriately formatted data files and load the data files\nan IV dosing file\na drug concentration file\na demographic file\na laboratory file (optional)\n\n\n# read in data\nivdose.data <- read.csv(file.path(rawDataDir,\"IVDose_DATA_simple.csv\"),stringsAsFactors = FALSE)\nhead(ivdose.data, 3)\n\n\n  patient_id  date.dose    infuse.time.real         infuse.time\n1          1 2009-10-18 2009-10-18 11:35:00 2009-10-18 12:00:00\n2          1 2009-10-18 2009-10-18 12:00:00 2009-10-18 12:00:00\n3          1 2009-10-18 2009-10-18 13:00:00 2009-10-18 13:00:00\n  infuse.dose bolus.time bolus.dose given.dose maxint weight\n1         8.8       <NA>         NA          0     60    4.4\n2         8.8       <NA>         NA          0     60    4.4\n3         8.8       <NA>         NA          0     60    4.4\n\nconc.data <- read.csv(file.path(rawDataDir,\"Concentration_DATA_simple.csv\"),stringsAsFactors = FALSE)\nhead(conc.data, 3)\n\n\n  patient_id patient_visit_id event conc.level           date.time\n1         10             10.1     4       0.17 2019-02-02 05:30:00\n2         10             10.1     2       4.05 2019-02-24 14:00:00\n3         10             10.1     3       0.64 2019-02-25 03:30:00\n\ndemo <- read.csv(file.path(rawDataDir,\"Demographics_DATA_simple.csv\"),stringsAsFactors = FALSE)\nhead(demo, 3)\n\n\n  patient_id patient_visit_id gender weight height surgery_date\n1          2              2.1      1  62.99 179.72    6/20/2015\n2          3              3.1      0   7.71  72.99   12/15/2018\n3          4              4.1      1  12.00  92.02    1/12/2018\n  ageatsurgery stat_sts cpb_sts date_icu_dc time_fromor\n1         6245        2      80   6/22/2015          NA\n2          574        3      67  12/16/2018          NA\n3         1214        1      70   1/13/2018          NA\n  length_of_icu_stay\n1                  2\n2                  1\n3                  1\n\ncreat.data <- read.csv(file.path(rawDataDir,\"Creatinine_DATA_simple.csv\"),stringsAsFactors = FALSE)\nhead(creat.data, 3)\n\n\n  patient_id           date.time creat\n1          2 2015-06-23 04:35:00  0.75\n2          2 2015-06-22 04:00:00  0.69\n3          2 2015-06-21 01:55:00  0.78\n\n(3) Rename ID variables with standardized names\nThe EHR package modules use a standardized naming convention for patient identification (ID) variables. We rename the unique patient-level ID from patient_id to mod_id and the visit-level ID from patient_visit_id to mod_id_visit. If there is only a single visit/course per subject, the unique patient-level ID and visit-level ID can be the same, however both mod_id and mod_id_visit should be defined.\n\n\n# rename ID variables\nnames(conc.data)[1:2] <- names(demo)[1:2] <- c(\"mod_id\", \"mod_id_visit\")\nnames(creat.data)[1] <- names(ivdose.data)[1] <- \"mod_id\"\n\n\n\n(4) Build a final PK dataset with the function run_Build_PK_IV() using the prepared datasets above\nNotice that the data building function generates an automatic message that tells some information about the data processing as well as the final dataset including the variables, the sample size, and missingness - see the message below.\n\n\n# running run_Build_PK_IV()\nsimple_pk_dat <- run_Build_PK_IV(\n    conc=conc.data,\n    dose=ivdose.data,\n    demo.list = demo,\n    demo.vars=c('weight', 'weight_demo', 'height', 'gender', 'ageatsurgery',\n                'stat_sts', 'cpb_sts', 'length_of_icu_stay'),\n    demo.abbr=c('wgt', 'wgt_demo', 'height', 'gender',\n                'age', 'stat', 'cpb', 'loi'),\n    lab.dat = list(creat.data),\n    lab.vars = c('creat'),\n    pk.vars=c('mod_id_visit', 'time', 'conc', 'dose', 'rate', 'event',\n              'other', 'multiple.record', 'date', 'mod_id'),\n    drugname='fent',\n    check.path=checkDir)\n\n\n0 duplicated rows\nThe dimension of the PK data before merging with demographics: 149 x 9\nThe number of subjects in the PK data before merging with demographics: 10\nThe number of subjects in the demographic file, who meet the exclusion criteria: 0\ncheck NA frequency in demographics, see file /var/folders/06/0qv1dr5508j_tbzqdjfqjf680000gn/T//Rtmp04oFz0/check1/fent-missing-demo.csv\nList of IDs missing at least 1 cpb_sts: \nChecked: all missing cpb_sts are 0\nThe list of final demographic variables: weight\nweight_demo\nheight\ngender\nageatsurgery\nstat_sts\ncpb_sts\nlength_of_icu_stay\nChecked: there are no missing creat\nThe dimension of the final PK data exported with the key demographics: 149 x 16 with 10 distinct subjects (mod_id_visit)\n\n\n\n# the final PK dataset\nhead(simple_pk_dat,15)\n\n\n   mod_id_visit  time conc amt rate mdv evid   wgt wgt_demo height\n1           1.2  0.00   NA  50    0   1    1 25.04    25.04 114.39\n2           1.2  0.75   NA 100    0   1    1 25.04    25.04 114.39\n3           1.2  1.65   NA 100    0   1    1 25.04    25.04 114.39\n4           1.2  1.77   NA 250    0   1    1 25.04    25.04 114.39\n5           1.2  2.05   NA 250    0   1    1 25.04    25.04 114.39\n6           1.2  3.72   NA 250    0   1    1 25.04    25.04 114.39\n7           1.2  5.23   NA 100    0   1    1 25.04    25.04 114.39\n8           1.2  6.25 2.83  NA   NA   0    0 25.04    25.04 114.39\n9           1.2 20.68 0.41  NA   NA   0    0 25.04    25.04 114.39\n10          1.2 70.90 0.04  NA   NA   0    0 25.04    25.04 114.39\n11          1.2 95.25 0.01  NA   NA   0    0 25.04    25.04 114.39\n12         10.1  0.00   NA  25    0   1    1  6.06     6.06  63.20\n13         10.1  0.52   NA 100    0   1    1  6.06     6.06  63.20\n14         10.1  1.42   NA  25    0   1    1  6.06     6.06  63.20\n15         10.1  2.77   NA  50    0   1    1  6.06     6.06  63.20\n   gender  age stat cpb loi creat\n1       1 2295    2  79   1  0.60\n2       1 2295    2  79   1  0.60\n3       1 2295    2  79   1  0.60\n4       1 2295    2  79   1  0.60\n5       1 2295    2  79   1  0.60\n6       1 2295    2  79   1  0.60\n7       1 2295    2  79   1  0.60\n8       1 2295    2  79   1  0.60\n9       1 2295    2  79   1  0.50\n10      1 2295    2  79   1  0.54\n11      1 2295    2  79   1  0.57\n12      0  209    1 195   5  0.64\n13      0  209    1 195   5  0.64\n14      0  209    1 195   5  0.64\n15      0  209    1 195   5  0.64\n\nReferences\nChoi L, Beck C, McNeer E, Weeks HL, Williams ML, James NT, Niu X, Abou-Khalil BW, Birdwell KA, Roden DM, Stein CM. Development of a System for Post-marketing Population Pharmacokinetic and Pharmacodynamic Studies using Real-World Data from Electronic Health Records. Clinical Pharmacology & Therapeutics. 2020 Apr;107(4):934-43. doi: 10.1002/cpt.1787.\n\n\n\n",
      "last_modified": "2021-08-19T08:55:06-05:00"
    },
    {
      "path": "Build-PK-Oral.html",
      "title": "Build-PK-Oral",
      "description": "This tutorial describes the PK data building module in the system for medications that are typically orally administrated. It demonstrates how to quickly build PK data using *Build-PK-Oral* when drug dose data that can be provided by users or generated from unstructured clinical notes using extracted dosing information with the *Extract-Med* module and processed with the *Pro-Med-NLP* module in the system.\n",
      "author": [
        {
          "name": "Michael L. Williams",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nIntroduction\nPopulation PK/PD Data Format\nEHR Sourced Oral Dosing Data\nBuild-PK-Oral\n\nHere add links to vignettes\nSee also “4. EHR Vignette for Build-PK-Oral” in EHR package\nIntroduction\nWe briefly describe a data format typically used in pharmacokinetics (PK), pharmacodynamics (PD) modeling. Then, we describe oral dosing data commonly obtained from electronic health records (EHRs) in the presence of last dose time and absense of last dose time information. Finally, we explain how to run Build-PK-Oral module.\nPopulation PK/PD Data Format\nSoftware performing population PK/PD modeling typically requires data to be in roughly the same format, following the data requirement for NONMEM as NONMEM has been used for a long time and considered as the gold standard software to perform population PK/PD analysis. Here is an example of data which is in a suitable format for analysis in NONMEM.\n\n   CID   time conc dose addl II mdv age\n1    1    0.0   NA 10.0   27 12   1  46\n2    1  336.0 16.1   NA   NA NA   0  46\n3    1  336.5   NA 10.0  139 12   1  46\n4    1 2015.0  6.4   NA   NA NA   0  46\n5    1 2015.5   NA  5.0  105 12   1  46\n6    1 3287.0  5.6   NA   NA NA   0  46\n7    1 3287.5   NA  5.0  285 12   1  46\n8    1 6720.0  6.6   NA   NA NA   0  46\n9    1 6720.5   NA  5.0  265 12   1  46\n10   1 9911.0  5.0   NA   NA NA   0  46\n11   2    0.0   NA 10.0   27 12   1  72\n12   2  336.0 15.1   NA   NA NA   0  72\n13   2  336.5   NA 10.0   65 12   1  72\n14   2 1128.0 11.7   NA   NA NA   0  72\n15   2 1128.5   NA  7.5   25 12   1  72\n16   2 1440.0  2.9   NA   NA NA   0  72\n17   2 1440.5   NA  2.5   29 12   1  72\n18   2 1800.0  2.2   NA   NA NA   0  72\n19   2 1800.5   NA  2.5   29 12   1  72\n20   2 2160.0  4.3   NA   NA NA   0  72\n21   3    0.0   NA  2.5   27 12   1  56\n22   3  336.0  3.4   NA   NA NA   0  56\n23   3  336.5   NA  2.5  159 12   1  56\n24   3 2256.0 10.2   NA   NA NA   0  56\n25   3 2256.5   NA  7.5   17 12   1  56\n26   3 2472.0  7.5   NA   NA NA   0  56\n\nThis simple example has two types of data rows, dose events (information concerning dosing) and concentration events (information concerning blood concentration levels for the drug of interest). The columns indicate the following information:\nCID: unique identifier for each individual in the dataset.\ntime: time of either dosing or concentration measurement.\nconc: drug blood concentration, NA for a dose event.\ndose: dose amount, we are concerned solely with oral dosing in this module, NA for concentration events.\naddl: additional doses, the number of times for an oral dose to be repeated.\nII: interdose interval, the amount of time between each additional dose.\nmdv: missing dependent variable; 1 for indicating that there is no dependent variable (in this case, blood concentration).\nage: each column can have covariates; these can be time varying or fixed within individual.\nTaking the first row as an example, which is a dose event, a dose of 10 mg is taken at time 0 then 27 additional doses are taken every 12 hours (time can take any unit). If we calculate each of these 27 doses then we see that the final dose is given at time=324, 12 hours before the measured concentration of 16.1 in row 2. Of course this same dosing information could be expressed in 28 rows, (10 mg at time 0, 10 mg at time 12, 10 mg at time 24, etc.) but this more compact form is preferable in the presence of a regular dosing interval.\nEHR Sourced Oral Dosing Data\nNow that we know an appropriate form which our data ultimately needs to take, we can consider how the data looks in it’s raw form. Drug dose information can be obtained from structured e-prescription databases, or extracted from clinical notes using the module Extract-Med (see Extract-Med to understand that process). The obtained dose information can be processing using Part II of Pro-Med-Str for the one from e-prescription databases and Pro-Med-NLP for the one extracted from clinical notes. Other data can be also processed using relevant modules (e.g., Pro-Drug Level, Pro-Laboratory). Our interest is in the intermediate dataset generated by these modules but not yet in the form presented above. Here is an example of such data.\n\n\nex\n\n\n   id                  dt dose_morn conc age weight  hgb\n1   1 2019-02-27 10:00:00      10.0 16.1  46    154 12.0\n2   1 2019-05-08 10:00:00       5.0  6.4  46    154 12.0\n3   1 2019-06-30 10:00:00       5.0  5.6  46    154 12.0\n4   1 2019-11-20 10:00:00       5.0  6.6  46    154 12.0\n5   1 2020-04-01 10:00:00       2.5  5.0  46    154 12.0\n6   2 2020-04-10 10:00:00      10.0 15.1  72    193  8.6\n7   2 2020-05-13 10:00:00       7.5 11.7  72    193  8.6\n8   2 2020-05-26 10:00:00       2.5  2.9  72    193  8.6\n9   2 2020-06-10 10:00:00       2.5  2.2  72    193  8.6\n10  2 2020-06-25 10:00:00       2.5  4.3  72    193  8.6\n11  3 2020-07-07 10:00:00       2.5  3.4  56    167 12.2\n12  3 2020-09-25 10:00:00       7.5 10.2  56    167 12.2\n13  3 2020-10-04 10:00:00       5.0  7.5  56    167 12.2\n                    ld\n1  2019-02-26 22:00:00\n2  2019-05-07 18:00:00\n3                 <NA>\n4  2019-11-19 18:00:00\n5                 <NA>\n6                 <NA>\n7  2020-05-12 21:00:00\n8                 <NA>\n9                 <NA>\n10                <NA>\n11                <NA>\n12 2020-09-24 22:00:00\n13                <NA>\n\nThe ID, time, and covariate data in this dataframe is self explanatory. The difficult data to deal with can be found in dose_morn, conc, and ld. conc is a measured blood concentration which is recorded at the time indicated in time. dose_morn is the dose which was taken in the morning of that measured concentration, as extracted by Extract-Med. ld is the last-dose time, the extracted time of the dose which precedes the measured concentration, if present in the EHR. This information can be used to construct a course of drug dosing but some assumptions need to be made. Consider the two following assumptions:\nDosing only occurs on the morning of the recorded dose.\nDosing occurs twice daily at 8am and 8pm.\nObviously, the correct assumption will depend on the drug of interest – some drugs are taken on a regular schedule, while others are as needed. Drugs undergoing routine therapeutic drug monitoring tend to be the latter so assumption 2 will likely be the better assumption.\nIf a twice-daily dosing assumption is appropriate, then we can begin to think about how to best choose the timing of each dose. Can we exploit some information in our dataset to determine dose timings which are more realistic than, say every day 8am and 8pm. In doing so we need to remember that the timing of the dose before the measured concentration is most important for estimating the PK profile. Some other things to consider:\nThe timing of the concentration measurement itself may impact dosing.\nThere may or may not be an extracted last-dose time to work with.\nFor this reason, we will break up our algorithm into with and without last-dose times and discuss how we arrive at a final dose-building algorithm.\nWithout Last-Dose Times\nWhen we do not have an extracted last-dose time, we must work off of only our measured concentration timing and assumptions about how routine therapeutic drug monitoring is typically performed. The majority of these labs are conducted in the morning, and patients will typically hold off on taking their medications until after the blood draw. For that reason, we assume that a dose is taken 30 minutes after a measured blood concentration, then proceeds with a dose every 12 hours. The final dose in the sequence will occur 6-18 hours before the next measured concentration, the timing of which will determine the next sequence of doses, and so on until the final measured concentration. The first measured concentration requires special attention. Typical therapeutic drug monitoring procedure suggests it is reasonable to assume that the drug has been taken regularly before this first concentration. The safest assumptiom, assuming no further information is available, is that the drug has been taken every 12 hours for long enough to reach a steady state of trough concentrations. In our PK dose building algorithm, we use a default of 336 hours (i.e., 14 days), ending 12 hours before the first measured concentration.\nWith Last-Dose times\nIn the case where extracted last-dose times are available, we can begin by building the same dataset as without last-dose times. We then add a row for a dose corresponding to the extracted last dose time and eliminate an appropriate number of doses from the preceding dose sequence to avoid incorrect double-dosing; this is done by removing doses until the last dose in the sequence is 6-18 hours before the extracted last-dose time. This allows for last-dose times which are more than 12 hours before the extracted concentration to be appropriately accounted for.\nBuild-PK-Oral\nWe now describe how to build the PK data without last-dose time and with last-dose time, both of which can be built using run_Build_PK_Oral() by defining the argument ldCol differently.\nTo begin we load the EHR package, the pkdata package, and the lubridate package.\n\n\n# load EHR package and dependencies\nlibrary(EHR)\nlibrary(pkdata)\nlibrary(lubridate)\n\n\n\nLet’s have another look at the example data we want to process:\n\n\nex\n\n\n   id                  dt dose_morn conc age weight  hgb\n1   1 2019-02-27 10:00:00      10.0 16.1  46    154 12.0\n2   1 2019-05-08 10:00:00       5.0  6.4  46    154 12.0\n3   1 2019-06-30 10:00:00       5.0  5.6  46    154 12.0\n4   1 2019-11-20 10:00:00       5.0  6.6  46    154 12.0\n5   1 2020-04-01 10:00:00       2.5  5.0  46    154 12.0\n6   2 2020-04-10 10:00:00      10.0 15.1  72    193  8.6\n7   2 2020-05-13 10:00:00       7.5 11.7  72    193  8.6\n8   2 2020-05-26 10:00:00       2.5  2.9  72    193  8.6\n9   2 2020-06-10 10:00:00       2.5  2.2  72    193  8.6\n10  2 2020-06-25 10:00:00       2.5  4.3  72    193  8.6\n11  3 2020-07-07 10:00:00       2.5  3.4  56    167 12.2\n12  3 2020-09-25 10:00:00       7.5 10.2  56    167 12.2\n13  3 2020-10-04 10:00:00       5.0  7.5  56    167 12.2\n                    ld\n1  2019-02-26 22:00:00\n2  2019-05-07 18:00:00\n3                 <NA>\n4  2019-11-19 18:00:00\n5                 <NA>\n6                 <NA>\n7  2020-05-12 21:00:00\n8                 <NA>\n9                 <NA>\n10                <NA>\n11                <NA>\n12 2020-09-24 22:00:00\n13                <NA>\n\nThere are 3 individuals in the dataset. Each has a set of EHR-extracted dose and blood concentrations data along with demographic data and information commonly found with laboratory data:\nAll concentrations are being taken in the morning. Given that this is a drug which should be taken orally every 12 hours, we can construct a reasonable dosing schedule which details the amount and timing of each dose.\nrun_Build_PK_Oral() will build an appropriate dataset for population PK analysis for drugs orally administered, given specification of appropriate columns:\nidCol: subject identification number\ndtCol: time of concentration measurement\ndoseCol: dose\nconcCol: drug concentration\nldCol: last-dose time; the default is NULL to ignore\nfirst_interval_hours: hours of regular dosing leading up to the first drug concentration; the default is 336 hours = 14 days\nimputeClosest: Vector of columns for imputation of missing data using last observation carried forward or, if unavailable, next observation propagated backward\n(1) Build the PK data without last-dose time\nSuppose we do not have the last-dose time information. For illustrative purpose, we remove this information (i.e., column 8 is omitted in this example data).\n\n\n# Build PK data without last-dose times\nrun_Build_PK_Oral(x = dat[,-8],\n                  idCol = \"id\",\n                  dtCol = \"dt\",\n                  doseCol = \"dose_morn\",\n                  concCol = \"conc\",\n                  ldCol = NULL,\n                  first_interval_hours = 336,\n                  imputeClosest = NULL)\n\n\n   CID   time                date conc dose addl II mdv age weight\n1    1    0.0 2019-02-13 10:00:00   NA 10.0   27 12   1  46    154\n2    1  336.0 2019-02-27 10:00:00 16.1   NA   NA NA   0  46    154\n3    1  336.5 2019-02-27 10:30:00   NA 10.0  139 12   1  46    154\n4    1 2015.0 2019-05-08 10:00:00  6.4   NA   NA NA   0  46    154\n5    1 2015.5 2019-05-08 10:30:00   NA  5.0  105 12   1  46    154\n6    1 3287.0 2019-06-30 10:00:00  5.6   NA   NA NA   0  46    154\n7    1 3287.5 2019-06-30 10:30:00   NA  5.0  285 12   1  46    154\n8    1 6720.0 2019-11-20 10:00:00  6.6   NA   NA NA   0  46    154\n9    1 6720.5 2019-11-20 10:30:00   NA  5.0  265 12   1  46    154\n10   1 9911.0 2020-04-01 10:00:00  5.0   NA   NA NA   0  46    154\n11   2    0.0 2020-03-27 10:00:00   NA 10.0   27 12   1  72    193\n12   2  336.0 2020-04-10 10:00:00 15.1   NA   NA NA   0  72    193\n13   2  336.5 2020-04-10 10:30:00   NA 10.0   65 12   1  72    193\n14   2 1128.0 2020-05-13 10:00:00 11.7   NA   NA NA   0  72    193\n15   2 1128.5 2020-05-13 10:30:00   NA  7.5   25 12   1  72    193\n16   2 1440.0 2020-05-26 10:00:00  2.9   NA   NA NA   0  72    193\n17   2 1440.5 2020-05-26 10:30:00   NA  2.5   29 12   1  72    193\n18   2 1800.0 2020-06-10 10:00:00  2.2   NA   NA NA   0  72    193\n19   2 1800.5 2020-06-10 10:30:00   NA  2.5   29 12   1  72    193\n20   2 2160.0 2020-06-25 10:00:00  4.3   NA   NA NA   0  72    193\n21   3    0.0 2020-06-23 10:00:00   NA  2.5   27 12   1  56    167\n22   3  336.0 2020-07-07 10:00:00  3.4   NA   NA NA   0  56    167\n23   3  336.5 2020-07-07 10:30:00   NA  2.5  159 12   1  56    167\n24   3 2256.0 2020-09-25 10:00:00 10.2   NA   NA NA   0  56    167\n25   3 2256.5 2020-09-25 10:30:00   NA  7.5   17 12   1  56    167\n26   3 2472.0 2020-10-04 10:00:00  7.5   NA   NA NA   0  56    167\n    hgb\n1  12.0\n2  12.0\n3  12.0\n4  12.0\n5  12.0\n6  12.0\n7  12.0\n8  12.0\n9  12.0\n10 12.0\n11  8.6\n12  8.6\n13  8.6\n14  8.6\n15  8.6\n16  8.6\n17  8.6\n18  8.6\n19  8.6\n20  8.6\n21 12.2\n22 12.2\n23 12.2\n24 12.2\n25 12.2\n26 12.2\n\nNote that addl and II dictate an every-twelve-hour dosing schedule which leads up to the proceeding concentration. Covariates are preserved and a time variable which represents hours since first dose is generated. This data is now in an appropriate format for PK analysis but makes no use of the last-dose times.\n(2) Build the PK data with last-dose time\nSuppose we do now have the last-dose time information although they are extracted along with some (but not all) concentrations. When last-dose times are avaiable, they can be specified in the argument ldCol in the input data (e.g., ldCol = \"ld\". Then, the sequence of doses leading up to the extracted dose is reduced and a new row is inserted which accurately describes the timing of the dose which precedes the relevant concentration.\n\n\n# Build PK data with last-dose times\nrun_Build_PK_Oral(x = dat,\n                  idCol = \"id\",\n                  dtCol = \"dt\",\n                  doseCol = \"dose_morn\",\n                  concCol = \"conc\",\n                  ldCol = \"ld\",\n                  first_interval_hours = 336,\n                  imputeClosest = NULL)\n\n\n   CID   time                date conc dose addl II mdv age weight\n1    1    0.0 2019-02-13 10:00:00   NA 10.0   26 12   1  46    154\n2    1  324.0 2019-02-26 22:00:00   NA 10.0    0 NA   1  46    154\n3    1  336.0 2019-02-27 10:00:00 16.1   NA   NA NA   0  46    154\n4    1  336.5 2019-02-27 10:30:00   NA 10.0  138 12   1  46    154\n5    1 1999.0 2019-05-07 18:00:00   NA 10.0    0 NA   1  46    154\n6    1 2015.0 2019-05-08 10:00:00  6.4   NA   NA NA   0  46    154\n7    1 2015.5 2019-05-08 10:30:00   NA  5.0  105 12   1  46    154\n8    1 3287.0 2019-06-30 10:00:00  5.6   NA   NA NA   0  46    154\n9    1 3287.5 2019-06-30 10:30:00   NA  5.0  284 12   1  46    154\n10   1 6704.0 2019-11-19 18:00:00   NA  5.0    0 NA   1  46    154\n11   1 6720.0 2019-11-20 10:00:00  6.6   NA   NA NA   0  46    154\n12   1 6720.5 2019-11-20 10:30:00   NA  5.0  265 12   1  46    154\n13   1 9911.0 2020-04-01 10:00:00  5.0   NA   NA NA   0  46    154\n14   2    0.0 2020-03-27 10:00:00   NA 10.0   27 12   1  72    193\n15   2  336.0 2020-04-10 10:00:00 15.1   NA   NA NA   0  72    193\n16   2  336.5 2020-04-10 10:30:00   NA 10.0   64 12   1  72    193\n17   2 1115.0 2020-05-12 21:00:00   NA 10.0    0 NA   1  72    193\n18   2 1128.0 2020-05-13 10:00:00 11.7   NA   NA NA   0  72    193\n19   2 1128.5 2020-05-13 10:30:00   NA  7.5   25 12   1  72    193\n20   2 1440.0 2020-05-26 10:00:00  2.9   NA   NA NA   0  72    193\n21   2 1440.5 2020-05-26 10:30:00   NA  2.5   29 12   1  72    193\n22   2 1800.0 2020-06-10 10:00:00  2.2   NA   NA NA   0  72    193\n23   2 1800.5 2020-06-10 10:30:00   NA  2.5   29 12   1  72    193\n24   2 2160.0 2020-06-25 10:00:00  4.3   NA   NA NA   0  72    193\n25   3    0.0 2020-06-23 10:00:00   NA  2.5   27 12   1  56    167\n26   3  336.0 2020-07-07 10:00:00  3.4   NA   NA NA   0  56    167\n27   3  336.5 2020-07-07 10:30:00   NA  2.5  158 12   1  56    167\n28   3 2244.0 2020-09-24 22:00:00   NA  2.5    0 NA   1  56    167\n29   3 2256.0 2020-09-25 10:00:00 10.2   NA   NA NA   0  56    167\n30   3 2256.5 2020-09-25 10:30:00   NA  7.5   17 12   1  56    167\n31   3 2472.0 2020-10-04 10:00:00  7.5   NA   NA NA   0  56    167\n    hgb\n1  12.0\n2  12.0\n3  12.0\n4  12.0\n5  12.0\n6  12.0\n7  12.0\n8  12.0\n9  12.0\n10 12.0\n11 12.0\n12 12.0\n13 12.0\n14  8.6\n15  8.6\n16  8.6\n17  8.6\n18  8.6\n19  8.6\n20  8.6\n21  8.6\n22  8.6\n23  8.6\n24  8.6\n25 12.2\n26 12.2\n27 12.2\n28 12.2\n29 12.2\n30 12.2\n31 12.2\n\nIndividual 1 has no extracted last-dose times so their data is unchanged from before. Compare, however, rows 7-9 to rows 7-8 of the previous dataset constructed without last-dose times. The measured concentration of 14.1 on date 2019-11-01 is associated with a last-dose time. addl drops from 69 to 68 and the extracted last-dose is added in row 8 with additional date 2019-10-31 20:58:36 which is the last-dose time extracted from clinical notes. Notice that the number of doses leading up to the concentration is unchanged and the timing of the final dose has been adjusted to reflect information in the EHR (i.e., the calculated time of 1162.70 for time). This dataset still relies on assumptions about dosing, but should reflect the actual dosing schedule better by incorporating last-dose times from the EHR.\nReferences\nChoi L, Beck C, McNeer E, Weeks HL, Williams ML, James NT, Niu X, Abou-Khalil BW, Birdwell KA, Roden DM, Stein CM. Development of a System for Post-marketing Population Pharmacokinetic and Pharmacodynamic Studies using Real-World Data from Electronic Health Records. Clinical Pharmacology & Therapeutics. 2020 Apr;107(4):934-43. doi: 10.1002/cpt.1787.\n\n\n\n",
      "last_modified": "2021-08-19T08:55:06-05:00"
    },
    {
      "path": "Extract-Med.html",
      "title": "Extract-Med",
      "description": "This tutorial describes how to obtain drug dosing information from unstructured clinical notes using *Extract-Med* module in the system.\n",
      "author": [
        {
          "name": "Hannah L. Weeks, Elizabeth McNeer",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nIntroduction\n\nHere add links to vignettes\nSee also “Extract-Med” of “1. EHR Vignette for Extract-Med and Pro-Med-NLP” in EHR package\nIntroduction\nReferences\nChoi L, Beck C, McNeer E, Weeks HL, Williams ML, James NT, Niu X, Abou-Khalil BW, Birdwell KA, Roden DM, Stein CM. Development of a System for Post-marketing Population Pharmacokinetic and Pharmacodynamic Studies using Real-World Data from Electronic Health Records. Clinical Pharmacology & Therapeutics. 2020 Apr;107(4):934-43. doi: 10.1002/cpt.1787.\nWeeks HL, Beck C, McNeer E, Williams ML, Bejan CA, Denny JC, Choi L. medExtractR: A targeted, customizable approach to medication extraction from electronic health records. Journal of the American Medical Informatics Association. 2020 Mar;27(3):407-18. doi: 10.1093/jamia/ocz207.\n\n\n\n",
      "last_modified": "2021-08-19T08:55:06-05:00"
    },
    {
      "path": "index.html",
      "title": "Choi Lab",
      "author": [],
      "contents": "\n\n\n\nLeena Choi, PhD\nProfessor of Biostatistics\nVice Chair of Diversity and Inclusion\nDepartment of Biostatistics\n\n\n\nhttps://www.vumc.org/biostatistics/person/leena-choi-phd\n\nThe major research focus of our lab is to construct a system, called “EHRtoPKPD”, for drug-related studies such as pharmacokinetics (PK), pharmacodynamics (PD), and pharmacogenomics (PGx) studies using electronic health records (EHRs). This system would allow to perform drug-related studie more efficiently by standardizing data extraction, data processing, and data building procedures. This system would provide a foundation for PK/PD-model guided clinical decision support systems embedded in EHRs to provide an optimal pharmacotherapy, the overarching goal of precision medicine.\n\nThe EHRtoPKPD, a System for PK/PD Studies using EHRs.\nModified from Clin Pharm Ther 2020.\nEHRtoPKPD is a modular system, divided into the three major procedures: data extraction (“Extract-”), data processing (“Pro-”), and data building (“Build-”). Modules were created or under development (gray color box) depending on the data element, task to perform, and type of PK/PD models.\nFor drugs with complex prescription pattern, dose data obtained from e-prescription databases may not be accurate enough to perform PK/PD studies. For these drugs, we may need to extract drug dose information from clinical notes using a natural language processing (NLP) system. We developed a flexible and targeted NLP system that can directly extract drug dose information from clinical notes, which was incorporated into our system (Extract-Med).\nBuilding drug dose data from extracted dose information can be challenging. To address these challenges, we developed a dose data building algorithm that was implemented in our system (Pro-Med-NLP).\nFor drugs with simple prescription pattern, dose data can be relatively easily extracted from e-prescription databases and processed using Pro-Med-Str module.\nOther data elements such as drug levels (Pro-Drug Level), demographics (Pro-Demographic), and laboratory data (Pro-Laboratory) can be processed using our system. These data can be combined with processed dose data to build PK/PD data using PK/PD data building modules (i.e., Build-PK-IV, Build-PK-Oral).\nThe NLP system is available as an R package, medExtractR, and the functions to run each module are implemented as an R package, EHR. More details can be found in Choi et al.\\(^{1}\\), and additional modules will be added in the future as it evolves.\n\nLab Team\nCole Beck\nElizabeth McNeer\nMichael Williams\nNathan T. James, ScM\n\nLab Alumni\nHannah L. Weeks\nReferences\nChoi L, Beck C, McNeer E, Weeks HL, Williams ML, James NT, Niu X, Abou-Khalil BW, Birdwell KA, Roden DM, Stein CM. Development of a System for Post-marketing Population Pharmacokinetic and Pharmacodynamic Studies using Real-World Data from Electronic Health Records. Clinical Pharmacology & Therapeutics. 2020 Apr;107(4):934-43. doi: 10.1002/cpt.1787.\n\n\n\n",
      "last_modified": "2021-08-19T08:55:06-05:00"
    },
    {
      "path": "Pro-Med-NLP.html",
      "title": "Pro-Med-NLP",
      "description": "This tutorial describes how to build longitudinal medication dose data from the raw output of an NLP system using the *Pro-Med-NLP* module.\n",
      "author": [
        {
          "name": "Hannah L. Weeks, Elizabeth McNeer",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nIntroduction\nPart I\nPart II\n\n\n\n\nHere add links to vignettes\nSee also “Pro-Med-NLP” of “1. EHR Vignette for Extract-Med and Pro-Med-NLP” in EHR package\nIntroduction\nThis tutorial describes how to use the Pro-Med-NLP module to generate longitudinal medication dose data from the raw output of an NLP system. The module is divided into two parts. Part I parses the raw output and pairs entities together, and Part II calculates dose intake and daily dose and removes redundant information.\nPart I\nTwo main functions are used in this part of the module, a parse function (parseMedExtractR, parseMedXN, parseCLAMP, or parseMedEx) and buildDose.\nParse functions\nParse functions are available for the medExtractR, MedXN, CLAMP, and MedEx systems (parseMedExtractR, parseMedXN, parseCLAMP, parseMedEx). If the user has output from another NLP system, the user can write code to standardize the output before calling the buildDose function.\nThe parse functions require the following argument:\nfilename: file name for a file containing the raw output from the NLP system\nThe following are the function calls for the parse functions.\n\n\nparseMedExtractR(filename)\nparseMedXN(filename, begText = \"^[ID0-9]+_[0-9-]+_[Note0-9]\")\nparseCLAMP(filename)\nparseMedEx(filename)\n\n\n\nThe parseMedXN function also has an argument specifying a regular expression pattern which indicates the start of each row (i.e., drug mention) in the raw MedXN output. In the example above, the begText argument identifies how the file names are structured for a set of clinical notes in a Vanderbilt University dataset (e.g., “ID111_2000-01-01_Note001” where ID111 is the patient ID, 2000-01-01 is the date of the note, and Note001 is the note ID). Thus, each row beginning with a file name in this format indicates a new drug mention.\nThe parse functions output a standardized form of the data that includes a row for each drug mention and columns for all entities anchored to that drug mention.\nRunning parseMedExtractR\nFirst, we create variables for the filenames of our raw NLP system data. In the EHR package, we have example medExtractR data for tacrolimus and lamotrigine.\n\n\ntac_mxr_fn <- system.file(\"examples\", \"tac_mxr.csv\", package = \"EHR\")\nlam_mxr_fn <- system.file(\"examples\", \"lam_mxr.csv\", package = \"EHR\")\n\n\n\nBelow is the example medExtractR output for tacrolimus:\n\n\n(tac_mxr <- read.csv(file.path(tac_mxr_fn),stringsAsFactors = FALSE))\n\n\n                         filename     entity        expr       pos\n1  tacpid1_2008-06-26_note1_1.txt   DrugName     Prograf   930:937\n2  tacpid1_2008-06-26_note1_1.txt   Strength        1 mg   951:955\n3  tacpid1_2008-06-26_note1_1.txt    DoseAmt           3   956:957\n4  tacpid1_2008-06-26_note1_1.txt  Frequency twice a day   976:987\n5  tacpid1_2008-06-26_note1_1.txt   DrugName     prograf 2709:2716\n6  tacpid1_2008-06-26_note1_1.txt       Dose         3mg 2717:2720\n7  tacpid1_2008-06-26_note1_1.txt  Frequency         bid 2721:2724\n8  tacpid1_2008-06-26_note1_1.txt   LastDose      8:30pm 2740:2746\n9  tacpid1_2008-06-26_note2_1.txt   DrugName     Prograf   618:625\n10 tacpid1_2008-06-26_note2_1.txt   Strength        1 mg   639:643\n11 tacpid1_2008-06-26_note2_1.txt    DoseAmt           3   644:645\n12 tacpid1_2008-06-26_note2_1.txt  Frequency twice a day   664:675\n13 tacpid1_2008-06-26_note2_1.txt   LastDose       14 hr   678:683\n14 tacpid1_2008-12-16_note3_1.txt   DrugName  Tacrolimus   722:732\n15 tacpid1_2008-12-16_note3_1.txt   DrugName     Prograf   761:768\n16 tacpid1_2008-12-16_note3_1.txt   Strength        1 mg   770:774\n17 tacpid1_2008-12-16_note3_1.txt    DoseAmt           3   775:776\n18 tacpid1_2008-12-16_note3_1.txt  Frequency twice a day   795:806\n19 tacpid1_2008-12-16_note3_1.txt DoseChange    decrease 2170:2178\n20 tacpid1_2008-12-16_note3_1.txt   DrugName     Prograf 2179:2186\n21 tacpid1_2008-12-16_note3_1.txt       Dose         2mg 2190:2193\n22 tacpid1_2008-12-16_note3_1.txt  Frequency         bid 2194:2197\n23 tacpid1_2008-12-16_note3_1.txt   DrugName     Prograf 2205:2212\n24 tacpid1_2008-12-16_note3_1.txt   LastDose    10:30 pm 2231:2239\n\nHere we demonstrate how to run parseMedExtractR using the raw medExtractR output from above.\n\n\ntac_mxr_parsed <- parseMedExtractR(tac_mxr_fn)\nlam_mxr_parsed <- parseMedExtractR(lam_mxr_fn)\n\n\n\nRunning parseMedXN\nSimilar to above, we first create a variable for the filename of our raw MedXN data for lamotrigine.\n\n\nlam_mxn_fn <- system.file(\"examples\", \"lam_medxn.csv\", package = \"EHR\")\n\n\n\nHere is the example MedXN output for lamotrigine:\n\nID1_2012-11-22_Note1.txt|lamotrigine::255::266|28439::196502|100 mg::278::284|\n     2::288::289`1.5::310::313|tabs::290::294`tabs::314::318`tabs::350::354||\n     morning::298::305`evening::322::329|2 weeks::334::341\nID1_2012-11-22_Note1.txt|Vimpat::1086::1092|809979|200mg::1093::1098||tab::1099::1102|\n     mouth::1106::1111|twice daily::1112::1123\nID1_2012-11-22_Note1.txt|lamotrigine::1172::1183|28439|100 mg::1184::1190||\n     tablet::1191::1197\nID1_2012-11-22_Note1.txt|Lamictal::1213::1221|196502||1.5::1223::1226|\n     tablets::1227::1234|mouth::1238::1243|twice a day::1244::1255\n\nWe demonstrate how to run the parseMedXN function using our example MedXN output below.\n\n\nlam_mxn_parsed <- parseMedXN(lam_mxn_fn, begText = \"^[ID0-9]+_[0-9-]+_[Note0-9]\")\n\n\n\nThe output from all systems, once parsed, has the same structure as the example parsed MedXN output below.\n\n                   filename                drugname\n1: ID1_2012-11-22_Note1.txt   lamotrigine::255::266\n2: ID1_2012-11-22_Note1.txt      Vimpat::1086::1092\n3: ID1_2012-11-22_Note1.txt lamotrigine::1172::1183\n4: ID1_2012-11-22_Note1.txt    Lamictal::1213::1221\n             strength                      dose             route\n1:   100 mg::278::284 2::288::289`1.5::310::313                  \n2:  200mg::1093::1098                           mouth::1106::1111\n3: 100 mg::1184::1190                                        <NA>\n4:                              1.5::1223::1226 mouth::1238::1243\n                                  freq          duration\n1: morning::298::305`evening::322::329 2 weeks::334::341\n2:             twice daily::1112::1123              <NA>\n3:                                <NA>              <NA>\n4:             twice a day::1244::1255              <NA>\n\nbuildDose\nAfter the NLP output is parsed, the buildDose function is run to pair the parsed entities. The main buildDose function arguments are as follows:\ndat: standardized form of the data (i.e., output from one of the parse functions)\ndn: argument to specify drug names of interest (generally not used with medExtractR since medExtractR is a targeted system and only includes the drug of interest in the raw output)\nThe general function call is:\n\n\nbuildDose(dat, dn = NULL)\n\n\n\nOther notable arguments that can be specified by buildDose include:\npreserve: columns which should be preserved in the final output, but not considered for pairing with other entities. The default is NULL, though for medExtractR the dose change entity is always preserved.\ndist_method: which distance method calculation to use in cost calculation for pairing entities. For more details see the supplementary material in McNeer, et al. (2020). The default from getOption('ehr.dist_method') is minEntEnd, or using the minimum distance between the end of one entity and beginning of the next).\ncheckForRare: a logical argument, indicates whether or not the output should return rare occurrences of entities (default is FALSE)\nThe output of the buildDose function is a dataset with a column for each entity and a row for each pairing.\nRunning buildDose\nIn our medExtractR example from above, the output of the buildDose function is the following:\n\n\n(tac_part_i_out <- buildDose(tac_mxr_parsed))\n\n\n                        filename   drugname strength dose route\n1 tacpid1_2008-06-26_note1_1.txt    Prograf     1 mg    3    NA\n2 tacpid1_2008-06-26_note1_1.txt    prograf     <NA> <NA>    NA\n3 tacpid1_2008-06-26_note2_1.txt    Prograf     1 mg    3    NA\n4 tacpid1_2008-12-16_note3_1.txt Tacrolimus     <NA> <NA>    NA\n5 tacpid1_2008-12-16_note3_1.txt    Prograf     1 mg    3    NA\n6 tacpid1_2008-12-16_note3_1.txt    Prograf     <NA> <NA>    NA\n7 tacpid1_2008-12-16_note3_1.txt    Prograf     <NA> <NA>    NA\n         freq dosestr dosechange lastdose drugname_start\n1 twice a day    <NA>       <NA>     <NA>            930\n2         bid     3mg       <NA>   8:30pm           2709\n3 twice a day    <NA>       <NA>    14 hr            618\n4        <NA>    <NA>       <NA>     <NA>            722\n5 twice a day    <NA>       <NA>     <NA>            761\n6         bid     2mg   decrease     <NA>           2179\n7        <NA>    <NA>       <NA> 10:30 pm           2205\n\n(lam_part_i_out <- buildDose(lam_mxr_parsed))\n\n\n                         filename       drugname strength dose route\n1  lampid1_2016-02-05_note4_1.txt       Lamictal     <NA> <NA>  <NA>\n2  lampid1_2016-02-05_note4_1.txt    Lamotrigine    200mg  1.5  <NA>\n3  lampid1_2016-02-05_note4_1.txt Lamotrigine XR   100 mg    3  <NA>\n4  lampid1_2016-02-05_note4_1.txt Lamotrigine XR   100 mg    2  <NA>\n5  lampid1_2016-02-05_note5_1.txt            ltg   200 mg  1.5  <NA>\n6  lampid1_2016-02-05_note5_1.txt         ltg xr   100 mg    3  <NA>\n7  lampid1_2016-02-05_note5_1.txt         ltg xr   100 mg    2  <NA>\n8  lampid2_2008-07-20_note6_1.txt    lamotrigine     <NA> <NA>  <NA>\n9  lampid2_2008-07-20_note6_1.txt       lamictal     <NA> <NA>  <NA>\n10 lampid2_2008-07-20_note6_1.txt       Lamictal     <NA> <NA>  <NA>\n11 lampid2_2012-04-15_note7_1.txt    lamotrigine   150 mg <NA>  <NA>\n12 lampid2_2012-04-15_note7_1.txt       Lamictal     <NA>    1  <NA>\n          freq dosestr dosechange lastdose drugname_start\n1          BID  300 mg       <NA>     <NA>            810\n2  twice daily    <NA>       <NA>     <NA>            847\n3      morning    <NA>       <NA>     <NA>            954\n4      evening    <NA>       <NA>     <NA>            954\n5        daily    <NA>       <NA>     <NA>            442\n6        in am    <NA>       <NA>     <NA>            465\n7        in pm    <NA>       <NA>     <NA>            465\n8         <NA>    <NA>       <NA>     <NA>           1267\n9         q12h  150 mg       <NA>     <NA>           1280\n10         BID   200mg   Increase     <NA>           2273\n11        <NA>    <NA>       <NA>     <NA>            103\n12 twice a day    <NA>       <NA>     <NA>            141\n\nIf the checkForRare argument is set to TRUE, any extracted expressions with a proportion of occurrence less than 0.2 are returned as rare values. When rare values are identified, a warning is printed to notify the user. The var column indicates the entity (note that dose in this output refers to dose amount, while dosestr would indicate dose given intake). This can be used as a quick check for potentially inaccurate information and allow the user to remove incorrect extractions before applying the Pro-Med-NLP module as incorrect extractions would reduce accuracy of the dose building data. Note that these values may still be correct extractions even though they are rare, as is the case for our output below.\n\n\nlam_checkForRare <- buildDose(lam_mxr_parsed, checkForRare=TRUE)\n\n\n       var   val Freq       Prop\n1 drugname   ltg    1 0.08333333\n2 strength 150mg    1 0.14285714\n3     dose     1    1 0.14285714\n\nPart II\nIn Part II of the module, we form the final analysis datasets containing computed dosing information at the note and date level for each patient. This process requires more detailed meta data associated with each clinical note file, the format of which is described below. In this part, we also discuss how time of last dose should be incorporated when present before producing the final output dataset.\nnoteMetaData\nThe meta data argument is required by the functions collapseDose and processLastDose, and requires four columns: filename, pid, date, note. In our example data, pid (patient ID), date, and note can all be extracted from the filename. Take the filename “tacpid1_2008-06-26_note1_1.txt” for example. It contains information in the form “[PID]_[date]_[note]”, where PID = “tacpid1”, date = “2008-06-26” and note = “note1”. The function below can build our meta data from each of the filenames.\n\n\nbmd <- function(x) {\n  fns <- strsplit(x, '_')\n  pid <- sapply(fns, `[`, 1)\n  date <- as.Date(sapply(fns, `[`, 2), format = '%Y-%m-%d')\n  note <- sapply(fns, `[`, 3)\n  data.frame(filename = x, pid, date, note, stringsAsFactors = FALSE)\n}\nbmd(\"tacpid1_2008-06-26_note1_1.txt\")\n\n\n                        filename     pid       date  note\n1 tacpid1_2008-06-26_note1_1.txt tacpid1 2008-06-26 note1\n\n(tac_metadata <- bmd(tac_part_i_out[['filename']]))\n\n\n                        filename     pid       date  note\n1 tacpid1_2008-06-26_note1_1.txt tacpid1 2008-06-26 note1\n2 tacpid1_2008-06-26_note1_1.txt tacpid1 2008-06-26 note1\n3 tacpid1_2008-06-26_note2_1.txt tacpid1 2008-06-26 note2\n4 tacpid1_2008-12-16_note3_1.txt tacpid1 2008-12-16 note3\n5 tacpid1_2008-12-16_note3_1.txt tacpid1 2008-12-16 note3\n6 tacpid1_2008-12-16_note3_1.txt tacpid1 2008-12-16 note3\n7 tacpid1_2008-12-16_note3_1.txt tacpid1 2008-12-16 note3\n\ncollapseDose\nThe main function used in Part II of the module is the collapseDose function, which relies on the underlying makeDose function. collapseDose allows the user to split the data using drug names given by regular expressions (...) and run makeDose separately on each subset of the data. For example, if the data includes multiple drugs, regular expressions can be specified for each drug. Another use of this function is to split the data by different formulations of the drug, such as separating immediate release formulations from extended release formulations, which are often written using “XR” or “ER” in the drug name.\nThe collapseDose function requires the following arguments:\nx: output from the buildDose function, or from addLastDose if last dose information is incorporated (see Handling lastDose section below)\nnoteMetaData: a data.frame with columns for filename, pid (patient id), date, and note\nnaFreq: method to use when assigning missing frequencies; the default is to assign the most common frequency\nThe general function call is:\n\n\ncollapseDose(x, noteMetaData, naFreq = 'most', ...)\n\n\n\nThe main function underlying collapseDose is makeDose, which standardizes entities, imputes missing values, calculates dose intake and daily dose, removes redundancies, and generates the final dose data. Two data.frames are generated from the makeDose function, one with redundancies removed at the note level and one at the date level (see McNeer et al. (2020) for details). The collapseDose function serves as a wrapper to makeDose to ensure results are collated and formatted properly for analysis.\nRunning collapseDose\nBelow, we demonstrate collapseDose using our lamotrigine example. In the function call, we supply an additional argument 'xr|er' to indicate that we want to separately consider extended release formulations of lamotrigine, (usually denoted by “XR” or “ER”). This prevents regular lamotrigine mentions from being collapsed with lamotrigine XR mentions, even if the dosage is identical.\n\n\ndata(lam_metadata, package = 'EHR')\nlam_part_ii <- collapseDose(lam_part_i_out, lam_metadata, naFreq = 'most', 'xr|er')\n\n\n\n\n\n\nNote level collapsing:\n\n\nlam_part_ii$note\n\n\n                        filename       drugname strength dose  route\n1 lampid1_2016-02-05_note4_1.txt       Lamictal     <NA> <NA> orally\n2 lampid1_2016-02-05_note4_1.txt Lamotrigine XR   100 mg    3 orally\n3 lampid1_2016-02-05_note4_1.txt Lamotrigine XR   100 mg    2 orally\n4 lampid1_2016-02-05_note5_1.txt            ltg   200 mg  1.5 orally\n5 lampid1_2016-02-05_note5_1.txt         ltg xr   100 mg    3 orally\n6 lampid1_2016-02-05_note5_1.txt         ltg xr   100 mg    2 orally\n7 lampid2_2008-07-20_note6_1.txt       lamictal     <NA> <NA> orally\n8 lampid2_2008-07-20_note6_1.txt       Lamictal     <NA> <NA> orally\n9 lampid2_2012-04-15_note7_1.txt       Lamictal     <NA>    1 orally\n   freq dosestr dosechange lastdose drugname_start dosestr.num\n1   bid  300 mg       <NA>     <NA>            810         300\n2    am    <NA>       <NA>     <NA>            954          NA\n3    pm    <NA>       <NA>     <NA>            954          NA\n4 daily    <NA>       <NA>     <NA>            442          NA\n5    am    <NA>       <NA>     <NA>            465          NA\n6    pm    <NA>       <NA>     <NA>            465          NA\n7   bid  150 mg       <NA>     <NA>           1280         150\n8   bid   200mg   Increase     <NA>           2273         200\n9   bid    <NA>       <NA>     <NA>            141          NA\n  strength.num doseamt.num freq.num dose.intake intaketime dose.seq\n1           NA          NA        2         300       <NA>       NA\n2          100         3.0        1         300         am        1\n3          100         2.0        1         200         pm        2\n4          200         1.5        1         300       <NA>       NA\n5          100         3.0        1         300         am        1\n6          100         2.0        1         200         pm        2\n7           NA          NA        2         150       <NA>       NA\n8           NA          NA        2         200       <NA>       NA\n9          150         1.0        2         150       <NA>       NA\n  dose.daily\n1        600\n2        500\n3        500\n4        300\n5        500\n6        500\n7        300\n8        400\n9        300\n\nDate level collapsing:\n\n\nlam_part_ii$date\n\n\n                        filename       drugname strength dose  route\n1 lampid1_2016-02-05_note4_1.txt       Lamictal     <NA> <NA> orally\n2 lampid1_2016-02-05_note4_1.txt Lamotrigine XR   100 mg    3 orally\n3 lampid1_2016-02-05_note4_1.txt Lamotrigine XR   100 mg    2 orally\n4 lampid1_2016-02-05_note5_1.txt            ltg   200 mg  1.5 orally\n5 lampid2_2008-07-20_note6_1.txt       lamictal     <NA> <NA> orally\n6 lampid2_2008-07-20_note6_1.txt       Lamictal     <NA> <NA> orally\n7 lampid2_2012-04-15_note7_1.txt       Lamictal     <NA>    1 orally\n   freq dosestr dosechange lastdose drugname_start dosestr.num\n1   bid  300 mg       <NA>     <NA>            810         300\n2    am    <NA>       <NA>     <NA>            954          NA\n3    pm    <NA>       <NA>     <NA>            954          NA\n4 daily    <NA>       <NA>     <NA>            442          NA\n5   bid  150 mg       <NA>     <NA>           1280         150\n6   bid   200mg   Increase     <NA>           2273         200\n7   bid    <NA>       <NA>     <NA>            141          NA\n  strength.num doseamt.num freq.num dose.intake intaketime dose.seq\n1           NA          NA        2         300       <NA>       NA\n2          100         3.0        1         300         am        1\n3          100         2.0        1         200         pm        2\n4          200         1.5        1         300       <NA>       NA\n5           NA          NA        2         150       <NA>       NA\n6           NA          NA        2         200       <NA>       NA\n7          150         1.0        2         150       <NA>       NA\n  dose.daily\n1        600\n2        500\n3        500\n4        300\n5        300\n6        400\n7        300\n\nHandling lastdose\nIn this section, we cover how incorporation of the last dose entity should be handled if it was extracted using medExtractR. In the Running buildDose section above, we see the raw last dose time extractions for the tacrolimus dataset. Using the functions processLastDose and addLastDose, we convert the extracted times into a processed and standardized datetime variable, and add the processed times to the buildDose output.\nThe processLastDose function requires the following arguments:\nmxrData: raw output from the extractMed function\nnoteMetaData: note meta data for each file name in mxrData\nlabData: a data frame containing lab dates and times associated with the file names within mxrData. This must contain at a minimum the columns pid and date (in the same format as noteMetaData), as well as labtime, a POSIXct variable indicating the date and time of a laboratory drug measurement\nExtracted last dose times can fall into two categories: a time expression (e.g., “10am”, “22:00”, “7 last night”) or a duration expression (e.g. “14 hour” level), where the “time” of last dose indicates the number of hours since the last dose was taken relative to the time of the clinical visit. In the latter case, the lab time (from the labData argument) is needed in order to convert the extracted duration expression into a datetime variable. Below is an example lab dataset for our sample tacrolimus data.\n\n\ndata(tac_lab, package = 'EHR')\ntac_lab\n\n\n      pid       date             labtime\n1 tacpid1 2008-06-26 2008-06-26 10:42:00\n2 tacpid1 2008-12-16 2008-12-16 12:11:00\n\nWithin processLastDose, extracted times are converted to time expressions of the format “HH:MM:SS” and assigned a date based on the date of the corresponding note. When the last dose time is after 12pm, it is assumed to have been taken on the previous date.\n\n\n(tac_ld <- processLastDose(mxrData = tac_mxr, noteMetaData = tac_metadata, labData = tac_lab))\n\n\n                        filename            lastdose    ld_pos\n1 tacpid1_2008-06-26_note1_1.txt 2008-06-25 20:30:00 2740:2746\n2 tacpid1_2008-06-26_note2_1.txt 2008-06-25 20:42:00   678:683\n3 tacpid1_2008-12-16_note3_1.txt 2008-12-15 22:30:00 2231:2239\n      pid       date raw_time ld_start time_type             labtime\n1 tacpid1 2008-06-26   8:30pm     2740      time 2008-06-26 10:42:00\n2 tacpid1 2008-06-26    14 hr      678  duration 2008-06-26 10:42:00\n3 tacpid1 2008-12-16 10:30 pm     2231      time 2008-12-16 12:11:00\n\nThe function output contains the processed and standardized last dose time (lastdose), the original extracted expression (raw_time), whether the raw expression was a time or duration (time_type), as well as position information for the last dose time (ld_start) for appropriate pairing with dosing information in addLastDose. The labtime column in the output above corresponds to the information provided in the labData argument.\nThe addLastDose function requires the following arguments:\nbuildData: output from buildDose\nlastdoseData: dataset containing last dose time information for the file names in buildData. This should include columns for filename and lastdose, with lastdose being a processed POSIXct datetime variable.\nIn the case where last dose information was extracted from clinical notes using medExtractR, the lastdoseData input should be output from the processLastDose function containing the last dose start positions, as demonstrated below. It is possible for multiple times to be extracted from a clinical note. For extracted times within a 2 hour window of one another, addLastDose treats these as equivalent and extracts the last dose time. Note that this may be context-dependent, and this rule was determined based on drugs administered every 12 hours and assuming a trough drug level. For time differences of more than two hours, the last dose start position is used to pair the extracted time with the closest drug mention. Alternatively, if the user has a separate dataset with validated last dose times, they can provide their own dataset. When providing a validated dataset, there should be only one last dose time per patient ID and date.\n\n\n(tac_part_i_out_lastdose <- addLastDose(buildData = tac_part_i_out, lastdoseData = tac_ld))\n\n\n                        filename   drugname strength dose route\n1 tacpid1_2008-06-26_note1_1.txt    Prograf     1 mg    3    NA\n2 tacpid1_2008-06-26_note1_1.txt    prograf     <NA> <NA>    NA\n3 tacpid1_2008-06-26_note2_1.txt    Prograf     1 mg    3    NA\n4 tacpid1_2008-12-16_note3_1.txt Tacrolimus     <NA> <NA>    NA\n5 tacpid1_2008-12-16_note3_1.txt    Prograf     1 mg    3    NA\n6 tacpid1_2008-12-16_note3_1.txt    Prograf     <NA> <NA>    NA\n7 tacpid1_2008-12-16_note3_1.txt    Prograf     <NA> <NA>    NA\n         freq dosestr dosechange            lastdose drugname_start\n1 twice a day    <NA>       <NA>                <NA>            930\n2         bid     3mg       <NA> 2008-06-25 20:30:00           2709\n3 twice a day    <NA>       <NA> 2008-06-25 20:42:00            618\n4        <NA>    <NA>       <NA>                <NA>            722\n5 twice a day    <NA>       <NA>                <NA>            761\n6         bid     2mg   decrease                <NA>           2179\n7        <NA>    <NA>       <NA> 2008-12-15 22:30:00           2205\n\nNote that in the lastdose columns, we now have standardized datetime objects instead of the raw extracted expressions.\nRunning collapseDose with last dose present\nFor our tacrolimus example above, the output of this function is below. Note that we use the output from addLastDose rather than directly from buildDose.\n\n\ntac_part_ii <- collapseDose(tac_part_i_out_lastdose, tac_metadata, naFreq = 'most')\n\n\n\n\n\n\nNote level collapsing:\n\n\ntac_part_ii$note\n\n\n                        filename drugname strength dose  route freq\n1 tacpid1_2008-06-26_note1_1.txt  Prograf     1 mg    3 orally  bid\n2 tacpid1_2008-06-26_note2_1.txt  Prograf     1 mg    3 orally  bid\n3 tacpid1_2008-12-16_note3_1.txt  Prograf     1 mg    3 orally  bid\n4 tacpid1_2008-12-16_note3_1.txt  Prograf     <NA> <NA> orally  bid\n  dosestr dosechange            lastdose drugname_start dosestr.num\n1    <NA>       <NA> 2008-06-25 20:30:00            930          NA\n2    <NA>       <NA> 2008-06-25 20:42:00            618          NA\n3    <NA>       <NA> 2008-12-15 22:30:00            761          NA\n4     2mg   decrease 2008-12-15 22:30:00           2179           2\n  strength.num doseamt.num freq.num dose.intake intaketime dose.seq\n1            1           3        2           3       <NA>       NA\n2            1           3        2           3       <NA>       NA\n3            1           3        2           3       <NA>       NA\n4           NA          NA        2           2       <NA>       NA\n  dose.daily\n1          6\n2          6\n3          6\n4          4\n\nDate level collapsing:\n\n\ntac_part_ii$date\n\n\n                        filename drugname strength dose  route freq\n1 tacpid1_2008-06-26_note1_1.txt  Prograf     1 mg    3 orally  bid\n2 tacpid1_2008-06-26_note2_1.txt  Prograf     1 mg    3 orally  bid\n3 tacpid1_2008-12-16_note3_1.txt  Prograf     1 mg    3 orally  bid\n4 tacpid1_2008-12-16_note3_1.txt  Prograf     <NA> <NA> orally  bid\n  dosestr dosechange            lastdose drugname_start dosestr.num\n1    <NA>       <NA> 2008-06-25 20:30:00            930          NA\n2    <NA>       <NA> 2008-06-25 20:42:00            618          NA\n3    <NA>       <NA> 2008-12-15 22:30:00            761          NA\n4     2mg   decrease 2008-12-15 22:30:00           2179           2\n  strength.num doseamt.num freq.num dose.intake intaketime dose.seq\n1            1           3        2           3       <NA>       NA\n2            1           3        2           3       <NA>       NA\n3            1           3        2           3       <NA>       NA\n4           NA          NA        2           2       <NA>       NA\n  dose.daily\n1          6\n2          6\n3          6\n4          4\n\nAdditional collapsing\nCollapsing by date or note produces observations at the daily intake level. It is possible to further collapse data to the daily level, though you may want to drop the dose.intake variable as it would potentially lose meaning.\n\n\nx <- lam_part_ii[['note']]\n# retrieve metadata for each filename\nk1 <- lam_metadata[match(x[,'filename'], lam_metadata[,'filename']), c('pid','date','note')]\n# select additional key data\nk2 <- cbind(k1, x[,c('dose.daily','drugname_start')])\n# turn keys into character string\nchk <- do.call(paste, c(k2, sep = '|'))\n# keep first instance of each chk key\nlam_part_iii_note <- x[!duplicated(chk),]\nlam_part_iii_note[,c('filename','drugname','drugname_start','dose.daily')]\n\n\n                        filename       drugname drugname_start\n1 lampid1_2016-02-05_note4_1.txt       Lamictal            810\n2 lampid1_2016-02-05_note4_1.txt Lamotrigine XR            954\n4 lampid1_2016-02-05_note5_1.txt            ltg            442\n5 lampid1_2016-02-05_note5_1.txt         ltg xr            465\n7 lampid2_2008-07-20_note6_1.txt       lamictal           1280\n8 lampid2_2008-07-20_note6_1.txt       Lamictal           2273\n9 lampid2_2012-04-15_note7_1.txt       Lamictal            141\n  dose.daily\n1        600\n2        500\n4        300\n5        500\n7        300\n8        400\n9        300\n\n\n\nx <- lam_part_ii[['date']]\n# ignore note for date level collapsing\nk1 <- lam_metadata[match(x[,'filename'], lam_metadata[,'filename']), c('pid','date')]\nk2 <- cbind(k1, x[,c('dose.daily','drugname_start')])\nchk <- do.call(paste, c(k2, sep = '|'))\nlam_part_iii_date <- x[!duplicated(chk),]\nlam_part_iii_date[,c('filename','drugname','drugname_start','dose.daily')]\n\n\n                        filename       drugname drugname_start\n1 lampid1_2016-02-05_note4_1.txt       Lamictal            810\n2 lampid1_2016-02-05_note4_1.txt Lamotrigine XR            954\n4 lampid1_2016-02-05_note5_1.txt            ltg            442\n5 lampid2_2008-07-20_note6_1.txt       lamictal           1280\n6 lampid2_2008-07-20_note6_1.txt       Lamictal           2273\n7 lampid2_2012-04-15_note7_1.txt       Lamictal            141\n  dose.daily\n1        600\n2        500\n4        300\n5        300\n6        400\n7        300\n\nReferences\nChoi L, Beck C, McNeer E, Weeks HL, Williams ML, James NT, Niu X, Abou-Khalil BW, Birdwell KA, Roden DM, Stein CM. Development of a System for Post-marketing Population Pharmacokinetic and Pharmacodynamic Studies using Real-World Data from Electronic Health Records. Clinical Pharmacology & Therapeutics. 2020 Apr;107(4):934-43. doi: 10.1002/cpt.1787.\nMcNeer E, Beck C, Weeks HL, Williams ML, James NT, Bejan CA, Choi L. Building Longitudinal Medication Dose Data Using Medication Information Extracted from Clinical Notes in Electronic Health Records. J Am Med Inform Assoc. 2021 Mar 18;28(4):782-790. doi: 10.1093/jamia/ocaa291.\n\n\n\n",
      "last_modified": "2021-08-19T08:55:06-05:00"
    },
    {
      "path": "Pro-Med-Str-Part2.html",
      "title": "Pro-Med-Str - Part II",
      "description": "This tutorial describes how to process structured medication data, especially focusing on e-prescription data.\n",
      "author": [
        {
          "name": "Elizabeth McNeer",
          "url": {}
        }
      ],
      "contents": "\n\nContents\nIntroduction\nRaw E-Prescription Data\nProcessing the Data\n\nHere add links to vignettes\nSee also “Part II: e-prescription data” of “2. EHR Vignette for Structured Data” in EHR package\nIntroduction\nThis tutorial describes how to use the Pro-Med-Str - Part II module in EHRtoPKPD to process structured e-prescription data.\nThe major tasks the module performs are as follows:\nCreating numeric variables for strength, dose, and frequency\nCalculating daily dose\nRemoving duplicate daily doses for a patient\nRaw E-Prescription Data\nTo use this module, all prescriptions must be for only one drug. Different names, such as brand names and generic names, for the same drug are allowed (e.g., Lamictal and lamotrigine). The data used in this module must include columns for ID, date, strength, dose amount, and frequency. If a description column is included, this module will attempt to extract the strength from the description column in cases where the strength is missing.\nBelow is example e-prescription data from the EHR package including columns for ID, drug name, dose, frequency, date, strength, and description.\n\n\nrawDataDir <- system.file(\"examples\", \"str_ex2\", package=\"EHR\")\n(eRX <- read.csv(file.path(rawDataDir,\"e-rx_DATA.csv\"),stringsAsFactors = FALSE))\n\n\n  GRID    MED_NAME   RX_DOSE             FREQUENCY ENTRY_DATE\n1  ID1 lamotrigine         1                   bid 2009-02-24\n2  ID2 lamotrigine         2                   bid 2006-12-30\n3  ID2    Lamictal         1                   bid 2006-12-30\n4  ID3 Lamictal XR         3                   bid 2004-08-24\n5  ID4 lamotrigine         1           twice a day 2010-05-22\n6  ID5 lamotrigine    2 tabs                   qam 2007-06-13\n7  ID6 lamotrigine 1.5+1+1.5 brkfst, lunch, dinner 2015-03-14\n  STRENGTH_AMOUNT                                        DESCRIPTION\n1             100 lamotrigine 100 mg tablet (Also Known As Lamictal)\n2             100 lamotrigine 100 mg tablet (Also Known As Lamictal)\n3             200                             LaMICtal 200 mg tablet\n4                                       Lamictal XR 100 mg 24 hr Tab\n5          200 mg lamotrigine 200 mg tablet (Also Known As Lamictal)\n6             200         LaMICtal XR 200 mg tablet,extended release\n7             100 lamoTRIgine 100 mg tablet (Also Known As Lamictal)\n\nTo get a daily dose for each patient, we multiply strength*dose*frequency. In order to do this, the STRENGTH_AMOUNT, RX_DOSE, and FREQUENCY variables need to be converted to numeric. Strengths that include units will have the units removed (e.g., numeric strength for ID4 will be 200), frequencies will be converted to the equivalent number of times per day that the medication is taken (e.g., bid = 2, twice a day = 2, qam = 1), and doses will have words like “tabs” removed (e.g., numeric dose for ID5 will be 2). For ID6, separate doses are written for breakfast, lunch, and dinner, so the numeric dose will be 4 (1.5+1+1.5), and the daily dose will be calculated as strength*dose. ID3 is missing a value for STRENGTH_AMOUNT, but we can use the strength that is present in the DESCRIPTION column. In the next section, we show how the run_MedStrII function in the EHR package takes care of all of these tasks for us and calculates a daily dose.\nProcessing the Data\nWe begin by loading the EHR package.\n\n\nlibrary(EHR)\n\n\n\nThe e-prescription data can be processed by the run_MedStrII function using:\n\n\neRX.out <- run_MedStrII(file.path(rawDataDir,\"e-rx_DATA.csv\"),\n    select = c('GRID','MED_NAME','RX_DOSE','FREQUENCY','ENTRY_DATE','STRENGTH_AMOUNT','DESCRIPTION'),\n    rename = c('ID','MED_NAME','RX_DOSE','FREQUENCY','ENTRY_DATE','STRENGTH_AMOUNT','DESCRIPTION'))\n\n\n\nThe following arguments are used in the run_MedStrII function:\nfile: file name of prescription data\nselect: the names of the columns to select\nrename: new column names; the default are the names required for the underlying functions, processErx and processErxAddl\n\n\neRX.out\n\n\n   ID    MED_NAME   RX_DOSE             FREQUENCY ENTRY_DATE\n1 ID1 lamotrigine         1                   bid 2009-02-24\n2 ID2 lamotrigine         2                   bid 2006-12-30\n4 ID3 Lamictal XR         3                   bid 2004-08-24\n5 ID4 lamotrigine         1           twice a day 2010-05-22\n6 ID5 lamotrigine    2 tabs                   qam 2007-06-13\n7 ID6 lamotrigine 1.5+1+1.5 brkfst, lunch, dinner 2015-03-14\n  STRENGTH_AMOUNT                                        DESCRIPTION\n1             100 lamotrigine 100 mg tablet (also known as lamictal)\n2             100 lamotrigine 100 mg tablet (also known as lamictal)\n4                                       lamictal xr 100 mg 24 hr tab\n5          200 mg lamotrigine 200 mg tablet (also known as lamictal)\n6             200         lamictal xr 200 mg tablet,extended release\n7             100 lamotrigine 100 mg tablet (also known as lamictal)\n  strength freq.standard freq.num dose daily.dose       date\n1      100           bid        2    1        200 2009-02-24\n2      100           bid        2    2        400 2006-12-30\n4      100           bid        2    3        600 2004-08-24\n5      200           bid        2    1        400 2010-05-22\n6      200            am        1    2        400 2007-06-13\n7      100           tid        3    4        400 2015-03-14\n  num_doses num_freqs\n1        NA        NA\n2        NA        NA\n4        NA        NA\n5        NA        NA\n6        NA        NA\n7         3         3\n\nIn the above example, daily dose was calculated for the first 5 patients by multiplying strength*dose*freq.num, and a redundant daily dose was removed for the patient with ID2. In order to calculate a daily dose for the patient with ID3, the strength of 100 from the description was used because STRENGTH_AMOUNT was missing. For the patient with ID6, the dose amounts of 1.5, 1, and 1.5 are added together to get a dose of 4, and the daily dose is calculated as strength*dose.\nReferences\nChoi L, Beck C, McNeer E, Weeks HL, Williams ML, James NT, Niu X, Abou-Khalil BW, Birdwell KA, Roden DM, Stein CM. Development of a System for Post-marketing Population Pharmacokinetic and Pharmacodynamic Studies using Real-World Data from Electronic Health Records. Clinical Pharmacology & Therapeutics. 2020 Apr;107(4):934-43. doi: 10.1002/cpt.1787.\n\n\n\n",
      "last_modified": "2021-08-19T08:55:06-05:00"
    },
    {
      "path": "workshops.html",
      "title": "*EHRtoPKPD* Workshops",
      "description": "The tutorial series demonstrate how to use the *EHRtoPKPD* with some examples in EHR package.\n",
      "author": [],
      "contents": "\n\nContents\nNote for Other Modules\nExtract-Med\nPro-Med-NLP\nPro-Med-Str - Part II\nBuild-PK-Oral\nBuild-PK-IV - Simple\nBuild-PK-IV - Comprehensive\nPro-Med-Str - Part I\n\nNote for Other Modules\nThe tutorials for Pro-Demographic, Part1 of Pro-Med-Str, Pro-Drug Level, and Pro-Laboratory are provided by giving an example within Build-PK-IV - Comprehensive.\nExtract-Med\nThis tutorial describes how to obtain drug dosing information from unstructured clinical notes using Extract-Med module in the system.\nPro-Med-NLP\nThis tutorial describes how to build longitudinal medication dose data from the raw output of an NLP system using the Pro-Med-NLP module.\nPro-Med-Str - Part II\nThis tutorial describes how to processes structured medication data, especially focusing on e-prescription data.\nBuild-PK-Oral\nThis tutorial describes the PK data building procedure in the EHRtoPKPD for medications that are typically orally administrated. It demonstrates how to quickly build PK data using Build-PK-Oral when drug dose data are provided by users or generated from unstructured clinical notes using extracted dosing information with the Extract-Med module and processed with the Pro-Med-NLP module in the system.\nBuild-PK-IV - Simple\nThis tutorial describes a simple PK data building procedure in the EHRtoPKPD for medications that are typically intravenously administrated. It demonstrates how to quickly build PK data using Build-PK-IV without using the data processing modules when cleaned data for concentration, drug dose, demographic and laboratory datasets are already available in an appropriate data form.\nBuild-PK-IV - Comprehensive\nThis tutorial describes a comprehensive PK data building procedure in the EHRtoPKPD for medications that are typically intravenously administrated. It demonstrates how to utilize several data processing modules (e.g., Pro-Demographic, Pro-Med-Str, Pro-Drug Level, Pro-Laboratory) to standardize and combine more complex datasets when cleaned data are not available, and then build PK data using Build-PK-IV.\nPro-Med-Str - Part I\nThis tutorial describes how to processes structured medication data, especially focusing on intravenously given dose data.\n\n\n\n",
      "last_modified": "2021-08-19T08:55:06-05:00"
    }
  ],
  "collections": []
}
