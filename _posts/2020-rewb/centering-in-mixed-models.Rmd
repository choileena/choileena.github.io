---
title: "Centering in Mixed Models"
description: |
  Yadda Yadda
author:
  - name: Michael Clark
    url: https://m-clark.github.io
date: '2020-05-14'
preview: ../../img/covid_preview.gif  
output:
  distill::distill_article:
    self_contained: false
    toc: true
    css: [../../styles.css, ../../css/misc.css]
    code_folding: hide
bibliography: ../../bibs/mixed.bib
draft: true
tags: [mixed models, group centering, grand mean centering]
categories:
  - visualization
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  comment = NA,
  R.options = list(width = 120),
  cache.rebuild = FALSE,
  cache = FALSE,
  fig.align = 'center',
  fig.asp = .7,
  dev = 'svglite',
  dev.args = list(bg = 'transparent')
)

library(tidyverse)
library(kableExtra)
library(scico)

kable_df <- function(..., digits=3) {
  kable(..., digits=digits) %>% 
    kable_styling(full_width = F)
}

rnd = tidyext::rnd
```

<aside>First posted 2020-05-14.</aside>

## Introduction

This post is an attempt to discuss and extend some of  Bell et al.'s articles[@bell2015explaining][@bell2019fixed][@bell2018understanding] advocating mixed models with random effects over  so-called 'fixed-effects' models.  The gist of the results were that a specific style of random effects model had multiple advantages and no disadvantages relative to the FE models. As Mundlak put it 40+ years ago:

>... the question is why would a uniform approach lead to two competing estimators, the coefficients which do not vary over individuals. That brings us to the second point which can be stated very simply: when the model is properly specified, the GLSE (i.e. RE) is identical to the "within" (i.e. FE) estimator. Thus there is only one estimator. The whole literature which has been based on an imaginary difference between the two estimators... is based on an incorrect specification which ignores the correlation between the effects and the explanatory variables. It is thus argued that there is a uniform approach and a unique estimator.[@mundlak1978]

As I have never had interest in, nor found a compelling reason to use fixed-effects models[^nofe], and the referenced articles give plenty of reasons not to use them to go along with the quote above, I won't discuss them further. In this case, I am interested in some scenarios not covered in previous simulations, namely those with larger data and non-hierarchical structure.


### The model

Similar to Bell & Jones (2015), the underlying model is as follows. Here the $x$ represent within cluster/group varying covariates, while the $c$ are group level (i.e. constant within group) covariates. For example, the $x$ could represent individual level values some variables while the $c$ could represent geographic level variables.   Along with these we have a group random effect $u$, and the usual observation observation level noise $\epsilon$.

$$y \sim \beta_0 +\beta_1\cdot x_1 + \beta_2\cdot x_2 + \beta_3\cdot c_1 + \beta_4\cdot c_2 + u_{grp} + \epsilon$$
In this particular case, $c_1$ is the group mean value of $x_1$. 

$$c_1 = \bar{x}_{1_{grp}}$$
If we were run that model as a standard mixed model, i.e. including the group level mean of $x_1$, it is identical to Mundlak's model, which has in various places unfortunately been named the *within-between* or *hybrid* models.  We can distinguish Mundlak's model from the 'within-between' model of Bell as follows:


$$\textrm{Mundlak}: y \sim \beta_0 +\beta_1\cdot x_1 + \beta_2\cdot x_2 + \beta_3\cdot c_1 + \beta_4\cdot c_2 + u_{grp} + \epsilon$$
$$\textrm{Within-Between}:  y \sim \beta_0 +\beta_1\cdot x_{within} + \beta_2\cdot x_2 + \beta_{3b}\cdot c_1 + \beta_4\cdot c_2 + u_{grp} + \epsilon$$
In this case, $x_{within}$ is a group centered covariate, $x_1$.

$$x_{within} = (x_1-\bar{x}_{grp})$$
If we go back to the Mundlak model we can express it as follows.

$$\textrm{Mundlak}: y \sim \beta_0 +\beta_1\cdot x_1 + \beta_2\cdot x_2 + (\beta_{3b}-\beta_1)\cdot c_1 + \beta_4\cdot c_2 + u_{grp} + \epsilon$$

Which means:

$$\beta_3 = \beta_{3b} - \beta_1$$
In either case we are interested in a *contextual effect* by adding the group mean covariate.  In these models, the effect of $\beta_3$ is the difference between what is typically called the 'within' and 'between' effects, but are more generally observation-level (or lower-level) vs. group-level effects.  If there is no contextual effect, $\beta_3$ would be zero and $\beta_{3b}$ converges to $\beta_1$, and we can reduce to the following random effects model:

$$\textrm{RE}: y \sim \beta_0 +\beta_1\cdot x_1 + \beta_2\cdot x_2 + \beta_4\cdot c_2 + u_{grp} + \epsilon$$

The primary issue is what happens when there is a contextual effect[^econfe]. In a standard mixed model with no contextual covariates, the effect of $x1$ cannot disambiguate the two.  If we are only interested in the 'within' effect, it will be 'biased', which we will see shortly  

### Summary of Bell & Jones


Only partial results are shown in Bell & Jones (2015). These are the full results for the following data generating scenario:

$$ y \sim 1 + .5x_1 + 2x_2 -1.5c_1 + -2.5 c_2 + u_{grp} + \epsilon$$

Large credit to them for making code and data publicly available.

```{r bell-fig, echo=FALSE}
bell_sim_results = haven::read_dta('data/bell_sim/simscollapsedALLall.dta')

# bell_sim_results %>% tidyext::describe_all()

# contextual is the effect of the aggregate variable, i.e. B3
# L2corX5 is unclear. The values are -1:3 and presumably it is the correlation between z3j and uj in the text
# L2var is level 2 variance is the group variance and constant at 4 (although expressed as standard deviation in text)
# L1var is residual variance and constant at 3 (although expressed as standard deviation in text)


re_results = bell_sim_results %>% 
  select(
    N,
    n,
    Contextual,
    balanced,
    L2corX5,
    L2Var,
    L1Var,
    matches('RE$|REWB$')
  )

# bias, not including 3b which is not estimated by RE model
re_bias = re_results %>%
  filter(L2corX5 == 0) %>%
  select(-L2Var,-L1Var,-L2corX5,-matches('opt|RMSE|3B')) %>%
  pivot_longer(
    -(N:balanced),
    names_to = c('param', 'model'),
    names_prefix = 'MBias',
    names_pat = '(B[0-9])([A-Z]+)'
  ) 

re_bias %>%
  mutate(N = factor(N), n = factor(n, labels = paste0('n per grp = ', unique(n)))) %>%
  rename(`# of groups` = N) %>%
  ggplot(aes(x = Contextual, y = value)) +
  geom_hline(aes(yintercept = 1), color = '#99002440') +
  geom_point(aes(
    color = model,
    size = abs(value - 1),
    shape = `# of groups`
  ), alpha = .25) +
  # lims(y = c(.93, 1.04)) +
  scico::scale_color_scico_d(end = .5) +
  guides(size = 'none') +
  # facet_wrap(param + n ~ model, ncol = 4) +
  facet_grid(rows = vars(param, n), cols = vars(model)) +
  visibly::theme_clean()
```

In the above, the RE is a standard mixed model with no contextual effect will under or overestimate the within effect depending on the magnitude of that effect.
As we can see, if there are no contextual effec

### Our situation

My data is often not hierarchical, might contain hundreds to thousands of clusters, and may have (unbalanced) groups of 1 to possibly hundreds of observations, and may have little cluster level variance. These situations are largely unexplored in what I've read, so that's where we are for this post.  I was also curious about the extent of the bias, as the Bell & Jones results didn't seem very profound except in the most extreme settings.

The other thing is that I approach mixed models as I would any other.  What goes into the model is substantively driven.  I would add group level covariates to explain the otherwise latent group effects. In some cases that could be largely undertaken without any group averaged effects.  In other cases the group averaged effect would possibly not be very meaningful (e.g. an average age), or would actually be constant, i.e. controlled for, in a balanced design. Also, if we are concerned more with prediction, bias is less of a concern, and in fact would normally be introduced to a model explicitly (e.g. typical regularized regression approaches).  As such, one should think hard about whether this concern is really applicable to their situation.  On the other hand, it is trivial to simply add such effects to the model.


## Simulation

### Setup

Target and covariates:

- y continuous vs. binary
- level 1: 
    - primary covariate `x_win`  (random normal mean 0, sd 1) OR
    - primary covariate `x1`    (`x_win` + `c1`)
    - additional covariate `x2` (random normal mean 0, sd 1)
- level 2: 
    - `c1` the group mean value of `x_win` 
    - additional binary covariate `c2` (random bernoulli Ï€ = .5)


Considerations: 

- Number of observations per group  5, 20, 100
- Number of groups: 500, 1000
- Intraclass correlation: 50% vs. 10%

For these models I used standardized data to produce the X variables and the total residual variance (i.e. cluster and observation level) totals 1.  In this case, something like .25 would be at least a moderate effect for the covariates[^var_y]. We set the coefficients as follows:


- Intercept = .25
- x1 = .5
- x2 = .1
- c1 = [-.50, -.25, 0, .25, .50]
- c2 = .1
- group level variance/observation level variance: .1/.9 , .5,.5

I did not explore correlations of `c2` with the random effects as did Bell & Jones, but otherwise used their code as a reference.  In these simulations, we have a relatively strong effect for `x1`, and `c1` runs the gamut of no effect to very strong. In total there are 60 settings.

```{r test_grid, echo = FALSE}
test_grid = expand_grid(
  n_grps    = c(500, 1000),
  n_per_grp = c(5, 20, 100),
  sd_g      = c(sqrt(.1), sqrt(.5)),
  c1        = c(-.5, -.25, 0, .25, .5)
) %>% 
  mutate(
  sigma  = c(.9, .5)[factor(sd_g)]
  )

test_grid %>% 
  select(matches('^n'), c1, sd_g, sigma) %>% 
  round(4) %>% 
  DT::datatable(options = list(dom = 't', scrollY = TRUE), rownames = F)
```


## Results

### Single random effect

```{r load-basic-results, echo=FALSE}
load('data/bell_sim/sim_ran_int_balanced.RData')
source('code/mixed_models/plot_results_basic.R')

results_basic = bind_rows(
  REWB = results_rewb_avg,
  RE = results_re_avg,
  Mundlak = results_mundlak_avg,
  .id = 'model'
)
```


Simulations were run for 1000 times for each of the settings shown. In general, the Bell results are duplicated[^opppat], where only the straight random effects model with no contextual effects shows any bias.  


```{r plot-basic-results-bias, layout='l-body-outset', out.width = '110%', echo=FALSE}
results_basic %>%
  plot_results(model = 'all') +
  facet_grid(model ~ n_grps + n_per_grp) +
  theme(
    axis.text.x  = element_text(size = 4),
    strip.text   = element_text(size = 6),
    legend.text  = element_text(size = 6),
    legend.title = element_text(size = 6)
  )
```

However, we can also see that with increasing cluster size and variability, this bias becomes minimal.  With 20 per group and an ICC of .5, the bias practically negligible. We also see that the Mundlak shows identical results as expected, which means there isn't much to be gained by group-centering.

<!-- The results are echoed for RMSE, as it is just the average squared bias. -->

<!-- ```{r plot-basic-results-rmse, layout='l-body-outset', echo=FALSE} -->
<!-- results_basic %>% -->
<!--   plot_results(model = 'all', stat = 'opt') + -->
<!--   facet_grid(model ~ n_grps + n_per_grp) + -->
<!--   theme( -->
<!--     strip.text = element_text(size = 6) -->
<!--   ) -->
<!-- ``` -->




### Mulitple Random Effects
### Random Slopes



## Supplemental

Scripts for the above:

- Simple Random Intercepts
- Crossed Random Effects

Bell & Jones (2015) [Supplemental Materials on Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/23415)


[^nofe]: I'm always interested in contextual effects, not simply controlling for them.

[^econfe]: This effect is essentially what the economists were concerned with regarding the correlation of within variables and the random effects.  Their solution with FE models was essentially overkill.

[^var_y]: The median variance of the target variable is 1.5.

[^opppat]: The pattern here is actually opposite here for the RE model because our group level coefficient is positive, consistent with the lower level effect.  Bell & Jones had a positive coefficient for their lower level effect and negative for the group-level effect.