<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Comparisons of the Unseen</title>
  
  <meta property="description" itemprop="description" content="Examining group differences across latent variables"/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2019-08-05"/>
  <meta property="article:created" itemprop="dateCreated" content="2019-08-05"/>
  <meta name="article:author" content="Michael Clark"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Comparisons of the Unseen"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Examining group differences across latent variables"/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Comparisons of the Unseen"/>
  <meta property="twitter:description" content="Examining group differences across latent variables"/>
  
  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","preview","output","draft","tags","categories"]}},"value":[{"type":"character","attributes":{},"value":["Comparisons of the Unseen"]},{"type":"character","attributes":{},"value":["Examining group differences across latent variables\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","url"]}},"value":[{"type":"character","attributes":{},"value":["Michael Clark"]},{"type":"character","attributes":{},"value":["https://m-clark.github.io"]}]}]},{"type":"character","attributes":{},"value":["2019-08-05"]},{"type":"character","attributes":{},"value":["../../img/compare_group_latent.png"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc","css"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["../../styles.css"]}]}]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["R","factor analysis","growth curve","structural equation modeling","SEM","intercepts","means"]},{"type":"character","attributes":{},"value":["SEM","factor analysis"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["comparing-latent-variables_files/bowser-1.9.3/bowser.min.js","comparing-latent-variables_files/DiagrammeR-styles-0.2/styles.css","comparing-latent-variables_files/distill-2.2.21/template.v2.js","comparing-latent-variables_files/grViz-binding-1.0.0/grViz.js","comparing-latent-variables_files/htmlwidgets-1.3/htmlwidgets.js","comparing-latent-variables_files/jquery-1.11.3/jquery.min.js","comparing-latent-variables_files/kePrint-0.0.1/kePrint.js","comparing-latent-variables_files/viz-0.3/viz.js","comparing-latent-variables_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  d-code {
    overflow-x: auto !important;
  }
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  
  d-code {
    overflow-x: visible !important;
  }
  
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .custom p {
    margin-bottom: 0.5em;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="comparing-latent-variables_files/kePrint-0.0.1/kePrint.js"></script>
  <script src="comparing-latent-variables_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="comparing-latent-variables_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="comparing-latent-variables_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="comparing-latent-variables_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->

  <link rel="stylesheet" href="../../styles.css" type="text/css"/>

</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Comparisons of the Unseen","description":"Examining group differences across latent variables","authors":[{"author":"Michael Clark","authorURL":"https://m-clark.github.io","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2019-08-05T00:00:00.000-04:00","citationText":"Clark, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Comparisons of the Unseen</h1>
<p><p>Examining group differences across latent variables</p></p>
</div>

<div class="d-byline">
  Michael Clark <a href="https://m-clark.github.io" class="uri">https://m-clark.github.io</a> 
  
<br/>2019-08-05
</div>

<div class="d-article">
<h3 class="d-toc-header">Table of Contents</h3>
<nav class="d-toc" id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#multiple-group-analysis">Multiple group analysis</a></li>
<li><a href="#latent-variable-intercepts">Latent variable intercepts</a></li>
<li><a href="#observed-variable-group-differences">Observed variable group differences</a></li>
<li><a href="#structural-model">Structural model</a><ul>
<li><a href="#multigroup-as-the-structural-model">Multigroup as the structural model</a></li>
<li><a href="#group-difference-as-an-indirect-effect">Group difference as an indirect effect</a></li>
</ul></li>
<li><a href="#more-structural-models">More structural models</a></li>
<li><a href="#sumfactor-score">Sum/Factor score</a></li>
<li><a href="#summary-of-differences">Summary of differences</a></li>
<li><a href="#supplemental-measurement-invariance">Supplemental: Measurement invariance</a></li>
</ul>
</nav>
<hr class="d-toc-separator"/>
<h2 id="introduction">Introduction</h2>
<p>In some cases we are interested in looking at group differences with regard to <span class="emph"> latent variables</span>. For example, social scientists are interested in race and sex differences on psychological measures, or educational scientists might want to create exams in different languages. We cannot measure many constructs directly, but can get reliable measures of them indirectly, e.g. by asking a series of questions, or otherwise observing multiple instances of activity thought to be related to some construct. There are a variety of ways to assess group differences across latent structure, such as anxiety or verbal ability, and this post provides a demo using lavaan.</p>
<p>My motivation for doing this is that it comes up from time to time in consulting, and I wanted a quick reminder for the syntax to refer back to. As a starting point though, you can find some demonstration on the <a href="https://lavaan.ugent.be">lavaan website</a>. For more on factor analysis, structural equation modeling, and more, see <a href="https://m-clark.github.io/sem/">my document</a>.</p>
<h2 id="multiple-group-analysis">Multiple group analysis</h2>
<p>A common way to assess group differences is via multiple group analysis, which amounts to doing separate structural equation models of some kind across the groups of interest. We will use a classic data set to demonstrate the approach. From the help file:</p>
<blockquote>
<p>The Holzinger and Swineford (1939) dataset consists of mental ability test scores of seventh- and eighth-grade children from two different schools (Pasteur and Grant-White). In the original dataset, there are scores for 26 tests. However, a smaller subset with 9 variables is more widely used in the literature…</p>
</blockquote>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(lavaan)
data(HolzingerSwineford1939)</code></pre>
</div>
<p>The basic model is a factor analysis with three latent variables, with items for visual-spatial ability (<code>x1-x3</code>), verbal comprehension (<code>x4-x6</code>), and so-called ‘speed’ tests (<code>x7-x9</code>), e.g. for addition and counting, which might be thought of general cognitive processing.</p>
<p>With lavaan, we specify the model for three factor (or latent variables). After that, a simple group argument will allow the multigroup analysis, providing the factor analysis for both school groups.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(tidyverse)
library(lavaan)

hs_model_baseline &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
&#39;

fit_baseline &lt;- cfa(
  hs_model_baseline, 
  data = HolzingerSwineford1939, 
  group = &quot;school&quot;
)

summary(fit_baseline)  </code></pre>
<pre><code>
lavaan 0.6-7 ended normally after 57 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of free parameters                         60
                                                      
  Number of observations per group:                   
    Pasteur                                        156
    Grant-White                                    145
                                                      
Model Test User Model:
                                                      
  Test statistic                               115.851
  Degrees of freedom                                48
  P-value (Chi-square)                           0.000
  Test statistic for each group:
    Pasteur                                     64.309
    Grant-White                                 51.542

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured


Group 1 [Pasteur]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.394    0.122    3.220    0.001
    x3                0.570    0.140    4.076    0.000
  verbal =~                                           
    x4                1.000                           
    x5                1.183    0.102   11.613    0.000
    x6                0.875    0.077   11.421    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.125    0.277    4.057    0.000
    x9                0.922    0.225    4.104    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    verbal            0.479    0.106    4.531    0.000
    speed             0.185    0.077    2.397    0.017
  verbal ~~                                           
    speed             0.182    0.069    2.628    0.009

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                4.941    0.095   52.249    0.000
   .x2                5.984    0.098   60.949    0.000
   .x3                2.487    0.093   26.778    0.000
   .x4                2.823    0.092   30.689    0.000
   .x5                3.995    0.105   38.183    0.000
   .x6                1.922    0.079   24.321    0.000
   .x7                4.432    0.087   51.181    0.000
   .x8                5.563    0.078   71.214    0.000
   .x9                5.418    0.079   68.440    0.000
    visual            0.000                           
    verbal            0.000                           
    speed             0.000                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.298    0.232    1.286    0.198
   .x2                1.334    0.158    8.464    0.000
   .x3                0.989    0.136    7.271    0.000
   .x4                0.425    0.069    6.138    0.000
   .x5                0.456    0.086    5.292    0.000
   .x6                0.290    0.050    5.780    0.000
   .x7                0.820    0.125    6.580    0.000
   .x8                0.510    0.116    4.406    0.000
   .x9                0.680    0.104    6.516    0.000
    visual            1.097    0.276    3.967    0.000
    verbal            0.894    0.150    5.963    0.000
    speed             0.350    0.126    2.778    0.005


Group 2 [Grant-White]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.736    0.155    4.760    0.000
    x3                0.925    0.166    5.583    0.000
  verbal =~                                           
    x4                1.000                           
    x5                0.990    0.087   11.418    0.000
    x6                0.963    0.085   11.377    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.226    0.187    6.569    0.000
    x9                1.058    0.165    6.429    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    verbal            0.408    0.098    4.153    0.000
    speed             0.276    0.076    3.639    0.000
  verbal ~~                                           
    speed             0.222    0.073    3.022    0.003

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                4.930    0.095   51.696    0.000
   .x2                6.200    0.092   67.416    0.000
   .x3                1.996    0.086   23.195    0.000
   .x4                3.317    0.093   35.625    0.000
   .x5                4.712    0.096   48.986    0.000
   .x6                2.469    0.094   26.277    0.000
   .x7                3.921    0.086   45.819    0.000
   .x8                5.488    0.087   63.174    0.000
   .x9                5.327    0.085   62.571    0.000
    visual            0.000                           
    verbal            0.000                           
    speed             0.000                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.715    0.126    5.676    0.000
   .x2                0.899    0.123    7.339    0.000
   .x3                0.557    0.103    5.409    0.000
   .x4                0.315    0.065    4.870    0.000
   .x5                0.419    0.072    5.812    0.000
   .x6                0.406    0.069    5.880    0.000
   .x7                0.600    0.091    6.584    0.000
   .x8                0.401    0.094    4.249    0.000
   .x9                0.535    0.089    6.010    0.000
    visual            0.604    0.160    3.762    0.000
    verbal            0.942    0.152    6.177    0.000
    speed             0.461    0.118    3.910    0.000</code></pre>
</div>
<p>So we’re left with visual inspection to note whether there are general differences on latent variables among the groups. This is all well and good, but given that none of the parameters will be identical from one group to the next, perhaps we want a more principled approach. Say our question specifically concerns a mean difference between schools on the visual latent variable. How do we go about it?</p>
<p>Note that at this point the intercepts for the latent variables are zero. They have to be for the model to be identified, much in the same way that at least one factor loading (the first by default) has to be fixed to one. We only have so much information to estimate the parameters in a latent variable setting. Now let’s see how we might go about changing things to get a better understanding of group differences on the latent variables.</p>
<h2 id="latent-variable-intercepts">Latent variable intercepts</h2>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>To get around this limitation, we could try and fix some parameters, thereby freeing the intercepts to be estimated. For example, if we fix the mean of one of the observed variables to be zero instead, we would be able to estimate the intercept for the latent variable. In the following we’ll do this for the visuo-spatial ability construct, which will be our point of focus for group differences going forward.</p>
<aside>
Recall that for the standard latent linear model, the observed variable is the dependent variable . For example, given an observed variable <span class="math inline">\(X\)</span>, a latent variable <span class="math inline">\(F\)</span> and loading <span class="math inline">\(\lambda\)</span>: <span class="math display">\[X = b_0 + \lambda F \]</span>
</aside>
<p>In the model we we also identify a new parameter, which will be the differences in these latent variable intercepts, simply called <code>diff</code>. I have omitted some output for brevity of space.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_1 &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  
  # intercepts: in order to have an identified model, you would have to fix the
  # intercepts of observed to 0, 1 represents the intercept, 0* fixes it to be 0
  x1 ~ 0*1   

  # intercept for Pasteur and Grant-White schools
  visual ~  c(int_p, int_gw)*1    
   
  # comparisons
  diff := int_p - int_gw
&#39;

fit_1 &lt;- cfa(hs_model_1, 
             data = HolzingerSwineford1939, 
             group = &quot;school&quot;,
             meanstructure = T)
summary(fit_1, header=F, nd=2)</code></pre>
<pre><code>
Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured


Group 1 [Pasteur]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                 1.00                           
    x2                 0.39     0.12     3.22     0.00
    x3                 0.57     0.14     4.08     0.00
  verbal =~                                           
    x4                 1.00                           
    x5                 1.18     0.10    11.61     0.00
    x6                 0.87     0.08    11.42     0.00
  speed =~                                            
    x7                 1.00                           
    x8                 1.12     0.28     4.06     0.00
    x9                 0.92     0.22     4.10     0.00

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    verbal             0.48     0.11     4.53     0.00
    speed              0.19     0.08     2.40     0.02
  verbal ~~                                           
    speed              0.18     0.07     2.63     0.01

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                 0.00                           
    visual  (int_)     4.94     0.09    52.25     0.00
   .x2                 4.04     0.61     6.61     0.00
   .x3                -0.33     0.70    -0.47     0.64
   .x4                 2.82     0.09    30.69     0.00
   .x5                 4.00     0.10    38.18     0.00
   .x6                 1.92     0.08    24.32     0.00
   .x7                 4.43     0.09    51.18     0.00
   .x8                 5.56     0.08    71.21     0.00
   .x9                 5.42     0.08    68.44     0.00
    verbal             0.00                           
    speed              0.00                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                 0.30     0.23     1.29     0.20
   .x2                 1.33     0.16     8.46     0.00
   .x3                 0.99     0.14     7.27     0.00
   .x4                 0.43     0.07     6.14     0.00
   .x5                 0.46     0.09     5.29     0.00
   .x6                 0.29     0.05     5.78     0.00
   .x7                 0.82     0.12     6.58     0.00
   .x8                 0.51     0.12     4.41     0.00
   .x9                 0.68     0.10     6.52     0.00
    visual             1.10     0.28     3.97     0.00
    verbal             0.89     0.15     5.96     0.00
    speed              0.35     0.13     2.78     0.01


Group 2 [Grant-White]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                 1.00                           
    x2                 0.74     0.15     4.76     0.00
    x3                 0.92     0.17     5.58     0.00
  verbal =~                                           
    x4                 1.00                           
    x5                 0.99     0.09    11.42     0.00
    x6                 0.96     0.08    11.38     0.00
  speed =~                                            
    x7                 1.00                           
    x8                 1.23     0.19     6.57     0.00
    x9                 1.06     0.16     6.43     0.00

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    verbal             0.41     0.10     4.15     0.00
    speed              0.28     0.08     3.64     0.00
  verbal ~~                                           
    speed              0.22     0.07     3.02     0.00

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                 0.00                           
    visual  (int_)     4.93     0.10    51.70     0.00
   .x2                 2.57     0.77     3.35     0.00
   .x3                -2.56     0.82    -3.12     0.00
   .x4                 3.32     0.09    35.63     0.00
   .x5                 4.71     0.10    48.99     0.00
   .x6                 2.47     0.09    26.28     0.00
   .x7                 3.92     0.09    45.82     0.00
   .x8                 5.49     0.09    63.17     0.00
   .x9                 5.33     0.09    62.57     0.00
    verbal             0.00                           
    speed              0.00                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                 0.71     0.13     5.68     0.00
   .x2                 0.90     0.12     7.34     0.00
   .x3                 0.56     0.10     5.41     0.00
   .x4                 0.32     0.06     4.87     0.00
   .x5                 0.42     0.07     5.81     0.00
   .x6                 0.41     0.07     5.88     0.00
   .x7                 0.60     0.09     6.58     0.00
   .x8                 0.40     0.09     4.25     0.00
   .x9                 0.53     0.09     6.01     0.00
    visual             0.60     0.16     3.76     0.00
    verbal             0.94     0.15     6.18     0.00
    speed              0.46     0.12     3.91     0.00

Defined Parameters:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
    diff               0.01     0.13     0.08     0.93</code></pre>
</div>
<p>For clearer presentation, we’ll look at a table of the specific parameter estimates.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:left;">
op
</th>
<th style="text-align:right;">
block
</th>
<th style="text-align:right;">
group
</th>
<th style="text-align:left;">
label
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
<th style="text-align:right;">
std.lv
</th>
<th style="text-align:right;">
std.all
</th>
<th style="text-align:right;">
std.nox
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
visual ~1
</td>
<td style="text-align:left;">
~1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
int_p
</td>
<td style="text-align:right;">
4.941
</td>
<td style="text-align:right;">
0.095
</td>
<td style="text-align:right;">
52.249
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
4.756
</td>
<td style="text-align:right;">
5.127
</td>
<td style="text-align:right;">
4.718
</td>
<td style="text-align:right;">
4.718
</td>
<td style="text-align:right;">
4.718
</td>
</tr>
<tr>
<td style="text-align:left;">
visual ~1
</td>
<td style="text-align:left;">
~1
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
int_gw
</td>
<td style="text-align:right;">
4.930
</td>
<td style="text-align:right;">
0.095
</td>
<td style="text-align:right;">
51.696
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
4.743
</td>
<td style="text-align:right;">
5.117
</td>
<td style="text-align:right;">
6.345
</td>
<td style="text-align:right;">
6.345
</td>
<td style="text-align:right;">
6.345
</td>
</tr>
<tr>
<td style="text-align:left;">
diff := int_p-int_gw
</td>
<td style="text-align:left;">
:=
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
diff
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
0.085
</td>
<td style="text-align:right;">
0.933
</td>
<td style="text-align:right;">
-0.252
</td>
<td style="text-align:right;">
0.275
</td>
<td style="text-align:right;">
-1.627
</td>
<td style="text-align:right;">
-1.627
</td>
<td style="text-align:right;">
-1.627
</td>
</tr>
</tbody>
</table>
</div>
<p>The above shows the schools to be not much different from one another on the visual-spatial ability latent variable. But compare this result to the intercepts for <code>x1</code> in our baseline model. This model would would be identical to comparing the intercepts on whichever observed variable you had fixed to zero. Much like we must scale the latent variable to that of one of the observed variables by fixing the loading to be 1, we essentially come to the same type of issue by fixing its mean to be on that of the observed variable.</p>
<p>To make this more explicit, we’ll label the <code>x1</code> intercepts in our baseline model and look at their difference. I won’t show the model out put and simply focus on the parameter table instead.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_2 &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  x1 ~ c(a, b)*1   
   
  # comparisons
   diff := a - b
&#39;

fit_2 &lt;- cfa(hs_model_2, 
           data = HolzingerSwineford1939, 
           group = &quot;school&quot;,
           meanstructure = T)

# summary(fit_2)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:left;">
op
</th>
<th style="text-align:right;">
block
</th>
<th style="text-align:right;">
group
</th>
<th style="text-align:left;">
label
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
<th style="text-align:right;">
std.lv
</th>
<th style="text-align:right;">
std.all
</th>
<th style="text-align:right;">
std.nox
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
x1 ~1
</td>
<td style="text-align:left;">
~1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:left;">
a
</td>
<td style="text-align:right;">
4.941
</td>
<td style="text-align:right;">
0.095
</td>
<td style="text-align:right;">
52.249
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
4.756
</td>
<td style="text-align:right;">
5.127
</td>
<td style="text-align:right;">
4.941
</td>
<td style="text-align:right;">
4.183
</td>
<td style="text-align:right;">
4.183
</td>
</tr>
<tr>
<td style="text-align:left;">
x1 ~1
</td>
<td style="text-align:left;">
~1
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:left;">
b
</td>
<td style="text-align:right;">
4.930
</td>
<td style="text-align:right;">
0.095
</td>
<td style="text-align:right;">
51.696
</td>
<td style="text-align:right;">
0.000
</td>
<td style="text-align:right;">
4.743
</td>
<td style="text-align:right;">
5.117
</td>
<td style="text-align:right;">
4.930
</td>
<td style="text-align:right;">
4.293
</td>
<td style="text-align:right;">
4.293
</td>
</tr>
<tr>
<td style="text-align:left;">
diff := a-b
</td>
<td style="text-align:left;">
:=
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:left;">
diff
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
0.085
</td>
<td style="text-align:right;">
0.933
</td>
<td style="text-align:right;">
-0.252
</td>
<td style="text-align:right;">
0.275
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
-0.110
</td>
<td style="text-align:right;">
-0.110
</td>
</tr>
</tbody>
</table>
</div>
<p>Same difference.</p>
<h2 id="observed-variable-group-differences">Observed variable group differences</h2>
<p>The following approach is not the same model, but as we’ll see, would also provide the same result. In this case, each observed variable is affected by the school grouping, and the path coefficient for <code>x1</code> is the same difference in means as before.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_3 &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  x1 ~ diff*school 
  x2 + x3 + x4 + x5 + x6 +  x7 + x8 + x9 ~ school
&#39;

fit_3 &lt;- cfa(hs_model_3, 
             data = HolzingerSwineford1939,
             meanstructure = T)

# summary(fit_3)</code></pre>
</div>
<p>A comparison of all three shows the same results, but that the third model has fewer parameters, as the loadings and latent variable variances are not changing across groups.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
model
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
fit_1
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
-0.252
</td>
<td style="text-align:right;">
0.275
</td>
</tr>
<tr>
<td style="text-align:left;">
fit_2
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
-0.252
</td>
<td style="text-align:right;">
0.275
</td>
</tr>
<tr>
<td style="text-align:left;">
fit_3
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
-0.252
</td>
<td style="text-align:right;">
0.275
</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
(#tab:compare_123_Npar)Model N parameters
</caption>
<thead>
<tr>
<th style="text-align:right;">
fit_1
</th>
<th style="text-align:right;">
fit_2
</th>
<th style="text-align:right;">
fit_3
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
39
</td>
</tr>
</tbody>
</table>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
(#tab:compare_123_AIC)Model AIC
</caption>
<thead>
<tr>
<th style="text-align:right;">
fit_1
</th>
<th style="text-align:right;">
fit_2
</th>
<th style="text-align:right;">
fit_3
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
7484.395
</td>
<td style="text-align:right;">
7484.395
</td>
<td style="text-align:right;">
7474.493
</td>
</tr>
</tbody>
</table>
</div>
<h2 id="structural-model">Structural model</h2>
<p>In the models I see, people would more commonly address such a theoretical question without a multigroup approach, simply regressing the latent variable of interest on the group factor. For lack of a better name, I’ll just call this a structural model in the sense we have an explicit regression model. We can do that here.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# standard cfa with school predicting visual
hs_model_4a &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  visual ~ diff*school
  
  visual ~~ speed + verbal  # lavaan will not estimate this by default
&#39;

fit_4a = sem(hs_model_4a, data=HolzingerSwineford1939, meanstructure=T)
summary(fit_4a)</code></pre>
<pre><code>
lavaan 0.6-7 ended normally after 49 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of free parameters                         31
                                                      
  Number of observations                           301
                                                      
Model Test User Model:
                                                      
  Test statistic                               161.444
  Degrees of freedom                                32
  P-value (Chi-square)                           0.000

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.570    0.100    5.723    0.000
    x3                0.797    0.111    7.212    0.000
  verbal =~                                           
    x4                1.000                           
    x5                1.113    0.065   17.021    0.000
    x6                0.928    0.055   16.741    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.194    0.168    7.124    0.000
    x9                1.060    0.148    7.152    0.000

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~                                            
    school  (diff)    0.287    0.110    2.612    0.009

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
 .visual ~~                                           
    speed             0.241    0.054    4.446    0.000
    verbal            0.429    0.073    5.846    0.000
  verbal ~~                                           
    speed             0.172    0.049    3.483    0.000

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                4.500    0.180   24.997    0.000
   .x2                5.840    0.122   47.989    0.000
   .x3                1.903    0.151   12.631    0.000
   .x4                3.061    0.067   45.694    0.000
   .x5                4.341    0.074   58.452    0.000
   .x6                2.186    0.063   34.667    0.000
   .x7                4.186    0.063   66.766    0.000
   .x8                5.527    0.058   94.854    0.000
   .x9                5.374    0.058   92.546    0.000
   .visual            0.000                           
    verbal            0.000                           
    speed             0.000                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.604    0.105    5.739    0.000
   .x2                1.137    0.102   11.172    0.000
   .x3                0.795    0.090    8.879    0.000
   .x4                0.372    0.048    7.821    0.000
   .x5                0.448    0.058    7.698    0.000
   .x6                0.354    0.043    8.254    0.000
   .x7                0.796    0.081    9.775    0.000
   .x8                0.470    0.076    6.209    0.000
   .x9                0.580    0.071    8.195    0.000
   .visual            0.754    0.135    5.597    0.000
    verbal            0.978    0.112    8.735    0.000
    speed             0.387    0.087    4.462    0.000</code></pre>
</div>
<p>At first blush, it would seem we are not getting the same result, as the mean difference is now estimated to be 0.287. Our difference is notably larger and significant. We can also see that the fit is different based on AIC and the number of parameters estimated.</p>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
fit_1
</th>
<th style="text-align:right;">
fit_2
</th>
<th style="text-align:right;">
fit_3
</th>
<th style="text-align:right;">
fit_4a
</th>
<th style="text-align:right;">
fit_baseline
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
7484.395
</td>
<td style="text-align:right;">
7484.395
</td>
<td style="text-align:right;">
7474.493
</td>
<td style="text-align:right;">
7531.852
</td>
<td style="text-align:right;">
7484.395
</td>
</tr>
</tbody>
</table>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
fit_1
</th>
<th style="text-align:right;">
fit_2
</th>
<th style="text-align:right;">
fit_3
</th>
<th style="text-align:right;">
fit_4a
</th>
<th style="text-align:right;">
fit_baseline
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
39
</td>
<td style="text-align:right;">
31
</td>
<td style="text-align:right;">
60
</td>
</tr>
</tbody>
</table>
</div>
<h4 id="structural-model-as-multigroup">Structural model as multigroup</h4>
<p>However, we can recover the previous multigroup results by regressing the other observed variables on school as well. This leaves the only group effect remaining to be the effect on <code>x1</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_4b &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  visual ~ diff*school
  
  x2 + x3 + x4 + x5 + x6 +  x7 + x8 + x9 ~ school
&#39;

fit_4b = sem(hs_model_4b, data=HolzingerSwineford1939, meanstructure=T)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
fit_1
</th>
<th style="text-align:right;">
fit_2
</th>
<th style="text-align:right;">
fit_3
</th>
<th style="text-align:right;">
fit_4a
</th>
<th style="text-align:right;">
fit_4b
</th>
<th style="text-align:right;">
fit_baseline
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
7484.395
</td>
<td style="text-align:right;">
7484.395
</td>
<td style="text-align:right;">
7474.493
</td>
<td style="text-align:right;">
7531.852
</td>
<td style="text-align:right;">
7526.606
</td>
<td style="text-align:right;">
7484.395
</td>
</tr>
</tbody>
</table>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
fit_1
</th>
<th style="text-align:right;">
fit_2
</th>
<th style="text-align:right;">
fit_3
</th>
<th style="text-align:right;">
fit_4a
</th>
<th style="text-align:right;">
fit_4b
</th>
<th style="text-align:right;">
fit_baseline
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
39
</td>
<td style="text-align:right;">
31
</td>
<td style="text-align:right;">
37
</td>
<td style="text-align:right;">
60
</td>
</tr>
</tbody>
</table>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
model
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
-0.252
</td>
<td style="text-align:right;">
0.275
</td>
</tr>
<tr>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
-0.252
</td>
<td style="text-align:right;">
0.275
</td>
</tr>
<tr>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
-0.252
</td>
<td style="text-align:right;">
0.275
</td>
</tr>
<tr>
<td style="text-align:left;">
4b
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="multigroup-as-the-structural-model">Multigroup as the structural model</h3>
<p>Let’s see if we can get the structural model result from our multigroup approach. In fact we can. The following produces the same coefficient by summing the differences on the observed items. As we will see later, the statistical result is essentially what we’d get by using a linear regression on a sum score of visual items.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_baseline_2 &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 
  
  x1 ~ c(a1, a2)*1
  x2 ~ c(b1, b2)*1
  x3 ~ c(c1, c2)*1
  
  diff := (a1 - a2) + (b1 - b2) + (c1 - c2)
&#39;

fit_baseline_2 &lt;- cfa(
  hs_model_baseline_2, 
  data = HolzingerSwineford1939, 
  group = &quot;school&quot;
)

summary(fit_baseline_2)</code></pre>
<pre><code>
lavaan 0.6-7 ended normally after 57 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of free parameters                         60
                                                      
  Number of observations per group:                   
    Pasteur                                        156
    Grant-White                                    145
                                                      
Model Test User Model:
                                                      
  Test statistic                               115.851
  Degrees of freedom                                48
  P-value (Chi-square)                           0.000
  Test statistic for each group:
    Pasteur                                     64.309
    Grant-White                                 51.542

Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured


Group 1 [Pasteur]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.394    0.122    3.220    0.001
    x3                0.570    0.140    4.076    0.000
  verbal =~                                           
    x4                1.000                           
    x5                1.183    0.102   11.613    0.000
    x6                0.875    0.077   11.421    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.125    0.277    4.057    0.000
    x9                0.922    0.225    4.104    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    verbal            0.479    0.106    4.531    0.000
    speed             0.185    0.077    2.397    0.017
  verbal ~~                                           
    speed             0.182    0.069    2.628    0.009

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1        (a1)    4.941    0.095   52.249    0.000
   .x2        (b1)    5.984    0.098   60.949    0.000
   .x3        (c1)    2.487    0.093   26.778    0.000
   .x4                2.823    0.092   30.689    0.000
   .x5                3.995    0.105   38.183    0.000
   .x6                1.922    0.079   24.321    0.000
   .x7                4.432    0.087   51.181    0.000
   .x8                5.563    0.078   71.214    0.000
   .x9                5.418    0.079   68.440    0.000
    visual            0.000                           
    verbal            0.000                           
    speed             0.000                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.298    0.232    1.286    0.198
   .x2                1.334    0.158    8.464    0.000
   .x3                0.989    0.136    7.271    0.000
   .x4                0.425    0.069    6.138    0.000
   .x5                0.456    0.086    5.292    0.000
   .x6                0.290    0.050    5.780    0.000
   .x7                0.820    0.125    6.580    0.000
   .x8                0.510    0.116    4.406    0.000
   .x9                0.680    0.104    6.516    0.000
    visual            1.097    0.276    3.967    0.000
    verbal            0.894    0.150    5.963    0.000
    speed             0.350    0.126    2.778    0.005


Group 2 [Grant-White]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                1.000                           
    x2                0.736    0.155    4.760    0.000
    x3                0.925    0.166    5.583    0.000
  verbal =~                                           
    x4                1.000                           
    x5                0.990    0.087   11.418    0.000
    x6                0.963    0.085   11.377    0.000
  speed =~                                            
    x7                1.000                           
    x8                1.226    0.187    6.569    0.000
    x9                1.058    0.165    6.429    0.000

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    verbal            0.408    0.098    4.153    0.000
    speed             0.276    0.076    3.639    0.000
  verbal ~~                                           
    speed             0.222    0.073    3.022    0.003

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1        (a2)    4.930    0.095   51.696    0.000
   .x2        (b2)    6.200    0.092   67.416    0.000
   .x3        (c2)    1.996    0.086   23.195    0.000
   .x4                3.317    0.093   35.625    0.000
   .x5                4.712    0.096   48.986    0.000
   .x6                2.469    0.094   26.277    0.000
   .x7                3.921    0.086   45.819    0.000
   .x8                5.488    0.087   63.174    0.000
   .x9                5.327    0.085   62.571    0.000
    visual            0.000                           
    verbal            0.000                           
    speed             0.000                           

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                0.715    0.126    5.676    0.000
   .x2                0.899    0.123    7.339    0.000
   .x3                0.557    0.103    5.409    0.000
   .x4                0.315    0.065    4.870    0.000
   .x5                0.419    0.072    5.812    0.000
   .x6                0.406    0.069    5.880    0.000
   .x7                0.600    0.091    6.584    0.000
   .x8                0.401    0.094    4.249    0.000
   .x9                0.535    0.089    6.010    0.000
    visual            0.604    0.160    3.762    0.000
    verbal            0.942    0.152    6.177    0.000
    speed             0.461    0.118    3.910    0.000

Defined Parameters:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
    diff              0.287    0.297    0.965    0.335</code></pre>
</div>
<h3 id="group-difference-as-an-indirect-effect">Group difference as an indirect effect</h3>
<p>Going back to the first structural model <code>hs_model_4a</code>, it might be interesting to some to see that the group difference <em>still</em> regards a difference on the observed <code>x1</code> observed variable. We can see this more clearly if we set the <code>x1</code> loading to be estimated rather than fixed at one, then use the product of coefficients approach (a la <a href="">mediation</a>) to estimate the group difference.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_4c &lt;- &#39; 
  visual =~ x2 + a*x1 + x3    # estimate x1 loading vs. scaling by it
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 

  visual ~ b*school
  
  visual ~~ verbal + speed
  
  diff := a*b    # &quot;indirect&quot; effect of school on x1
&#39;

# same as fit_4a
fit_4c = cfa(hs_model_4c, data = HolzingerSwineford1939, meanstructure=T)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
model
</th>
<th style="text-align:left;">
label
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
4a
</td>
<td style="text-align:left;">
diff
</td>
<td style="text-align:right;">
0.287
</td>
<td style="text-align:right;">
0.11
</td>
<td style="text-align:right;">
2.612
</td>
<td style="text-align:right;">
0.009
</td>
<td style="text-align:right;">
0.072
</td>
<td style="text-align:right;">
0.503
</td>
</tr>
<tr>
<td style="text-align:left;">
4c
</td>
<td style="text-align:left;">
diff
</td>
<td style="text-align:right;">
0.287
</td>
<td style="text-align:right;">
0.11
</td>
<td style="text-align:right;">
2.612
</td>
<td style="text-align:right;">
0.009
</td>
<td style="text-align:right;">
0.072
</td>
<td style="text-align:right;">
0.503
</td>
</tr>
</tbody>
</table>
</div>
<p>And what is this value of 0.287? We see it as the group difference on the latent construct rather than simply being a mean difference on <code>x1</code>. However, in <code>fit_4a</code> it is estimated on the metric of <code>x1</code>, which had it’s loading fixed to 1. We will see another interpretation later.</p>
<aside>
You might be thinking, why does my effect on the latent variable depend on a specific item? Well it <em>shouldn’t</em>. If the items are random observations measured in the same way of the same underlying construct, then the loadings will essentially be equal, and so it wouldn’t matter which one is chosen as a default.
</aside>
<h2 id="more-structural-models">More structural models</h2>
<p>The following is equivalent to the result one would get from <code>group.equal = c('loadings', 'intercepts')</code>, but to make things more clear, I show the explicit syntax (commented out are other options one could potentially play with). The first group would have latent variable means at zero, while the second group would be allowed to vary. This is more or less what is desired if we want to know a group difference on the latent structure. The first group mean is arbitrarily set to zero, so the estimated intercept for the second group tells us the relative difference, much like when we are dummy coding with standard regression models.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_4d &lt;- &#39; 
  # make loadings equal across groups
  
  visual =~ c(1, 1)*x1 + c(v_x2, v_x2)*x2 + c(v_x3, v_x3)*x3
  verbal =~ c(1, 1)*x4 + c(v_x5, v_x5)*x5 + c(v_x6, v_x6)*x6
  speed  =~ c(1, 1)*x7 + c(v_x8, v_x8)*x8 + c(v_x9, v_x9)*x9 
  
  # make intercepts equal across groups
  
  x1 ~ c(0, 0) * 1
  x2 ~ c(int_x2, int_x2) * 1
  x3 ~ c(int_x3, int_x3) * 1
  x4 ~ c(0, 0) * 1
  x5 ~ c(int_x5, int_x5) * 1
  x6 ~ c(int_x6, int_x6) * 1
  x7 ~ c(0, 0) * 1
  x8 ~ c(int_x8, int_x8) * 1
  x9 ~ c(int_x9, int_x9) * 1
  
  # make covariances equal across groups
  
  # visual ~~ c(cov_vv, cov_vv) * verbal + c(cov_visp, cov_visp) * speed
  # verbal ~~ c(cov_vesp, cov_vesp) * speed
  
  # make variances equal
  
  # visual ~~ c(vvar, vvar) * visual
  # verbal ~~ c(tvar, tvar) * verbal
  # speed  ~~ c(svar, svar) * speed
  
  # x1 ~~ c(x1var, x1var) * x1
  # x2 ~~ c(x2var, x2var) * x2
  # x3 ~~ c(x3var, x3var) * x3
  # x4 ~~ c(x4var, x4var) * x4
  # x5 ~~ c(x5var, x5var) * x5
  # x6 ~~ c(x6var, x6var) * x6
  # x7 ~~ c(x7var, x7var) * x7
  # x8 ~~ c(x8var, x8var) * x8
  # x9 ~~ c(x9var, x9var) * x9
  
  
  visual ~ c(vis_int_p, vis_int_gw)*1
  verbal ~ c(verb_int_p, verb_int_gw)*1
  speed  ~ c(speed_int_p, speed_int_gw)*1
  
  
   
  # comparisons
   diff := vis_int_p - vis_int_gw
&#39;

fit_4d  = sem(hs_model_4d, 
                data=HolzingerSwineford1939, 
                group = &#39;school&#39;,
                meanstructure=T)

summary(fit_4d, header=F, nd=2)</code></pre>
<pre><code>
Parameter Estimates:

  Standard errors                             Standard
  Information                                 Expected
  Information saturated (h1) model          Structured


Group 1 [Pasteur]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                 1.00                           
    x2      (v_x2)     0.58     0.10     5.71     0.00
    x3      (v_x3)     0.80     0.11     7.15     0.00
  verbal =~                                           
    x4                 1.00                           
    x5      (v_x5)     1.12     0.07    16.97     0.00
    x6      (v_x6)     0.93     0.06    16.61     0.00
  speed =~                                            
    x7                 1.00                           
    x8      (v_x8)     1.13     0.15     7.79     0.00
    x9      (v_x9)     1.01     0.13     7.67     0.00

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    verbal             0.41     0.10     4.29     0.00
    speed              0.18     0.07     2.69     0.01
  verbal ~~                                           
    speed              0.18     0.06     2.90     0.00

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                 0.00                           
   .x2      (in_2)     3.27     0.50     6.54     0.00
   .x3      (in_3)    -1.72     0.55    -3.11     0.00
   .x4                 0.00                           
   .x5      (in_5)     0.92     0.21     4.36     0.00
   .x6      (in_6)    -0.66     0.18    -3.75     0.00
   .x7                 0.00                           
   .x8      (in_8)     0.84     0.60     1.39     0.17
   .x9      (in_9)     1.18     0.55     2.16     0.03
    visual  (vs__)     5.00     0.09    55.76     0.00
    verbal  (vr__)     2.78     0.09    31.95     0.00
    speed   (sp__)     4.24     0.07    57.97     0.00

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                 0.56     0.14     3.98     0.00
   .x2                 1.30     0.16     8.19     0.00
   .x3                 0.94     0.14     6.93     0.00
   .x4                 0.45     0.07     6.43     0.00
   .x5                 0.50     0.08     6.14     0.00
   .x6                 0.26     0.05     5.26     0.00
   .x7                 0.89     0.12     7.42     0.00
   .x8                 0.54     0.09     5.71     0.00
   .x9                 0.65     0.10     6.80     0.00
    visual             0.80     0.17     4.64     0.00
    verbal             0.88     0.13     6.69     0.00
    speed              0.32     0.08     3.91     0.00


Group 2 [Grant-White]:

Latent Variables:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual =~                                           
    x1                 1.00                           
    x2      (v_x2)     0.58     0.10     5.71     0.00
    x3      (v_x3)     0.80     0.11     7.15     0.00
  verbal =~                                           
    x4                 1.00                           
    x5      (v_x5)     1.12     0.07    16.97     0.00
    x6      (v_x6)     0.93     0.06    16.61     0.00
  speed =~                                            
    x7                 1.00                           
    x8      (v_x8)     1.13     0.15     7.79     0.00
    x9      (v_x9)     1.01     0.13     7.67     0.00

Covariances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
  visual ~~                                           
    verbal             0.43     0.10     4.42     0.00
    speed              0.33     0.08     4.01     0.00
  verbal ~~                                           
    speed              0.24     0.07     3.22     0.00

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                 0.00                           
   .x2      (in_2)     3.27     0.50     6.54     0.00
   .x3      (in_3)    -1.72     0.55    -3.11     0.00
   .x4                 0.00                           
   .x5      (in_5)     0.92     0.21     4.36     0.00
   .x6      (in_6)    -0.66     0.18    -3.75     0.00
   .x7                 0.00                           
   .x8      (in_8)     0.84     0.60     1.39     0.17
   .x9      (in_9)     1.18     0.55     2.16     0.03
    visual  (vs__)     4.85     0.09    52.96     0.00
    verbal  (vr__)     3.35     0.09    38.16     0.00
    speed   (sp__)     4.06     0.08    50.75     0.00

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
   .x1                 0.65     0.13     5.09     0.00
   .x2                 0.96     0.12     7.81     0.00
   .x3                 0.64     0.10     6.32     0.00
   .x4                 0.34     0.06     5.53     0.00
   .x5                 0.38     0.07     5.13     0.00
   .x6                 0.44     0.07     6.56     0.00
   .x7                 0.63     0.10     6.57     0.00
   .x8                 0.43     0.09     4.91     0.00
   .x9                 0.52     0.09     6.10     0.00
    visual             0.71     0.16     4.42     0.00
    verbal             0.87     0.13     6.66     0.00
    speed              0.51     0.12     4.38     0.00

Defined Parameters:
                   Estimate  Std.Err  z-value  P(&gt;|z|)
    diff               0.15     0.12     1.21     0.23</code></pre>
</div>
<p>The fit is now estimated to be 0.148, as we are now taking into account the intercorrelations of the latent variables. However, there is a more simple and obvious way to do this model. We simply regress all latent variables on school.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_4e &lt;- &#39; 
  visual =~ x1 + x2 + x3    # estimate x1 loading vs. scaling by it
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9 

  visual ~ diff*school
  
  verbal + speed ~ school
&#39;

fit_4e = cfa(hs_model_4e, data = HolzingerSwineford1939, meanstructure=T)
# summary(fit_4e)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
model
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
conf.low
</th>
<th style="text-align:right;">
conf.high
</th>
</tr>
</thead>
<tbody>
<tr grouplength="4">
<td colspan="5" style="border-bottom: 1px solid;">
<strong>Observed value differences</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
1
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
-0.252
</td>
<td style="text-align:right;">
0.275
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
2
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
-0.252
</td>
<td style="text-align:right;">
0.275
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
3
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
-0.252
</td>
<td style="text-align:right;">
0.275
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
4b
</td>
<td style="text-align:right;">
0.011
</td>
<td style="text-align:right;">
0.134
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr grouplength="4">
<td colspan="5" style="border-bottom: 1px solid;">
<strong>Latent variable differences</strong>
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
4a
</td>
<td style="text-align:right;">
0.287
</td>
<td style="text-align:right;">
0.110
</td>
<td style="text-align:right;">
0.072
</td>
<td style="text-align:right;">
0.503
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
4c
</td>
<td style="text-align:right;">
0.287
</td>
<td style="text-align:right;">
0.110
</td>
<td style="text-align:right;">
0.072
</td>
<td style="text-align:right;">
0.503
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
4d
</td>
<td style="text-align:right;">
0.148
</td>
<td style="text-align:right;">
0.122
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:left; padding-left: 2em;" indentlevel="1">
4e
</td>
<td style="text-align:right;">
0.147
</td>
<td style="text-align:right;">
0.122
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
</tbody>
</table>
</div>
<p>The primary differences we’ve seen thus far can be summarized as follows:</p>
<ul>
<li>1:3 and 4b: These models are focusing on observed variable differences, specifically on <code>x1</code>.</li>
<li>4a and 4c: These models are latent variable differences on the visual factor, but do not control for indirect (or <em>backdoor</em>) effect school has on visual <em>through</em> speed and verbal. In that light, we might consider this the <em>total effect</em> of school on the visual factor. Had we regressed the verbal and speed factors on school also, thereby decomposing the total effect into those different paths, we’d get the same result for the school difference on the visual factor as we do in 4d and e</li>
<li>4d and 4e: This is generally what we want. A simple group difference on a latent variable(s) with other parameters assumed (relatively) equal across groups.</li>
</ul>
<h2 id="sumfactor-score">Sum/Factor score</h2>
<p>What would happen if we look at the structural/regression model with the estimated latent variable scores<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>? How about we go even simpler, by not even running an SEM and simply using sum scores? Let’s see what results.</p>
<p>We’ll start with the estimated factor scores.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_5 &lt;- &#39; 
  visual =~ x1 + x2 + x3
  verbal =~ x4 + x5 + x6
  speed  =~ x7 + x8 + x9
&#39;

fit_5 = cfa(hs_model_5, data = HolzingerSwineford1939, meanstructure=T)

HolzingerSwineford1939 = HolzingerSwineford1939 %&gt;% 
  mutate(
    visual = lavPredict(fit_5)[,&#39;visual&#39;],
    verbal = lavPredict(fit_5)[,&#39;verbal&#39;],
    speed  = lavPredict(fit_5)[,&#39;speed&#39;]
  )

lm_1 = lm(visual ~ school + verbal + speed, data = HolzingerSwineford1939)
coef(lm_1)  </code></pre>
<pre><code>
  (Intercept) schoolPasteur        verbal         speed 
  -0.07231513    0.13953111    0.34744541    0.63626370 </code></pre>
</div>
<p>The estimated coefficient is pretty close to that estimated by the SEM when we regressed all the factors on school. Interestingly, if we fix the loadings to be constant, we recover the initial multigroup estimates.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_5b &lt;- &#39; 
  visual =~ x1 + l1*x2 + l1*x3
  verbal =~ x4 + l2*x5 + l2*x6
  speed  =~ x7 + l3*x8 + l3*x9 
&#39;

fit_5b = cfa(hs_model_5b,
             data = lavaan::HolzingerSwineford1939,
             meanstructure = T)

HolzingerSwineford1939 = HolzingerSwineford1939 %&gt;%
  mutate(
    visual = lavPredict(fit_5b)[, &#39;visual&#39;],
    verbal = lavPredict(fit_5b)[, &#39;verbal&#39;],
    speed  = lavPredict(fit_5b)[, &#39;speed&#39;]
  )

lm_2 = lm(visual ~ school, data = HolzingerSwineford1939)
coef(lm_2)  # same as x1 diffs</code></pre>
<pre><code>
  (Intercept) schoolPasteur 
 -0.005790171   0.011172061 </code></pre>
<pre class="r"><code>
lm_3 = lm(x1 ~ school, data = HolzingerSwineford1939)
coef(lm_3)</code></pre>
<pre><code>
  (Intercept) schoolPasteur 
   4.92988506    0.01135425 </code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>Now lets do a sum score. It may not be obvious, but a sum score can be seen as assuming a latent variable model where there is only a single construct and loadings and variances are equal for each item. As such, it is a natural substitute for a latent variable if we don’t want to use SEM, especially if we’re dealing with a notably reliable measure.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
HolzingerSwineford1939 = HolzingerSwineford1939 %&gt;%
  rowwise() %&gt;%
  mutate(
    visual_sum = sum(x1, x2, x3),
    verbal_sum = sum(x4, x5, x6),
    speed_sum  = sum(x7, x8, x9)
  ) %&gt;%
  ungroup()

lm_sum = lm(visual_sum ~ school, HolzingerSwineford1939)

coef(lm_sum)  # same as structural diffs</code></pre>
<pre><code>
  (Intercept) schoolPasteur 
   13.1255747     0.2868184 </code></pre>
</div>
<p>That coefficient representing the group difference looks familiar- it’s the same value as we had for models <code>4a</code> and <code>4c</code>, where we looked at a group difference only for the visual factor. As with those, this can be seen as a total effect of school on the visual ‘factor’.</p>
<h2 id="summary-of-differences">Summary of differences</h2>
<p>We can summarize our results as follows. The <a href="#multiple-group-analysis"><strong>??</strong></a> multigroup approach can be seen as an interaction of everything with the grouping variable. In some measurement scenarios, for example, the development of a nationwide achievement exam, this might be desirable as a means to establish <span class="emph">measurement invariance</span> (see below). However, I think this is probably rarely a theoretical goal for most applied researchers using SEM. Furthermore, group sizes may be prohibitively small given the number of parameters that need to be estimated. And if we consider other modeling contexts outside of SEM, it is exceedingly rare to interact every covariate with a moderator.</p>
<p>In general though, we may very well be interested in a specific group difference on some latent variable, possibly controlling for other effects in some fashion. It is far simpler to specify such a model as above by regressing the latent variable on the group indicator as in the demonstration above, and it is a notably simpler model as well.</p>
<h2 id="supplemental-measurement-invariance">Supplemental: Measurement invariance</h2>
<p>As a final note, in some cases we are instead looking for similarities across groups among the latent constructs, rather than differences. This is especially the case in scale development, where one would like a measure to be consistent across groups of individuals (e.g. sex, age, race, etc.).</p>
<p>Aside from general problems of ‘accepting the null hypothesis’, the basic idea is to test a restricted model (e.g. loadings, intercepts, etc. are equal) vs. the less restrictive one that assumes the differences across groups exist, and if the general fit of the models is not appreciably different, then one can claim equivalence across groups. As a starting point, we assume <span class="emph">configural</span> equivalence, or in other words, that the factor structure is the same. There is no point in testing measurement equivalence if there is not a similar factor structure. The first more restricted model is that the loadings are equivalent. The next is that observed variable intercepts are equivalent, followed by latent variable means, and finally residual variances/covariances.</p>
<p>I find in consulting and in published reports that researchers think that because they are interested in group differences that they are required to take a measurement invariance approach. This is not the case at all, as our previous models have shown. However, below is a demonstration using <span class="pack">semTools</span>. The package used to have a simple function that did exactly what most users want in a way easier than any other SEM package I’ve come across. In an effort to add flexibility and accommodate other data scenarios, they’ve made it much more complicated to do the default scenario, and have unfortunately deprecated the simple approach. I demonstrate both below.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
hs_model_4 &lt;- &#39; 
  visual  =~ x1 + x2 + x3
  verbal  =~ x4 + x5 + x6
  speed   =~ x7 + x8 + x9 
&#39;

semTools::measurementInvariance(
  model = hs_model_4, 
  data  = HolzingerSwineford1939, 
  group = &quot;school&quot;
)</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
cat(&quot;
Measurement invariance models:

Model 1 : fit.configural
Model 2 : fit.loadings
Model 3 : fit.intercepts
Model 4 : fit.means

Chi-Squared Difference Test

               Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    
fit.configural 48 7484.4 7706.8 115.85                                  
fit.loadings   54 7480.6 7680.8 124.04      8.192       6     0.2244    
fit.intercepts 60 7508.6 7686.6 164.10     40.059       6  4.435e-07 ***
fit.means      63 7543.1 7710.0 204.61     40.502       3  8.338e-09 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


Fit measures:

                 cfi rmsea cfi.delta rmsea.delta
fit.configural 0.923 0.097        NA          NA
fit.loadings   0.921 0.093     0.002       0.004
fit.intercepts 0.882 0.107     0.038       0.015
fit.means      0.840 0.122     0.042       0.015
    &quot;)</code></pre>
<pre><code>
Measurement invariance models:

Model 1 : fit.configural
Model 2 : fit.loadings
Model 3 : fit.intercepts
Model 4 : fit.means

Chi-Squared Difference Test

               Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    
fit.configural 48 7484.4 7706.8 115.85                                  
fit.loadings   54 7480.6 7680.8 124.04      8.192       6     0.2244    
fit.intercepts 60 7508.6 7686.6 164.10     40.059       6  4.435e-07 ***
fit.means      63 7543.1 7710.0 204.61     40.502       3  8.338e-09 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


Fit measures:

                 cfi rmsea cfi.delta rmsea.delta
fit.configural 0.923 0.097        NA          NA
fit.loadings   0.921 0.093     0.002       0.004
fit.intercepts 0.882 0.107     0.038       0.015
fit.means      0.840 0.122     0.042       0.015
    </code></pre>
</div>
<p>Now for the new approach. From a single line of code, we now have to do the following to produce the same result. Great if you need that additional functionality, not so much if you don’t. If you look at the visual latent variable intercepts model , their difference would equal that seen in models <code>4d/e</code>.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
test.seq &lt;- c(&quot;loadings&quot;,&quot;intercepts&quot;,&quot;means&quot;,&quot;residuals&quot;)

meq.list &lt;- list()

for (i in 0:length(test.seq)) {
  if (i == 0L) {
    meq.label &lt;- &quot;configural&quot;
    group.equal &lt;- &quot;&quot;
  } else {
    meq.label &lt;- test.seq[i]
    group.equal &lt;- test.seq[1:i]
  }
  
  meq.list[[meq.label]] &lt;- 
    semTools::measEq.syntax(
      configural.model = hs_model_baseline,
      data = lavaan::HolzingerSwineford1939,
      ID.fac = &quot;auto.fix.first&quot;,
      group = &quot;school&quot;,
      group.equal = group.equal,
      return.fit = TRUE
  )
}

semTools::compareFit(meq.list)</code></pre>
<pre><code>
################### Nested Model Comparison #########################
Chi-Squared Difference Test

                    Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    
meq.list.configural 48 7484.4 7706.8 115.85                                  
meq.list.loadings   54 7480.6 7680.8 124.04      8.192       6    0.22436    
meq.list.intercepts 60 7508.6 7686.6 164.10     40.059       6  4.435e-07 ***
meq.list.means      63 7543.1 7710.0 204.61     40.502       3  8.338e-09 ***
meq.list.residuals  72 7541.9 7675.3 221.34     16.730       9    0.05312 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

####################### Model Fit Indices ###########################
                       chisq df pvalue   cfi   tli       aic       bic rmsea  srmr
meq.list.configural 115.851† 48   .000 .923† .885  7484.395  7706.822  .097  .068†
meq.list.loadings   124.044  54   .000 .921  .895† 7480.587† 7680.771  .093† .072 
meq.list.intercepts 164.103  60   .000 .882  .859  7508.647  7686.588  .107  .082 
meq.list.means      204.605  63   .000 .840  .817  7543.149  7709.969  .122  .109 
meq.list.residuals  221.335  72   .000 .831  .831  7541.879  7675.335† .117  .114 

################## Differences in Fit Indices #######################
                                        df    cfi    tli    aic     bic  rmsea  srmr
meq.list.loadings - meq.list.configural  6 -0.002  0.009 -3.808 -26.050 -0.004 0.004
meq.list.intercepts - meq.list.loadings  6 -0.038 -0.036 28.059   5.817  0.015 0.011
meq.list.means - meq.list.intercepts     3 -0.042 -0.042 34.502  23.381  0.015 0.026
meq.list.residuals - meq.list.means      9 -0.009  0.014 -1.270 -34.634 -0.005 0.005</code></pre>
</div>
<p>This last one just compares the means. We see that assuming no group difference results in a worse model all around.</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
# means_only
test.seq &lt;- c(&quot;means&quot;)

meq.list &lt;- list()

for (i in 0:length(test.seq)) {
  if (i == 0L) {
    meq.label &lt;- &quot;configural&quot;
    group.equal &lt;- &quot;&quot;
  } else {
    meq.label &lt;- test.seq[i]
    group.equal &lt;- test.seq[1:i]
  }
  
  meq.list[[meq.label]] &lt;- 
    semTools::measEq.syntax(
      configural.model = hs_model_baseline,
      data = lavaan::HolzingerSwineford1939,
      ID.fac = &quot;auto.fix.first&quot;,
      group = &quot;school&quot;,
      group.equal = group.equal,
      return.fit = TRUE
  )
}

semTools::compareFit(meq.list)</code></pre>
<pre><code>
################### Nested Model Comparison #########################
Chi-Squared Difference Test

                    Df    AIC    BIC  Chisq Chisq diff Df diff Pr(&gt;Chisq)    
meq.list.configural 48 7484.4 7706.8 115.85                                  
meq.list.means      51 7515.7 7727.0 153.19     37.343       3  3.893e-08 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

####################### Model Fit Indices ###########################
                       chisq df pvalue   cfi   tli       aic       bic rmsea  srmr
meq.list.configural 115.851† 48   .000 .923† .885† 7484.395† 7706.822† .097† .068†
meq.list.means      153.195  51   .000 .885  .837  7515.738  7727.044  .115  .089 

################## Differences in Fit Indices #######################
                                     df    cfi    tli    aic    bic rmsea  srmr
meq.list.means - meq.list.configural  3 -0.039 -0.048 31.343 20.222 0.018 0.021</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Note that lavaan allows one to take this two step approach while estimating proper standard errors given the measurement error associated with the latent variable scores. The function is <span class="func">fsr</span>, but as of this writing, it is undergoing development, has been hidden from the user, and was not working.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
